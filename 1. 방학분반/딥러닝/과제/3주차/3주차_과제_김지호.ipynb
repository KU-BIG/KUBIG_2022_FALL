{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차_과제_김지호.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- dataset을 임의로 선정해서 직접 분석 해보기(제공한 코드를 활용해서 해보기)\n",
        "- activation functions 중 relu사용시 함수 직접 정의\n",
        "- lr, optimizer 등 바꿔보기\n",
        "- hidden layer/neuron 수를 바꾸기\n",
        "- 전처리도 추가\n",
        "- 모든 시도를 올려주세요!\n",
        "- 제일 높은 acc를 보인 시도를 명시해주세요!\n"
      ],
      "metadata": {
        "id": "sgAYo4nrw2F4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://yonghyuc.wordpress.com/2019/08/06/pytorch-cuda-gpu-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/"
      ],
      "metadata": {
        "id": "YRuCtEh5Yux2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fX437IL6qbI-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.datasets import load_digits\n",
        "from torch.utils.data import  TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(42)\n",
        "if device == \"cuda\":\n",
        "  torch.cuda.manual_seed_all(42)"
      ],
      "metadata": {
        "id": "SggpQfSPt85C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "F-8JUdihhU1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits=load_digits() ## 손글씨 데이터"
      ],
      "metadata": {
        "id": "FywYbfsKtjcR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = digits.data\n",
        "output = digits.target  # 각 이미지에 대응하는 숫자"
      ],
      "metadata": {
        "id": "C2P0hqZ9yBGm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input.shape ####(n_samples, n_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtR8wjPsZhE3",
        "outputId": "768f2d4e-9d55-4a6c-b03b-697a5a85f8a4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digits.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0y4_du7cQJE",
        "outputId": "e5c39159-4e3a-4e63-a07c-8cc43415db14"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits['DESCR'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTMPexrKcUP0",
        "outputId": "2926a313-da2e-4a52-f8c0-02600bfadd5c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuYGQnZBb5-D",
        "outputId": "3298635e-c2c6-45a9-d9c3-b5de250a5f49"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.gray() \n",
        "plt.matshow(digits.images[0]) \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ho7Amaejb9-S",
        "outputId": "4dc7b431-22a8-49ab-b4bf-be041f629afe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imshow()는 행렬 형태의 2차원 데이터를 색깔로 표시해줌 \n",
        "# 픽셀들의 축 위치 간격을 보정하여 이미지가 자연스러운 모양으로 보일 수 있게 하는 방법\n",
        "# nearest는 가장 고해상도 보간법 \n",
        "plt.imshow(digits.images[1005], cmap=plt.cm.gray_r, interpolation='nearest') \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vvYlN7-WbJ5g",
        "outputId": "1ec9317f-0a74-41ec-93ae-f1686d051de9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.images.shape)\n",
        "print(digits.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6WpzU23cc1U",
        "outputId": "18a6de5a-2102-4dee-a812-a92876529d08"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 8, 8)\n",
            "(1797, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(input, output, test_size = 0.3, random_state = 42, stratify= digits.target, shuffle = True)\n",
        "\n",
        "x_train = torch.FloatTensor(x_train).to(device)\n",
        "y_train = torch.LongTensor(y_train).to(device)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "# 데이터를 tensor로 바꿔주고 gpu 연산이 가능해지도록 gpu에 옮김 (device)\n",
        "# label 값을 왜 long 에 옮겨놓는가? loss function이 다르기 때문 "
      ],
      "metadata": {
        "id": "bLMzf-2ntYeX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0], x_train[0].shape) #8*8\n",
        "print(y_train[0],y_train[1])\n",
        "\n",
        "#input 1797개 (len 64 array)\n",
        "#y의 class는 10개 (0-9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEdiTZkrVqS",
        "outputId": "80f1f1da-27ec-4537-e1a4-2c17944f3469"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.,  0.,  0., 16., 12.,  1.,  0.,  0.,  0.,  0.,  6., 16., 14.,  7.,\n",
            "         0.,  0.,  0.,  0., 14., 15.,  1., 11.,  0.,  0.,  0.,  0., 16., 15.,\n",
            "         0., 14.,  1.,  0.,  0.,  1., 16., 10.,  0., 14.,  2.,  0.,  0.,  0.,\n",
            "        15., 13.,  3., 15.,  3.,  0.,  0.,  0.,  9., 16., 16., 15.,  0.,  0.,\n",
            "         0.,  0.,  0., 13., 16.,  8.,  0.,  0.], device='cuda:0') torch.Size([64])\n",
            "tensor(0, device='cuda:0') tensor(7, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서는 데이터셋을 좀 더 쉽게 다룰 수 있도록 유용한 도구로서 torch.utils.data.Dataset과 torch.utils.data.DataLoader를 제공합니다. 이를 사용하면 미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리까지 간단히 수행할 수 있습니다. 기본적인 사용 방법은 **Dataset을 정의**하고, 이를 **DataLoader에 전달**하는 것\n",
        "- init : class 에서 객체가 생성되면 바로 실행되는 함수\n",
        "- len : observation 수를 정의하는 함수\n",
        "- getitem : iteration 마다 해당하는 데이터를 돌려주는 함수"
      ],
      "metadata": {
        "id": "combmxzmYFyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = x_train\n",
        "    self.y_data = [[y] for y in y_train]\n",
        "#  데이터셋의 전처리를 해주는 부분\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "#  데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx]).to(device)\n",
        "    y = torch.LongTensor(self.y_data[idx]).to(device)\n",
        "#  데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
        "\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "y38TlgXoqV5Z"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "#Dataset을 정의\n",
        "dataset = CustomDataset() # init 실행 -> 데이터셋의 전처리를 해주는 부분 전역변수인 x_train, y_train 가져옴 \n",
        "#DataLoader에 전달\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size) "
      ],
      "metadata": {
        "id": "x8VHwnuFqino"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링"
      ],
      "metadata": {
        "id": "_jjvRRD7hSZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## activation function"
      ],
      "metadata": {
        "id": "5Z1ahPPhmVQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "class로 구현 가능\n",
        "- init : 초기 생성 함수\n",
        "- foward : 순전파(입력값 => 예측값 의 과정)\n",
        "\n",
        "activation function 이용 파라미터가 필요 X (https://pytorch.org/docs/stable/nn.html)\n",
        "- nn.ReLU()\n",
        "- nn.tanH()\n",
        "\n",
        "\n",
        "- batch normazliation 1d, 파라미터 값으로 vector의 길이를 전해줌\n",
        "- 추후에 이미지를 다루게 된다면, 그때는 batch normalization 2d를 이용함\n",
        "- 그때는 파라미터 값으로 채널, 가로, 세로 길이를 전달해주게 됨 "
      ],
      "metadata": {
        "id": "07uV8RY7Yr_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Sigmoid()"
      ],
      "metadata": {
        "id": "pj4TADLPhgin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_sigmoid(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model_sigmoid, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "          nn.Linear(64,398, bias=True), # input_layer = 30, hidden_layer1 = 398 \n",
        "          nn.Sigmoid(),\n",
        "        nn.BatchNorm1d(398)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "          nn.Linear(398,15, bias=True), # hidden_layer1 = 398, hidden_layer2 = 15\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "          nn.Linear(15,10, bias=True), # hidden_layer1 = 15, hidden_layer2 = 10\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(10, 10, bias=True), # hidden_layer3 = 10, output_layer = 5\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.layer1(x)\n",
        "    output = self.layer2(output)\n",
        "    output = self.layer3(output)\n",
        "    output = self.layer4(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "a0zLstbMqxEZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.ReLU()"
      ],
      "metadata": {
        "id": "tV5bCxJplPIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model_relu(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model_relu, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "          nn.Linear(64,398, bias=True), # input_layer = 30, hidden_layer1 = 398 \n",
        "          nn.ReLU(),\n",
        "        nn.BatchNorm1d(398)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "          nn.Linear(398,15, bias=True), # hidden_layer1 = 398, hidden_layer2 = 15\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "          nn.Linear(15,10, bias=True), # hidden_layer1 = 15, hidden_layer2 = 10\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(10, 10, bias=True), # hidden_layer3 = 10, output_layer = 5\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.layer1(x)\n",
        "    output = self.layer2(output)\n",
        "    output = self.layer3(output)\n",
        "    output = self.layer4(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "usmMwNYmlScv"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.tanh()"
      ],
      "metadata": {
        "id": "4MB-trW0layE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_tanh(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model_tanh, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "          nn.Linear(64,398, bias=True), # input_layer = 30, hidden_layer1 = 398 \n",
        "          nn.Tanh(),\n",
        "        nn.BatchNorm1d(398)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "          nn.Linear(398,15, bias=True), # hidden_layer1 = 398, hidden_layer2 = 15\n",
        "        nn.Tanh()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "          nn.Linear(15,10, bias=True), # hidden_layer1 = 15, hidden_layer2 = 10\n",
        "        nn.Tanh()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(10, 10, bias=True), # hidden_layer3 = 10, output_layer = 5\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.layer1(x)\n",
        "    output = self.layer2(output)\n",
        "    output = self.layer3(output)\n",
        "    output = self.layer4(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "05bP6YE2ldfc"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## weight initialize\n",
        "Layer의 weight를 어떤 분포를 가지도록 초기화시켜줌+global minimum찾기 위해서"
      ],
      "metadata": {
        "id": "F9jKPG2jmb3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xavier \n",
        "xavier 분포 사용 gradient explode/vanish 막는...?"
      ],
      "metadata": {
        "id": "R_vjmdMakZad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights_xavier(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(layer.weight)\n",
        "        layer.bias.data.fill_(0.01)\n",
        "\n",
        "        # Layer의 weight를 어떤 분포를 가지도록 초기화시켜줌+global minimum찾기 위해서"
      ],
      "metadata": {
        "id": "kqcqqkECrSGK"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal distribution"
      ],
      "metadata": {
        "id": "frb_g5bhmzZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights_Gaussian(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        torch.nn.init.normal_(layer.weight)\n",
        "        layer.bias.data.fill_(0.01)\n"
      ],
      "metadata": {
        "id": "F1ETwI_Om5dJ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델"
      ],
      "metadata": {
        "id": "ns29g8Evn9C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_s = Model_sigmoid().to(device)\n",
        "model_r = Model_relu().to(device)\n",
        "model_t = Model_tanh().to(device)\n"
      ],
      "metadata": {
        "id": "oMDUBFg6rUpw"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cl2rbJmPpENn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_s.apply(init_weights_xavier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV0hKJBWpQhc",
        "outputId": "fe8d49ef-177f-4c89-e299-cee6eedac464"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model_sigmoid(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=398, bias=True)\n",
              "    (1): Sigmoid()\n",
              "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_r.apply(init_weights_xavier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKrPl7o2palt",
        "outputId": "59334787-0b1e-421f-a8d5-b3d7b93dbe00"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model_relu(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=398, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_t.apply(init_weights_xavier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivnw0f4IpeK3",
        "outputId": "d25f2171-aee8-4b29-aeba-81c9354d5f35"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model_tanh(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=398, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
              "    (1): Tanh()\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (1): Tanh()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid +xavior + adam"
      ],
      "metadata": {
        "id": "M_Kxd-O0pjhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_s"
      ],
      "metadata": {
        "id": "S-FP7h1qpiVi"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer \n",
        "이건 아직 어렵다"
      ],
      "metadata": {
        "id": "RIqRTC9Lnh-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn  = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "1c-jr7xzn4uX"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### optimizer -> Adam"
      ],
      "metadata": {
        "id": "NYdubqUzlCXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer_adam = optim.Adam(model.parameters(), lr= 0.01)\n",
        "\n",
        "# https://pytorch.org/docs/stable/optim.html#module-torch.optim 페이지 참조\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# sgd 등등"
      ],
      "metadata": {
        "id": "AYFp-eTErh7b"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### optimizer -> SGD \n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "sgd 등등"
      ],
      "metadata": {
        "id": "KWthdH8dntmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_sgd = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# https://pytorch.org/docs/stable/optim.html#module-torch.optim 페이지 참조\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# sgd 등등"
      ],
      "metadata": {
        "id": "LCtR480npwQ7"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### optimizer 고르기"
      ],
      "metadata": {
        "id": "F_QawzElp05y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optimizer_adam "
      ],
      "metadata": {
        "id": "d2tmej7-qEP0"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train ?"
      ],
      "metadata": {
        "id": "7dv0WafPqI2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(100):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = loss_fn(hypothesis, y_train)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  losses.append(cost.item())\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90QxHvlIrjS7",
        "outputId": "3984bdb3-e25a-4b80-fee7-afdd7cd44f3d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.5350135564804077\n",
            "10 1.5156371593475342\n",
            "20 1.5035064220428467\n",
            "30 1.495517611503601\n",
            "40 1.489952564239502\n",
            "50 1.4858590364456177\n",
            "60 1.482729434967041\n",
            "70 1.4802625179290771\n",
            "80 1.4782662391662598\n",
            "90 1.4766145944595337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "81ASYrW7roFM",
        "outputId": "e979a7f7-0bc1-4dc2-822b-9afbf4517c44"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "yDANI-ZLqajY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model = model.to('cpu')\n",
        "  y_pred = model(x_test)\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  predicted = np.argmax(y_pred, axis =1)\n",
        "  accuracy = (accuracy_score(predicted, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4kJzpLErqhZ",
        "outputId": "35780774-4591-4a12-950d-9de9d88db519"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'model의 output은 :  {y_pred[0]}')\n",
        "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
        "print(f'accuracy는 {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyIKhs3Nr6Ay",
        "outputId": "b4a25ddb-cf9e-4408-c16b-cf21739c4ded"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model의 output은 :  [2.1958880e-03 9.7547340e-01 1.4592690e-03 6.2254900e-03 6.5607079e-03\n",
            " 1.8241915e-05 2.8518436e-05 4.8615562e-04 3.2466630e-06 7.5489846e-03]\n",
            "argmax를 한 후의 output은 1\n",
            "accuracy는 0.9833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReLU + xavior + adam"
      ],
      "metadata": {
        "id": "C50ResL_qhnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_r"
      ],
      "metadata": {
        "id": "b-7mTKK7q7z_"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn  = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "_oks0TV0q_Od"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_adam = optim.Adam(model.parameters(), lr= 0.01)"
      ],
      "metadata": {
        "id": "ZABdO5e-rHIt"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optimizer_adam"
      ],
      "metadata": {
        "id": "ItLq4zSTrSVX"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(100):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = loss_fn(hypothesis, y_train)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  losses.append(cost.item())\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "uyPIv_QCrJUC",
        "outputId": "381a7a18-aa97-49dc-e277-57b8fb589eaa"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-de979bc2cd9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# 비용 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-6ec1db63c4ce>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "IzW77M0prNzR",
        "outputId": "84767817-902c-4ca4-f3f8-a9a4142a784a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model = model.to('cpu')\n",
        "  y_pred = model(x_test)\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  predicted = np.argmax(y_pred, axis =1)\n",
        "  accuracy = (accuracy_score(predicted, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvNMis2JrMWU",
        "outputId": "81d183fe-e364-4f1e-8b84-d2b128a4cf12"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'model의 output은 :  {y_pred[0]}')\n",
        "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
        "print(f'accuracy는 {accuracy}')"
      ],
      "metadata": {
        "id": "kyzuLTCNrPOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GoCEtjjoquy8"
      }
    }
  ]
}