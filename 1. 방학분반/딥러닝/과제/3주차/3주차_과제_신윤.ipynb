{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- dataset을 임의로 선정해서 직접 분석 해보기(제공한 코드를 활용해서 해보기)\n",
        "- activation functions 중 relu사용시 함수 직접 정의\n",
        "- lr, optimizer 등 바꿔보기\n",
        "- hidden layer/neuron 수를 바꾸기\n",
        "- 전처리도 추가\n",
        "- 모든 시도를 올려주세요!\n",
        "- 제일 높은 acc를 보인 시도를 명시해주세요!\n"
      ],
      "metadata": {
        "id": "sgAYo4nrw2F4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fX437IL6qbI-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import load_wine\n",
        "from torch.utils.data import  TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_wine()"
      ],
      "metadata": {
        "id": "FywYbfsKtjcR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리"
      ],
      "metadata": {
        "id": "c1N5_3uU6anI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([pd.DataFrame(data.data, columns=data.feature_names), pd.DataFrame(data.target, columns=['target'])], axis=1)"
      ],
      "metadata": {
        "id": "3fDX7bNa0x5W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()   # 결측치 없음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdfJXNfA6YaO",
        "outputId": "1c3f4589-ed80-48a4-e51f-78a3a9465b12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alcohol                         0\n",
              "malic_acid                      0\n",
              "ash                             0\n",
              "alcalinity_of_ash               0\n",
              "magnesium                       0\n",
              "total_phenols                   0\n",
              "flavanoids                      0\n",
              "nonflavanoid_phenols            0\n",
              "proanthocyanins                 0\n",
              "color_intensity                 0\n",
              "hue                             0\n",
              "od280/od315_of_diluted_wines    0\n",
              "proline                         0\n",
              "target                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()   # 전부 numeric > 표준화 필요해보임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "_qG4pLD56g3H",
        "outputId": "18a484bc-4411-49b4-80ae-44e8293040ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
              "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
              "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
              "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
              "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
              "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
              "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
              "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
              "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
              "\n",
              "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
              "count     178.000000  178.000000            178.000000       178.000000   \n",
              "mean        2.295112    2.029270              0.361854         1.590899   \n",
              "std         0.625851    0.998859              0.124453         0.572359   \n",
              "min         0.980000    0.340000              0.130000         0.410000   \n",
              "25%         1.742500    1.205000              0.270000         1.250000   \n",
              "50%         2.355000    2.135000              0.340000         1.555000   \n",
              "75%         2.800000    2.875000              0.437500         1.950000   \n",
              "max         3.880000    5.080000              0.660000         3.580000   \n",
              "\n",
              "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
              "count       178.000000  178.000000                    178.000000   178.000000   \n",
              "mean          5.058090    0.957449                      2.611685   746.893258   \n",
              "std           2.318286    0.228572                      0.709990   314.907474   \n",
              "min           1.280000    0.480000                      1.270000   278.000000   \n",
              "25%           3.220000    0.782500                      1.937500   500.500000   \n",
              "50%           4.690000    0.965000                      2.780000   673.500000   \n",
              "75%           6.200000    1.120000                      3.170000   985.000000   \n",
              "max          13.000000    1.710000                      4.000000  1680.000000   \n",
              "\n",
              "           target  \n",
              "count  178.000000  \n",
              "mean     0.938202  \n",
              "std      0.775035  \n",
              "min      0.000000  \n",
              "25%      0.000000  \n",
              "50%      1.000000  \n",
              "75%      2.000000  \n",
              "max      2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d002f00-6e7e-49cf-9ece-e506fcbb893a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.000618</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>746.893258</td>\n",
              "      <td>0.938202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.811827</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>314.907474</td>\n",
              "      <td>0.775035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.030000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.362500</td>\n",
              "      <td>1.602500</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.742500</td>\n",
              "      <td>1.205000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>3.220000</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>500.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.050000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>2.360000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>2.355000</td>\n",
              "      <td>2.135000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>1.555000</td>\n",
              "      <td>4.690000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>673.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.677500</td>\n",
              "      <td>3.082500</td>\n",
              "      <td>2.557500</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>985.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.830000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1680.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d002f00-6e7e-49cf-9ece-e506fcbb893a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d002f00-6e7e-49cf-9ece-e506fcbb893a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d002f00-6e7e-49cf-9ece-e506fcbb893a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = data.data\n",
        "output = data.target"
      ],
      "metadata": {
        "id": "C2P0hqZ9yBGm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = pd.DataFrame(input, columns = data.feature_names)"
      ],
      "metadata": {
        "id": "1l-KmA9V9QY5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardization 평균 0 / 분산 1\n",
        "scaler = StandardScaler()   \n",
        "scaler = scaler.fit_transform(input1)"
      ],
      "metadata": {
        "id": "qg54CwYN81d3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = input1.to_numpy()"
      ],
      "metadata": {
        "id": "lt42R6FB9dD0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 분석"
      ],
      "metadata": {
        "id": "NZ9eBL3Y6hrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == \"cuda\":\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "SggpQfSPt85C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(input, output, test_size = 0.3, random_state = 42, stratify= data.target, shuffle = True)\n",
        "\n",
        "x_train = torch.FloatTensor(x_train).to(device)\n",
        "y_train = torch.LongTensor(y_train).to(device)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "# 데이터를 tensor로 바꿔주고 gpu 연산이 가능해지도록 gpu에 옮김\n",
        "# label 값을 왜 long 에 옮겨놓는가? loss function이 다르기 때문 "
      ],
      "metadata": {
        "id": "bLMzf-2ntYeX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data.feature_names))\n",
        "print(data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZdHKpSka6l2",
        "outputId": "21b15158-3cee-4244-eace-590d498c394f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "['class_0' 'class_1' 'class_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])\n",
        "\n",
        "#input 13개 (속성이 13개)\n",
        "#y의 class는 3개 (class0, 1, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEdiTZkrVqS",
        "outputId": "36842ce9-cb00-4d78-f90c-8902b89e9116"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3750e+01, 1.7300e+00, 2.4100e+00, 1.6000e+01, 8.9000e+01, 2.6000e+00,\n",
            "        2.7600e+00, 2.9000e-01, 1.8100e+00, 5.6000e+00, 1.1500e+00, 2.9000e+00,\n",
            "        1.3200e+03], device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서는 데이터셋을 좀 더 쉽게 다룰 수 있도록 유용한 도구로서 torch.utils.data.Dataset과 torch.utils.data.DataLoader를 제공합니다. 이를 사용하면 미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리까지 간단히 수행할 수 있습니다. 기본적인 사용 방법은 Dataset을 정의하고, 이를 DataLoader에 전달하는 것\n",
        "- init : class 에서 객체가 생성되면 바로 실행되는 함수\n",
        "- len : observation 수를 정의하는 함수\n",
        "- getitem : iteration 마다 해당하는 데이터를 돌려주는 함수"
      ],
      "metadata": {
        "id": "combmxzmYFyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = x_train\n",
        "    self.y_data = [[y] for y in y_train]\n",
        "#  데이터셋의 전처리를 해주는 부분\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "#  데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx]).to(device)\n",
        "    y = torch.LongTensor(self.y_data[idx]).to(device)\n",
        "#  데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
        "\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "y38TlgXoqV5Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size) "
      ],
      "metadata": {
        "id": "x8VHwnuFqino"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(13,398, bias=True),\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(398,15, bias=True),\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(15,5, bias=True), \n",
        "          nn.Softmax()\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "C6V7a4tyq6Jc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class로 구현 가능\n",
        "- init : 초기 생성 함수\n",
        "- foward : 순전파(입력값 => 예측값 의 과정)"
      ],
      "metadata": {
        "id": "07uV8RY7Yr_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "          nn.Linear(13,398, bias=True), # input_layer = 30, hidden_layer1 = 398 \n",
        "          nn.Sigmoid(),\n",
        "        nn.BatchNorm1d(398)\n",
        "    )\n",
        "  # activation function 이용 \n",
        "  #   nn.ReLU()\n",
        "  #   nn.tanH()\n",
        "  #   https://pytorch.org/docs/stable/nn.html 그 외에도 여기서 확인 가능함 \n",
        "  #   파라미터가 필요하지 않다는 것이 특징\n",
        "\n",
        "  # batch normazliation 1d, 파라미터 값으로 vector의 길이를 전해줌\n",
        "  # 추후에 이미지를 다루게 된다면, 그때는 batch normalization 2d를 이용하게 됨 \n",
        "  # 그때는 파라미터 값으로 채널, 가로, 세로 길이를 전달해주게 됨 \n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "          nn.Linear(398,15, bias=True), # hidden_layer1 = 398, hidden_layer2 = 15\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "          nn.Linear(15,10, bias=True), # hidden_layer1 = 15, hidden_layer2 = 10\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(10, 5, bias=True), # hidden_layer3 = 10, output_layer = 5\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.layer1(x)\n",
        "    output = self.layer2(output)\n",
        "    output = self.layer3(output)\n",
        "    output = self.layer4(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "a0zLstbMqxEZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(layer.weight)\n",
        "        layer.bias.data.fill_(0.01)\n",
        "\n",
        "        #xavier사용\n",
        "        # Layer의 weight를 어떤 분포를 가지도록 초기화시켜줌+global minimum찾기 위해서"
      ],
      "metadata": {
        "id": "kqcqqkECrSGK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n",
        "- 기본 설정대로 진행"
      ],
      "metadata": {
        "id": "rK2gFIeLDkf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMDUBFg6rUpw",
        "outputId": "18a8743f-be2d-413d-8368-517e1e7bbd3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=13, out_features=398, bias=True)\n",
              "    (1): Sigmoid()\n",
              "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwZt5CetrYFb",
        "outputId": "ab433ad6-0763-42bd-91de-5d8133b5173b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (layer1): Sequential(\n",
            "    (0): Linear(in_features=13, out_features=398, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (1): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn  = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr= 0.01)\n",
        "\n",
        "# https://pytorch.org/docs/stable/optim.html#module-torch.optim 페이지 참조\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# sgd 등등"
      ],
      "metadata": {
        "id": "AYFp-eTErh7b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(100):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = loss_fn(hypothesis, y_train)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  losses.append(cost.item())\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90QxHvlIrjS7",
        "outputId": "47e29505-0ee7-4ce3-ad14-4dc7fe7b8ba0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.5411123037338257\n",
            "10 1.400137186050415\n",
            "20 1.2934082746505737\n",
            "30 1.2250208854675293\n",
            "40 1.1763157844543457\n",
            "50 1.1400551795959473\n",
            "60 1.0523244142532349\n",
            "70 0.9969934821128845\n",
            "80 0.9682345390319824\n",
            "90 0.9833006262779236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "81ASYrW7roFM",
        "outputId": "35c277a3-886c-4add-fc8f-6740ab6a4df2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model = model.to('cpu')\n",
        "  y_pred = model(x_test)\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  predicted = np.argmax(y_pred, axis =1)\n",
        "  accuracy = (accuracy_score(predicted, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4kJzpLErqhZ",
        "outputId": "2c75175e-e0d8-446c-b22e-576718289cc8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'model의 output은 :  {y_pred[0]}')\n",
        "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
        "print(f'accuracy는 {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyIKhs3Nr6Ay",
        "outputId": "9a12c00c-4c3b-4a30-b5f5-39513b053733"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model의 output은 :  [9.8827165e-01 5.7466161e-03 4.8704147e-03 6.5667066e-04 4.5466126e-04]\n",
            "argmax를 한 후의 output은 0\n",
            "accuracy는 0.9629629629629629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 \n",
        "acc 제일 높았음  \n",
        "\n",
        "\n",
        "- relu 사용해서 재시도\n",
        "- epoch 10배\n",
        "- hidden layer 수 변경\n",
        "- lr 변경\n",
        "- 뉴런 변경  \n",
        "\n",
        "을 시도했지만 대부분 원래 세팅된 값으로 돌렸을 때 acc가 높았음"
      ],
      "metadata": {
        "id": "XkCXgrSi-Ex6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model2(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model2, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "          nn.Linear(13,398, bias=True), # input_layer = 30, hidden_layer1 = 398 \n",
        "          nn.ReLU(),\n",
        "        nn.BatchNorm1d(398)\n",
        "    )\n",
        "  # activation function 이용 \n",
        "  #   nn.ReLU()\n",
        "  #   nn.tanH()\n",
        "  #   https://pytorch.org/docs/stable/nn.html 그 외에도 여기서 확인 가능함 \n",
        "  #   파라미터가 필요하지 않다는 것이 특징\n",
        "\n",
        "  # batch normazliation 1d, 파라미터 값으로 vector의 길이를 전해줌\n",
        "  # 추후에 이미지를 다루게 된다면, 그때는 batch normalization 2d를 이용하게 됨 \n",
        "  # 그때는 파라미터 값으로 채널, 가로, 세로 길이를 전달해주게 됨 \n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "          nn.Linear(398,15, bias=True), # hidden_layer1 = 398, hidden_layer2 = 15\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "          nn.Linear(15,10, bias=True), # hidden_layer1 = 15, hidden_layer2 = 10\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(10, 5, bias=True), # hidden_layer3 = 10, output_layer = 5\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.layer1(x)\n",
        "    output = self.layer2(output)\n",
        "    output = self.layer3(output)\n",
        "    output = self.layer4(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "GETsw1z7-PjO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(layer.weight)\n",
        "        layer.bias.data.fill_(0.01)\n",
        "\n",
        "        #xavier사용\n",
        "        # Layer의 weight를 어떤 분포를 가지도록 초기화시켜줌+global minimum찾기 위해서"
      ],
      "metadata": {
        "id": "lUCUalVn-PjQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Model2().to(device)\n",
        "model2.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1dab39-b64c-4945-dc7a-5dcdc699d7a9",
        "id": "4ZyyVpsJ-PjQ"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model2(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=13, out_features=398, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c36fa239-8d03-4311-f40a-283b4191bb47",
        "id": "Wj0tJngi-PjR"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model2(\n",
            "  (layer1): Sequential(\n",
            "    (0): Linear(in_features=13, out_features=398, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (1): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn  = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model2.parameters(), lr= 0.01)\n",
        "\n",
        "# https://pytorch.org/docs/stable/optim.html#module-torch.optim 페이지 참조\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# sgd 등등"
      ],
      "metadata": {
        "id": "Jwn9MGPX-PjS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(1000):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model2(x_train)\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = loss_fn(hypothesis, y_train)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  losses.append(cost.item())\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08db7cb7-7f25-486f-9438-535930871eb9",
        "id": "Mox-REcv-PjS"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.6192281246185303\n",
            "10 1.1452958583831787\n",
            "20 0.9822261929512024\n",
            "30 0.9523438811302185\n",
            "40 0.9446027874946594\n",
            "50 0.9384719133377075\n",
            "60 0.9374048113822937\n",
            "70 0.9367218017578125\n",
            "80 0.9366391897201538\n",
            "90 0.9366186857223511\n",
            "100 0.9366047382354736\n",
            "110 0.9365972280502319\n",
            "120 0.9365918636322021\n",
            "130 0.936587393283844\n",
            "140 0.936583399772644\n",
            "150 0.9365813136100769\n",
            "160 0.9365826845169067\n",
            "170 0.9365760087966919\n",
            "180 0.936569094657898\n",
            "190 0.9364068508148193\n",
            "200 0.9406071901321411\n",
            "210 0.9344013929367065\n",
            "220 0.9186819195747375\n",
            "230 0.9115817546844482\n",
            "240 0.9073490500450134\n",
            "250 0.9054253697395325\n",
            "260 0.904985249042511\n",
            "270 0.9049094319343567\n",
            "280 0.9048853516578674\n",
            "290 0.9048698544502258\n",
            "300 0.9048632979393005\n",
            "310 0.904858410358429\n",
            "320 0.9048619270324707\n",
            "330 0.9048599600791931\n",
            "340 0.9048572182655334\n",
            "350 0.9048545360565186\n",
            "360 0.9048523902893066\n",
            "370 0.9048507213592529\n",
            "380 0.9048494100570679\n",
            "390 0.9048482775688171\n",
            "400 0.9048472046852112\n",
            "410 0.9048463702201843\n",
            "420 0.9048457145690918\n",
            "430 0.904845118522644\n",
            "440 0.9048444628715515\n",
            "450 0.9048438668251038\n",
            "460 0.9048433899879456\n",
            "470 0.9048429727554321\n",
            "480 0.9048424959182739\n",
            "490 0.9048420786857605\n",
            "500 0.9048417210578918\n",
            "510 0.9048413634300232\n",
            "520 0.9048409461975098\n",
            "530 0.9048405885696411\n",
            "540 0.9048404097557068\n",
            "550 0.9048401713371277\n",
            "560 0.904839813709259\n",
            "570 0.9048396348953247\n",
            "580 0.904839277267456\n",
            "590 0.9048391580581665\n",
            "600 0.9048388600349426\n",
            "610 0.9048386216163635\n",
            "620 0.9048385620117188\n",
            "630 0.9048382639884949\n",
            "640 0.9048382043838501\n",
            "650 0.9048380851745605\n",
            "660 0.9048378467559814\n",
            "670 0.9048375487327576\n",
            "680 0.9048374891281128\n",
            "690 0.9048373103141785\n",
            "700 0.9048372507095337\n",
            "710 0.9048370718955994\n",
            "720 0.9048369526863098\n",
            "730 0.904836893081665\n",
            "740 0.9048367738723755\n",
            "750 0.9048365950584412\n",
            "760 0.9048365354537964\n",
            "770 0.9048364758491516\n",
            "780 0.9048364162445068\n",
            "790 0.9048363566398621\n",
            "800 0.9048362970352173\n",
            "810 0.9048360586166382\n",
            "820 0.9048360586166382\n",
            "830 0.9048359990119934\n",
            "840 0.9048359394073486\n",
            "850 0.9048358201980591\n",
            "860 0.9048357605934143\n",
            "870 0.9048357605934143\n",
            "880 0.9048356413841248\n",
            "890 0.9048355221748352\n",
            "900 0.9048354029655457\n",
            "910 0.9048352241516113\n",
            "920 0.9048351645469666\n",
            "930 0.9048351049423218\n",
            "940 0.904835045337677\n",
            "950 0.904835045337677\n",
            "960 0.904835045337677\n",
            "970 0.9048349857330322\n",
            "980 0.9048349261283875\n",
            "990 0.9048349261283875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "89a10c29-8307-40a8-8402-149af4f0ee66",
        "id": "ck1J1c_i-PjT"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model2 = model2.to('cpu')\n",
        "  y_pred = model2(x_test)\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  predicted = np.argmax(y_pred, axis =1)\n",
        "  accuracy = (accuracy_score(predicted, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2ffe5f-00db-4a80-a8b4-37b3d7ba8a2d",
        "id": "cJxCuw-x-PjT"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'model2의 output은 :  {y_pred[0]}')\n",
        "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
        "print(f'accuracy는 {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1da3962-58b2-486d-907b-4679ea7ac851",
        "id": "6QNbjbpN-PjU"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model2의 output은 :  [1.0000000e+00 1.4847962e-14 2.3642049e-10 2.0963995e-18 1.2646333e-17]\n",
            "argmax를 한 후의 output은 0\n",
            "accuracy는 0.9814814814814815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3\n",
        "- Model2에서 optimizer를 SGD로 변경"
      ],
      "metadata": {
        "id": "hE_O57ZkGNnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model3(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model3, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "          nn.Linear(13,398, bias=True), # input_layer = 30, hidden_layer1 = 398 \n",
        "          nn.ReLU(),\n",
        "        nn.BatchNorm1d(398)\n",
        "    )\n",
        "  # activation function 이용 \n",
        "  #   nn.ReLU()\n",
        "  #   nn.tanH()\n",
        "  #   https://pytorch.org/docs/stable/nn.html 그 외에도 여기서 확인 가능함 \n",
        "  #   파라미터가 필요하지 않다는 것이 특징\n",
        "\n",
        "  # batch normazliation 1d, 파라미터 값으로 vector의 길이를 전해줌\n",
        "  # 추후에 이미지를 다루게 된다면, 그때는 batch normalization 2d를 이용하게 됨 \n",
        "  # 그때는 파라미터 값으로 채널, 가로, 세로 길이를 전달해주게 됨 \n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "          nn.Linear(398,15, bias=True), # hidden_layer1 = 398, hidden_layer2 = 15\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "          nn.Linear(15,10, bias=True), # hidden_layer1 = 15, hidden_layer2 = 10\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(10, 5, bias=True), # hidden_layer3 = 10, output_layer = 5\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.layer1(x)\n",
        "    output = self.layer2(output)\n",
        "    output = self.layer3(output)\n",
        "    output = self.layer4(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "I7268_bNGYdQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(layer.weight)\n",
        "        layer.bias.data.fill_(0.01)\n",
        "\n",
        "        #xavier사용\n",
        "        # Layer의 weight를 어떤 분포를 가지도록 초기화시켜줌+global minimum찾기 위해서"
      ],
      "metadata": {
        "id": "WeHE3EYyGYdS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Model3().to(device)\n",
        "model3.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdc927f-0ad1-4a73-b0bc-9416b05ce4d9",
        "id": "X4R_odgkGYdT"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model3(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=13, out_features=398, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ea9237-a98e-4f03-db71-95d3d9a2c934",
        "id": "UArkbcs0GYdT"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model3(\n",
            "  (layer1): Sequential(\n",
            "    (0): Linear(in_features=13, out_features=398, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (1): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn  = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "optimizer = optim.SGD(model3.parameters(), lr= 0.01, momentum=0.99)\n",
        "\n",
        "# https://pytorch.org/docs/stable/optim.html#module-torch.optim 페이지 참조\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# sgd 등등"
      ],
      "metadata": {
        "id": "VpSW801LGYdU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(1000):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model3(x_train)\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = loss_fn(hypothesis, y_train)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  losses.append(cost.item())\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2dacdec-d79a-4ca4-b31a-80abc1bcdec6",
        "id": "fdEkyCBxGYdU"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.6506229639053345\n",
            "10 1.5077710151672363\n",
            "20 1.399988055229187\n",
            "30 1.275002121925354\n",
            "40 1.2204511165618896\n",
            "50 1.2166465520858765\n",
            "60 1.2158933877944946\n",
            "70 1.2155003547668457\n",
            "80 1.215567708015442\n",
            "90 1.2158291339874268\n",
            "100 1.215990424156189\n",
            "110 1.216381549835205\n",
            "120 1.216270089149475\n",
            "130 1.2163125276565552\n",
            "140 1.2163116931915283\n",
            "150 1.2162621021270752\n",
            "160 1.216143012046814\n",
            "170 1.216040849685669\n",
            "180 1.2158141136169434\n",
            "190 1.2155303955078125\n",
            "200 1.2150623798370361\n",
            "210 1.2146700620651245\n",
            "220 1.2139683961868286\n",
            "230 1.213379979133606\n",
            "240 1.2128294706344604\n",
            "250 1.2122492790222168\n",
            "260 1.2115869522094727\n",
            "270 1.2109845876693726\n",
            "280 1.2102727890014648\n",
            "290 1.209640383720398\n",
            "300 1.2088650465011597\n",
            "310 1.2080751657485962\n",
            "320 1.2073458433151245\n",
            "330 1.2069953680038452\n",
            "340 1.2068384885787964\n",
            "350 1.2060511112213135\n",
            "360 1.2047109603881836\n",
            "370 1.2039344310760498\n",
            "380 1.2035276889801025\n",
            "390 1.200097918510437\n",
            "400 1.2042386531829834\n",
            "410 1.2064063549041748\n",
            "420 1.2101269960403442\n",
            "430 1.212774634361267\n",
            "440 1.2147369384765625\n",
            "450 1.2155332565307617\n",
            "460 1.2163808345794678\n",
            "470 1.216713786125183\n",
            "480 1.216336727142334\n",
            "490 1.2158586978912354\n",
            "500 1.2150596380233765\n",
            "510 1.2133878469467163\n",
            "520 1.2107501029968262\n",
            "530 1.2081164121627808\n",
            "540 1.2064430713653564\n",
            "550 1.2054014205932617\n",
            "560 1.2046653032302856\n",
            "570 1.204144835472107\n",
            "580 1.2037923336029053\n",
            "590 1.203596591949463\n",
            "600 1.2034887075424194\n",
            "610 1.2034084796905518\n",
            "620 1.203353762626648\n",
            "630 1.2033179998397827\n",
            "640 1.2032941579818726\n",
            "650 1.203277349472046\n",
            "660 1.2032649517059326\n",
            "670 1.2032556533813477\n",
            "680 1.2032495737075806\n",
            "690 1.203244924545288\n",
            "700 1.2032411098480225\n",
            "710 1.2032381296157837\n",
            "720 1.2032355070114136\n",
            "730 1.2032331228256226\n",
            "740 1.2032314538955688\n",
            "750 1.2032297849655151\n",
            "760 1.2032285928726196\n",
            "770 1.2032275199890137\n",
            "780 1.2032266855239868\n",
            "790 1.20322585105896\n",
            "800 1.2032251358032227\n",
            "810 1.2032246589660645\n",
            "820 1.2032243013381958\n",
            "830 1.2032238245010376\n",
            "840 1.2032235860824585\n",
            "850 1.2032232284545898\n",
            "860 1.2032229900360107\n",
            "870 1.2032228708267212\n",
            "880 1.203222632408142\n",
            "890 1.2032225131988525\n",
            "900 1.203222393989563\n",
            "910 1.2032221555709839\n",
            "920 1.2032220363616943\n",
            "930 1.2032219171524048\n",
            "940 1.2032219171524048\n",
            "950 1.2032217979431152\n",
            "960 1.2032216787338257\n",
            "970 1.2032216787338257\n",
            "980 1.2032216787338257\n",
            "990 1.2032215595245361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "aeac634b-33c0-4ebb-8d84-7e0ad71762b8",
        "id": "_aBTk0SrGYdU"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model3 = model3.to('cpu')\n",
        "  y_pred = model3(x_test)\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  predicted = np.argmax(y_pred, axis =1)\n",
        "  accuracy = (accuracy_score(predicted, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc135ae-9ba7-42b2-b87a-774d37c963d0",
        "id": "cVuFzL3BGYdV"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'model3의 output은 :  {y_pred[0]}')\n",
        "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
        "print(f'accuracy는 {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1d21c0-362c-41e5-f8de-0bc47bcfdc87",
        "id": "XplnUgD_GYdV"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model3의 output은 :  [1. 0. 0. 0. 0.]\n",
            "argmax를 한 후의 output은 0\n",
            "accuracy는 0.7037037037037037\n"
          ]
        }
      ]
    }
  ]
}