{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차 과제_정영희",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "94bH27VkHCmn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SL1X212mWl5K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset을 임의로 선정해서 직접 분석 해보기(제공한 코드를 활용해서 해보기)\\\n",
        "activation functions 중 relu사용시 함수 직접 정의\\\n",
        "lr, optimizer 등 바꿔보기\\\n",
        "hidden layer/neuron 수를 바꾸기\\\n",
        "전처리도 추가\\\n",
        "모든 시도를 올려주세요!\\\n",
        "제일 높은 acc를 보인 시도를 명시해주세요"
      ],
      "metadata": {
        "id": "iN__1XDVIQOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터 확인"
      ],
      "metadata": {
        "id": "EYb-S4rSeJTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "#https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset"
      ],
      "metadata": {
        "id": "co_9haIzHw4Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 확인 -> numeric 30개\n",
        "print(data.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PimJQ_pXkum",
        "outputId": "cefe4906-3bb3-47dd-a0f1-5194cac87f72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = data.data\n",
        "output = data.target"
      ],
      "metadata": {
        "id": "6YZvZ0rxIIsU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature = data.feature_names"
      ],
      "metadata": {
        "id": "ZBlR11U5fOkk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data = input, columns = feature)\n",
        "df['label'] = output\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "59eBauOVffU-",
        "outputId": "7c4735a7-c096-4a8d-c4d6-26ebfbc484b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                   0.07871  ...          17.33           184.60      2019.0   \n",
              "1                   0.05667  ...          23.41           158.80      1956.0   \n",
              "2                   0.05999  ...          25.53           152.50      1709.0   \n",
              "3                   0.09744  ...          26.50            98.87       567.7   \n",
              "4                   0.05883  ...          16.67           152.20      1575.0   \n",
              "..                      ...  ...            ...              ...         ...   \n",
              "564                 0.05623  ...          26.40           166.10      2027.0   \n",
              "565                 0.05533  ...          38.25           155.00      1731.0   \n",
              "566                 0.05648  ...          34.12           126.70      1124.0   \n",
              "567                 0.07016  ...          39.42           184.60      1821.0   \n",
              "568                 0.05884  ...          30.37            59.16       268.6   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "0             0.16220            0.66560           0.7119   \n",
              "1             0.12380            0.18660           0.2416   \n",
              "2             0.14440            0.42450           0.4504   \n",
              "3             0.20980            0.86630           0.6869   \n",
              "4             0.13740            0.20500           0.4000   \n",
              "..                ...                ...              ...   \n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
              "0                  0.2654          0.4601                  0.11890      0  \n",
              "1                  0.1860          0.2750                  0.08902      0  \n",
              "2                  0.2430          0.3613                  0.08758      0  \n",
              "3                  0.2575          0.6638                  0.17300      0  \n",
              "4                  0.1625          0.2364                  0.07678      0  \n",
              "..                    ...             ...                      ...    ...  \n",
              "564                0.2216          0.2060                  0.07115      0  \n",
              "565                0.1628          0.2572                  0.06637      0  \n",
              "566                0.1418          0.2218                  0.07820      0  \n",
              "567                0.2650          0.4087                  0.12400      0  \n",
              "568                0.0000          0.2871                  0.07039      1  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-314aca09-e635-4976-91e5-47b6e9aca9a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-314aca09-e635-4976-91e5-47b6e9aca9a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-314aca09-e635-4976-91e5-47b6e9aca9a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-314aca09-e635-4976-91e5-47b6e9aca9a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "sM6Z3nWDWVhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "#와 결측치 없당"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM_JdUd_rcnu",
        "outputId": "f5705cbf-95a1-4bc3-9fd2-1c73218cc4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "label                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scale_input = pd.DataFrame(input, columns = feature)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit_transform(input)"
      ],
      "metadata": {
        "id": "HMFRpjmtve_d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling한 데이터: scale_df\n",
        "scale_df = pd.DataFrame(data = scaler, columns = feature)\n",
        "scale_df['label'] = output\n",
        "scale_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "Rnp7ODyWw_g0",
        "outputId": "4212d130-ed58-43bf-ace2-4d0b8be71400"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0       1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
              "1       1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
              "2       1.579888      0.456187        1.566503   1.558884         0.942210   \n",
              "3      -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
              "4       1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564     2.110995      0.721473        2.060786   2.343856         1.041842   \n",
              "565     1.704854      2.085134        1.615931   1.723842         0.102458   \n",
              "566     0.702284      2.045574        0.672676   0.577953        -0.840484   \n",
              "567     1.838341      2.336457        1.982524   1.735218         1.525767   \n",
              "568    -1.808401      1.221792       -1.814389  -1.347789        -3.112085   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0            3.283515        2.652874             2.532475       2.217515   \n",
              "1           -0.487072       -0.023846             0.548144       0.001392   \n",
              "2            1.052926        1.363478             2.037231       0.939685   \n",
              "3            3.402909        1.915897             1.451707       2.867383   \n",
              "4            0.539340        1.371011             1.428493      -0.009560   \n",
              "..                ...             ...                  ...            ...   \n",
              "564          0.219060        1.947285             2.320965      -0.312589   \n",
              "565         -0.017833        0.693043             1.263669      -0.217664   \n",
              "566         -0.038680        0.046588             0.105777      -0.809117   \n",
              "567          3.272144        3.296944             2.658866       2.137194   \n",
              "568         -1.150752       -1.114873            -1.261820      -0.820070   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                  2.255747  ...      -1.359293         2.303601    2.001237   \n",
              "1                 -0.868652  ...      -0.369203         1.535126    1.890489   \n",
              "2                 -0.398008  ...      -0.023974         1.347475    1.456285   \n",
              "3                  4.910919  ...       0.133984        -0.249939   -0.550021   \n",
              "4                 -0.562450  ...      -1.466770         1.338539    1.220724   \n",
              "..                      ...  ...            ...              ...         ...   \n",
              "564               -0.931027  ...       0.117700         1.752563    2.015301   \n",
              "565               -1.058611  ...       2.047399         1.421940    1.494959   \n",
              "566               -0.895587  ...       1.374854         0.579001    0.427906   \n",
              "567                1.043695  ...       2.237926         2.303601    1.653171   \n",
              "568               -0.561032  ...       0.764190        -1.432735   -1.075813   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "0            1.307686           2.616665         2.109526   \n",
              "1           -0.375612          -0.430444        -0.146749   \n",
              "2            0.527407           1.082932         0.854974   \n",
              "3            3.394275           3.893397         1.989588   \n",
              "4            0.220556          -0.313395         0.613179   \n",
              "..                ...                ...              ...   \n",
              "564          0.378365          -0.273318         0.664512   \n",
              "565         -0.691230          -0.394820         0.236573   \n",
              "566         -0.809587           0.350735         0.326767   \n",
              "567          1.430427           3.904848         3.197605   \n",
              "568         -1.859019          -1.207552        -1.305831   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
              "0                2.296076        2.750622                 1.937015      0  \n",
              "1                1.087084       -0.243890                 0.281190      0  \n",
              "2                1.955000        1.152255                 0.201391      0  \n",
              "3                2.175786        6.046041                 4.935010      0  \n",
              "4                0.729259       -0.868353                -0.397100      0  \n",
              "..                    ...             ...                      ...    ...  \n",
              "564              1.629151       -1.360158                -0.709091      0  \n",
              "565              0.733827       -0.531855                -0.973978      0  \n",
              "566              0.414069       -1.104549                -0.318409      0  \n",
              "567              2.289985        1.919083                 2.219635      0  \n",
              "568             -1.745063       -0.048138                -0.751207      1  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-851fbc5a-0adc-4ed3-8b18-8993b6255dcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.097064</td>\n",
              "      <td>-2.073335</td>\n",
              "      <td>1.269934</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>1.568466</td>\n",
              "      <td>3.283515</td>\n",
              "      <td>2.652874</td>\n",
              "      <td>2.532475</td>\n",
              "      <td>2.217515</td>\n",
              "      <td>2.255747</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.359293</td>\n",
              "      <td>2.303601</td>\n",
              "      <td>2.001237</td>\n",
              "      <td>1.307686</td>\n",
              "      <td>2.616665</td>\n",
              "      <td>2.109526</td>\n",
              "      <td>2.296076</td>\n",
              "      <td>2.750622</td>\n",
              "      <td>1.937015</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.829821</td>\n",
              "      <td>-0.353632</td>\n",
              "      <td>1.685955</td>\n",
              "      <td>1.908708</td>\n",
              "      <td>-0.826962</td>\n",
              "      <td>-0.487072</td>\n",
              "      <td>-0.023846</td>\n",
              "      <td>0.548144</td>\n",
              "      <td>0.001392</td>\n",
              "      <td>-0.868652</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.369203</td>\n",
              "      <td>1.535126</td>\n",
              "      <td>1.890489</td>\n",
              "      <td>-0.375612</td>\n",
              "      <td>-0.430444</td>\n",
              "      <td>-0.146749</td>\n",
              "      <td>1.087084</td>\n",
              "      <td>-0.243890</td>\n",
              "      <td>0.281190</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.579888</td>\n",
              "      <td>0.456187</td>\n",
              "      <td>1.566503</td>\n",
              "      <td>1.558884</td>\n",
              "      <td>0.942210</td>\n",
              "      <td>1.052926</td>\n",
              "      <td>1.363478</td>\n",
              "      <td>2.037231</td>\n",
              "      <td>0.939685</td>\n",
              "      <td>-0.398008</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023974</td>\n",
              "      <td>1.347475</td>\n",
              "      <td>1.456285</td>\n",
              "      <td>0.527407</td>\n",
              "      <td>1.082932</td>\n",
              "      <td>0.854974</td>\n",
              "      <td>1.955000</td>\n",
              "      <td>1.152255</td>\n",
              "      <td>0.201391</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.768909</td>\n",
              "      <td>0.253732</td>\n",
              "      <td>-0.592687</td>\n",
              "      <td>-0.764464</td>\n",
              "      <td>3.283553</td>\n",
              "      <td>3.402909</td>\n",
              "      <td>1.915897</td>\n",
              "      <td>1.451707</td>\n",
              "      <td>2.867383</td>\n",
              "      <td>4.910919</td>\n",
              "      <td>...</td>\n",
              "      <td>0.133984</td>\n",
              "      <td>-0.249939</td>\n",
              "      <td>-0.550021</td>\n",
              "      <td>3.394275</td>\n",
              "      <td>3.893397</td>\n",
              "      <td>1.989588</td>\n",
              "      <td>2.175786</td>\n",
              "      <td>6.046041</td>\n",
              "      <td>4.935010</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.750297</td>\n",
              "      <td>-1.151816</td>\n",
              "      <td>1.776573</td>\n",
              "      <td>1.826229</td>\n",
              "      <td>0.280372</td>\n",
              "      <td>0.539340</td>\n",
              "      <td>1.371011</td>\n",
              "      <td>1.428493</td>\n",
              "      <td>-0.009560</td>\n",
              "      <td>-0.562450</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.466770</td>\n",
              "      <td>1.338539</td>\n",
              "      <td>1.220724</td>\n",
              "      <td>0.220556</td>\n",
              "      <td>-0.313395</td>\n",
              "      <td>0.613179</td>\n",
              "      <td>0.729259</td>\n",
              "      <td>-0.868353</td>\n",
              "      <td>-0.397100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>2.110995</td>\n",
              "      <td>0.721473</td>\n",
              "      <td>2.060786</td>\n",
              "      <td>2.343856</td>\n",
              "      <td>1.041842</td>\n",
              "      <td>0.219060</td>\n",
              "      <td>1.947285</td>\n",
              "      <td>2.320965</td>\n",
              "      <td>-0.312589</td>\n",
              "      <td>-0.931027</td>\n",
              "      <td>...</td>\n",
              "      <td>0.117700</td>\n",
              "      <td>1.752563</td>\n",
              "      <td>2.015301</td>\n",
              "      <td>0.378365</td>\n",
              "      <td>-0.273318</td>\n",
              "      <td>0.664512</td>\n",
              "      <td>1.629151</td>\n",
              "      <td>-1.360158</td>\n",
              "      <td>-0.709091</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1.704854</td>\n",
              "      <td>2.085134</td>\n",
              "      <td>1.615931</td>\n",
              "      <td>1.723842</td>\n",
              "      <td>0.102458</td>\n",
              "      <td>-0.017833</td>\n",
              "      <td>0.693043</td>\n",
              "      <td>1.263669</td>\n",
              "      <td>-0.217664</td>\n",
              "      <td>-1.058611</td>\n",
              "      <td>...</td>\n",
              "      <td>2.047399</td>\n",
              "      <td>1.421940</td>\n",
              "      <td>1.494959</td>\n",
              "      <td>-0.691230</td>\n",
              "      <td>-0.394820</td>\n",
              "      <td>0.236573</td>\n",
              "      <td>0.733827</td>\n",
              "      <td>-0.531855</td>\n",
              "      <td>-0.973978</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0.702284</td>\n",
              "      <td>2.045574</td>\n",
              "      <td>0.672676</td>\n",
              "      <td>0.577953</td>\n",
              "      <td>-0.840484</td>\n",
              "      <td>-0.038680</td>\n",
              "      <td>0.046588</td>\n",
              "      <td>0.105777</td>\n",
              "      <td>-0.809117</td>\n",
              "      <td>-0.895587</td>\n",
              "      <td>...</td>\n",
              "      <td>1.374854</td>\n",
              "      <td>0.579001</td>\n",
              "      <td>0.427906</td>\n",
              "      <td>-0.809587</td>\n",
              "      <td>0.350735</td>\n",
              "      <td>0.326767</td>\n",
              "      <td>0.414069</td>\n",
              "      <td>-1.104549</td>\n",
              "      <td>-0.318409</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1.838341</td>\n",
              "      <td>2.336457</td>\n",
              "      <td>1.982524</td>\n",
              "      <td>1.735218</td>\n",
              "      <td>1.525767</td>\n",
              "      <td>3.272144</td>\n",
              "      <td>3.296944</td>\n",
              "      <td>2.658866</td>\n",
              "      <td>2.137194</td>\n",
              "      <td>1.043695</td>\n",
              "      <td>...</td>\n",
              "      <td>2.237926</td>\n",
              "      <td>2.303601</td>\n",
              "      <td>1.653171</td>\n",
              "      <td>1.430427</td>\n",
              "      <td>3.904848</td>\n",
              "      <td>3.197605</td>\n",
              "      <td>2.289985</td>\n",
              "      <td>1.919083</td>\n",
              "      <td>2.219635</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>-1.808401</td>\n",
              "      <td>1.221792</td>\n",
              "      <td>-1.814389</td>\n",
              "      <td>-1.347789</td>\n",
              "      <td>-3.112085</td>\n",
              "      <td>-1.150752</td>\n",
              "      <td>-1.114873</td>\n",
              "      <td>-1.261820</td>\n",
              "      <td>-0.820070</td>\n",
              "      <td>-0.561032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.764190</td>\n",
              "      <td>-1.432735</td>\n",
              "      <td>-1.075813</td>\n",
              "      <td>-1.859019</td>\n",
              "      <td>-1.207552</td>\n",
              "      <td>-1.305831</td>\n",
              "      <td>-1.745063</td>\n",
              "      <td>-0.048138</td>\n",
              "      <td>-0.751207</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-851fbc5a-0adc-4ed3-8b18-8993b6255dcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-851fbc5a-0adc-4ed3-8b18-8993b6255dcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-851fbc5a-0adc-4ed3-8b18-8993b6255dcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == \"cuda\":\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "0q-xEnVpIM1f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(scaler, output, test_size = 0.3, random_state = 42, stratify= data.target, shuffle = True)\n",
        "\n",
        "x_train = torch.FloatTensor(x_train).to(device) # 데이터를 tensor로 바꿔주고 gpu 연산이 가능해지도록 gpu에 옮김\n",
        "y_train = torch.LongTensor(y_train).to(device)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.LongTensor(y_test) # label -> long(64비트 정수) 에 옮겨놓는가? loss function이 다르기 때문\n"
      ],
      "metadata": {
        "id": "3UmBnxr-Id8Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])\n",
        "# input = 30개\n",
        "# label 2개(positive/negative) 1.0으로 분리"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWt6mPT0IfcV",
        "outputId": "a561c958-3459-4509-f054-786298eb6cab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7121, -0.2582, -0.6421, -0.6999,  1.5044,  0.8331,  0.1657,  0.1734,\n",
            "         0.5308,  1.3825,  0.0178,  0.9492,  0.0797, -0.2747,  2.5164,  0.3679,\n",
            "         0.5874,  1.0728, -0.2993,  0.5379, -0.6024, -0.0451, -0.5695, -0.6196,\n",
            "         2.0003,  0.2133,  0.2227,  0.4110, -0.3895,  0.4851])\n",
            "tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(feature))\n",
        "print(data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4duUuVcozNbM",
        "outputId": "19458c5e-d25d-41f3-9924-d59738e3cc26"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "['malignant' 'benign']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.utils.data.Dataset과 torch.utils.data.DataLoader\n",
        "-> 미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리까지 간단히 수행할 수 있습니다. 기본적인 사용 방법은 Dataset을 정의하고, 이를 DataLoader에 전달하는 것\n",
        "\n",
        "init : class 에서 객체가 생성되면 바로 실행되는 함수\\\n",
        "len : observation 수를 정의하는 함수\\\n",
        "getitem : iteration 마다 해당하는 데이터를 돌려주는 함수"
      ],
      "metadata": {
        "id": "AXO4SN_IK-a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#customDataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "#데이터 전처리\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = x_train\n",
        "    self.y_data = [[y] for y in y_train]\n",
        "\n",
        "#데이터 셋의 길이(총 샘플의 수)\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "#데이터 셋에서 특정 1개의 샘플을 가져오는 함수\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx]).to(device)\n",
        "    y = torch.LongTensor(self.y_data[idx]).to(device)\n",
        "\n",
        "    return x,y\n",
        "\n",
        "#https://wikidocs.net/57165"
      ],
      "metadata": {
        "id": "3j-JC90_Lk3p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size)"
      ],
      "metadata": {
        "id": "VkQHfz8gN18T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Sequential(코드 간단히 해줌)\n",
        "#다층 퍼셉트론 구현: 출력은 Sigmoid를 거친다\n",
        "model = nn.Sequential(\n",
        "          nn.Linear(30, 398, bias = True),\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(398, 15, bias = True),\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(15, 5, bias = True),\n",
        "          nn.Softmax() #Q. 마지막에 softmax는 먼가용?\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "3sKLOImLOjQ1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#activation function\n",
        "def relu(x):\n",
        "    a = torch.zeros_like(x)\n",
        "    return torch.max(x, a)"
      ],
      "metadata": {
        "id": "b1DhzoHZXvw9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(30, 398, bias = True),\n",
        "        nn.Sigmoid(),\n",
        "      nn.BatchNorm1d(398)\n",
        "    )\n",
        "\n",
        "#activation function\n",
        "# m = nn.ReLU()\n",
        "# input = torch.randn(2)\n",
        "# output = m(input)\n",
        "\n",
        "# batch normazliation 1d, 파라미터 값으로 vector의 길이를 전해줌\n",
        "  # 추후에 이미지를 다루게 된다면, 그때는 batch normalization 2d를 이용하게 됨 \n",
        "  # 그때는 파라미터 값으로 채널, 가로, 세로 길이를 전달해주게 됨 \n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "          nn.Linear(398,15, bias=True), # hidden_layer1 = 398, hidden_layer2 = 15\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "          nn.Linear(15,10, bias=True), # hidden_layer1 = 15, hidden_layer2 = 10\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(10, 5, bias=True), # hidden_layer3 = 10, output_layer = 5\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = self.layer1(x)\n",
        "    output = relu(output)\n",
        "\n",
        "    output = self.layer2(output)\n",
        "    output = relu(output)\n",
        "\n",
        "    output = self.layer3(output)\n",
        "    output = relu(output)\n",
        "\n",
        "    output = self.layer4(output)\n",
        "    output = relu(output)\n",
        "  \n",
        "    return output"
      ],
      "metadata": {
        "id": "WBMP9ybhaO2m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://wikidocs.net/61271\n",
        "#weight initialization\n",
        "def init_weights(layer):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        torch.nn.init.kaiming_uniform(layer.weight)\n",
        "        layer.bias.data.fill_(0.01)\n",
        "\n",
        "        #he사용: Relu함수 사용 시 kaiming(He) initialization이 효율적임\n",
        "        # Layer의 weight를 어떤 분포를 가지도록 초기화시켜줌+global minimum찾기 위해서"
      ],
      "metadata": {
        "id": "kYFn24OpbvcJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dt7VA73bxKx",
        "outputId": "4654c13e-7997-4890-e2b1-5871c5d9bb37"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer1): Sequential(\n",
              "    (0): Linear(in_features=30, out_features=398, bias=True)\n",
              "    (1): Sigmoid()\n",
              "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (1): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNwgeRY_byg9",
        "outputId": "ede7e316-d18a-4bf5-d18e-9451241af687"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (layer1): Sequential(\n",
            "    (0): Linear(in_features=30, out_features=398, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): BatchNorm1d(398, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Linear(in_features=398, out_features=15, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=15, out_features=10, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
            "    (1): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn  = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr= 0.01)\n",
        "\n",
        "#https://dbstndi6316.tistory.com/297"
      ],
      "metadata": {
        "id": "_D9drfUWe_m_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(100):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  # 비용 함수\n",
        "  cost = loss_fn(hypothesis, y_train)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  losses.append(cost.item())\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(epoch, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYKyrHoAfAiX",
        "outputId": "894a19d7-f494-443c-a17b-cce2ff0ff88c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.7128183841705322\n",
            "10 1.3174740076065063\n",
            "20 1.1272753477096558\n",
            "30 1.0133112668991089\n",
            "40 0.966148853302002\n",
            "50 0.9460715055465698\n",
            "60 0.9361539483070374\n",
            "70 0.926556408405304\n",
            "80 0.9225611090660095\n",
            "90 0.9200827479362488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SzALzEzTfC9k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "06e02dcf-cf60-4da7-a29f-7afa397231a3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model = model.to('cpu')\n",
        "  y_pred = model(x_test)\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  predicted = np.argmax(y_pred, axis =1)\n",
        "  accuracy = (accuracy_score(predicted, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCvk-VF8fF-y",
        "outputId": "623276f6-31db-4ab0-bd3f-2ecc70bd191a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'model의 output은 :  {y_pred[0]}')\n",
        "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
        "print(f'accuracy는 {accuracy}')"
      ],
      "metadata": {
        "id": "9I3ggOj2fGr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0911a204-161b-439f-9f7b-003f67275be4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model의 output은 :  [9.80224371e-01 1.08129075e-02 3.75065603e-03 7.43000011e-04\n",
            " 4.46909573e-03]\n",
            "argmax를 한 후의 output은 0\n",
            "accuracy는 0.9590643274853801\n"
          ]
        }
      ]
    }
  ]
}