{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7주차_과제_반민정.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nmQ5F7UAeKB_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task1\n",
        "\n",
        "빈 칸을 채워주세요!\n",
        "\n",
        "단계별 output이 github 파일에는 남아있으니 그 output과 동일한 형태인지 확인하면서 진행해주시면 됩니다~"
      ],
      "metadata": {
        "id": "Sgxd6SxmeVcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "sentence = (\"Brick walls are there for a reason and you must not think \"\n",
        "            \"that the brick walls aren't there to keep us out, but rather \"\n",
        "            \"in this way that the brick walls are there to show us how badly we want things.\")"
      ],
      "metadata": {
        "id": "NDvUeC8BoUb6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {}\n",
        "for i in range(len(world_set)):\n",
        "  vocab[world_set[i]] = i"
      ],
      "metadata": {
        "id": "b9lkrKyZf8ie"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0we5Y-gYDq",
        "outputId": "0100178e-ddc6-41ee-e41d-3e7b999575b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 0, 'c': 1, 'r': 2, 'w': 3, 'k': 4, 'y': 5, 'b': 6, 'o': 7, 'B': 8, 'e': 9, 'l': 10, \"'\": 11, 's': 12, 'h': 13, 'p': 14, 'g': 15, 'n': 16, '.': 17, ',': 18, 'u': 19, 'f': 20, 't': 21, ' ': 22, 'a': 23, 'm': 24, 'd': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpKupU6lgpfT",
        "outputId": "23526172-21a5-465e-a5de-bbee9c525d99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
        "\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 10  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "wFDZJHSMg9In"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i:i+sequence_length]\n",
        "  y_str = sentence[i+1: i+sequence_length+1]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbDcmJmghN7V",
        "outputId": "d39f8b8e-76d6-4094-c028-314068ace0a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Brick wall -> rick walls\n",
            "1 rick walls -> ick walls \n",
            "2 ick walls  -> ck walls a\n",
            "3 ck walls a -> k walls ar\n",
            "4 k walls ar ->  walls are\n",
            "5  walls are -> walls are \n",
            "6 walls are  -> alls are t\n",
            "7 alls are t -> lls are th\n",
            "8 lls are th -> ls are the\n",
            "9 ls are the -> s are ther\n",
            "10 s are ther ->  are there\n",
            "11  are there -> are there \n",
            "12 are there  -> re there f\n",
            "13 re there f -> e there fo\n",
            "14 e there fo ->  there for\n",
            "15  there for -> there for \n",
            "16 there for  -> here for a\n",
            "17 here for a -> ere for a \n",
            "18 ere for a  -> re for a r\n",
            "19 re for a r -> e for a re\n",
            "20 e for a re ->  for a rea\n",
            "21  for a rea -> for a reas\n",
            "22 for a reas -> or a reaso\n",
            "23 or a reaso -> r a reason\n",
            "24 r a reason ->  a reason \n",
            "25  a reason  -> a reason a\n",
            "26 a reason a ->  reason an\n",
            "27  reason an -> reason and\n",
            "28 reason and -> eason and \n",
            "29 eason and  -> ason and y\n",
            "30 ason and y -> son and yo\n",
            "31 son and yo -> on and you\n",
            "32 on and you -> n and you \n",
            "33 n and you  ->  and you m\n",
            "34  and you m -> and you mu\n",
            "35 and you mu -> nd you mus\n",
            "36 nd you mus -> d you must\n",
            "37 d you must ->  you must \n",
            "38  you must  -> you must n\n",
            "39 you must n -> ou must no\n",
            "40 ou must no -> u must not\n",
            "41 u must not ->  must not \n",
            "42  must not  -> must not t\n",
            "43 must not t -> ust not th\n",
            "44 ust not th -> st not thi\n",
            "45 st not thi -> t not thin\n",
            "46 t not thin ->  not think\n",
            "47  not think -> not think \n",
            "48 not think  -> ot think t\n",
            "49 ot think t -> t think th\n",
            "50 t think th ->  think tha\n",
            "51  think tha -> think that\n",
            "52 think that -> hink that \n",
            "53 hink that  -> ink that t\n",
            "54 ink that t -> nk that th\n",
            "55 nk that th -> k that the\n",
            "56 k that the ->  that the \n",
            "57  that the  -> that the b\n",
            "58 that the b -> hat the br\n",
            "59 hat the br -> at the bri\n",
            "60 at the bri -> t the bric\n",
            "61 t the bric ->  the brick\n",
            "62  the brick -> the brick \n",
            "63 the brick  -> he brick w\n",
            "64 he brick w -> e brick wa\n",
            "65 e brick wa ->  brick wal\n",
            "66  brick wal -> brick wall\n",
            "67 brick wall -> rick walls\n",
            "68 rick walls -> ick walls \n",
            "69 ick walls  -> ck walls a\n",
            "70 ck walls a -> k walls ar\n",
            "71 k walls ar ->  walls are\n",
            "72  walls are -> walls aren\n",
            "73 walls aren -> alls aren'\n",
            "74 alls aren' -> lls aren't\n",
            "75 lls aren't -> ls aren't \n",
            "76 ls aren't  -> s aren't t\n",
            "77 s aren't t ->  aren't th\n",
            "78  aren't th -> aren't the\n",
            "79 aren't the -> ren't ther\n",
            "80 ren't ther -> en't there\n",
            "81 en't there -> n't there \n",
            "82 n't there  -> 't there t\n",
            "83 't there t -> t there to\n",
            "84 t there to ->  there to \n",
            "85  there to  -> there to k\n",
            "86 there to k -> here to ke\n",
            "87 here to ke -> ere to kee\n",
            "88 ere to kee -> re to keep\n",
            "89 re to keep -> e to keep \n",
            "90 e to keep  ->  to keep u\n",
            "91  to keep u -> to keep us\n",
            "92 to keep us -> o keep us \n",
            "93 o keep us  ->  keep us o\n",
            "94  keep us o -> keep us ou\n",
            "95 keep us ou -> eep us out\n",
            "96 eep us out -> ep us out,\n",
            "97 ep us out, -> p us out, \n",
            "98 p us out,  ->  us out, b\n",
            "99  us out, b -> us out, bu\n",
            "100 us out, bu -> s out, but\n",
            "101 s out, but ->  out, but \n",
            "102  out, but  -> out, but r\n",
            "103 out, but r -> ut, but ra\n",
            "104 ut, but ra -> t, but rat\n",
            "105 t, but rat -> , but rath\n",
            "106 , but rath ->  but rathe\n",
            "107  but rathe -> but rather\n",
            "108 but rather -> ut rather \n",
            "109 ut rather  -> t rather i\n",
            "110 t rather i ->  rather in\n",
            "111  rather in -> rather in \n",
            "112 rather in  -> ather in t\n",
            "113 ather in t -> ther in th\n",
            "114 ther in th -> her in thi\n",
            "115 her in thi -> er in this\n",
            "116 er in this -> r in this \n",
            "117 r in this  ->  in this w\n",
            "118  in this w -> in this wa\n",
            "119 in this wa -> n this way\n",
            "120 n this way ->  this way \n",
            "121  this way  -> this way t\n",
            "122 this way t -> his way th\n",
            "123 his way th -> is way tha\n",
            "124 is way tha -> s way that\n",
            "125 s way that ->  way that \n",
            "126  way that  -> way that t\n",
            "127 way that t -> ay that th\n",
            "128 ay that th -> y that the\n",
            "129 y that the ->  that the \n",
            "130  that the  -> that the b\n",
            "131 that the b -> hat the br\n",
            "132 hat the br -> at the bri\n",
            "133 at the bri -> t the bric\n",
            "134 t the bric ->  the brick\n",
            "135  the brick -> the brick \n",
            "136 the brick  -> he brick w\n",
            "137 he brick w -> e brick wa\n",
            "138 e brick wa ->  brick wal\n",
            "139  brick wal -> brick wall\n",
            "140 brick wall -> rick walls\n",
            "141 rick walls -> ick walls \n",
            "142 ick walls  -> ck walls a\n",
            "143 ck walls a -> k walls ar\n",
            "144 k walls ar ->  walls are\n",
            "145  walls are -> walls are \n",
            "146 walls are  -> alls are t\n",
            "147 alls are t -> lls are th\n",
            "148 lls are th -> ls are the\n",
            "149 ls are the -> s are ther\n",
            "150 s are ther ->  are there\n",
            "151  are there -> are there \n",
            "152 are there  -> re there t\n",
            "153 re there t -> e there to\n",
            "154 e there to ->  there to \n",
            "155  there to  -> there to s\n",
            "156 there to s -> here to sh\n",
            "157 here to sh -> ere to sho\n",
            "158 ere to sho -> re to show\n",
            "159 re to show -> e to show \n",
            "160 e to show  ->  to show u\n",
            "161  to show u -> to show us\n",
            "162 to show us -> o show us \n",
            "163 o show us  ->  show us h\n",
            "164  show us h -> show us ho\n",
            "165 show us ho -> how us how\n",
            "166 how us how -> ow us how \n",
            "167 ow us how  -> w us how b\n",
            "168 w us how b ->  us how ba\n",
            "169  us how ba -> us how bad\n",
            "170 us how bad -> s how badl\n",
            "171 s how badl ->  how badly\n",
            "172  how badly -> how badly \n",
            "173 how badly  -> ow badly w\n",
            "174 ow badly w -> w badly we\n",
            "175 w badly we ->  badly we \n",
            "176  badly we  -> badly we w\n",
            "177 badly we w -> adly we wa\n",
            "178 adly we wa -> dly we wan\n",
            "179 dly we wan -> ly we want\n",
            "180 ly we want -> y we want \n",
            "181 y we want  ->  we want t\n",
            "182  we want t -> we want th\n",
            "183 we want th -> e want thi\n",
            "184 e want thi ->  want thin\n",
            "185  want thin -> want thing\n",
            "186 want thing -> ant things\n",
            "187 ant things -> nt things.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
        "\n",
        "print(type(x_data))\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVFlILiOixdc",
        "outputId": "688de2ac-4f13-466e-b275-5c9e67748efe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "[2, 0, 1, 4, 22, 3, 23, 10, 10, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor: 32비트 부동소수점, LongTesor: 64비트 정수(부호있음) 중 맞는 것은?)\n",
        "X = torch.FloatTensor(x_one_hot) #연산\n",
        "Y = torch.LongTensor(y_data) #label이므로 정수"
      ],
      "metadata": {
        "id": "5lPes1dvjlNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d2031b-d1fd-4f0f-d748-55864e688263"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMZzZlaymMk8",
        "outputId": "2679b109-8d74-4997-a6cd-1134e3834fce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([188, 10, 26])\n",
            "레이블의 크기 : torch.Size([188, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knx1DE_AmSFB",
        "outputId": "e0b20159-79c1-4552-b6c2-8cb6a5238add"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pWDiH1SmYT_",
        "outputId": "52773ca3-8c97-4ee9-d65a-bc768678b3bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  0,  1,  4, 22,  3, 23, 10, 10, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.RNN(input_size= input_dim, hidden_size= hidden_dim, num_layers=layers, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x,_ = self.rnn(x) \n",
        "    x = self.fc(x) \n",
        "    return x"
      ],
      "metadata": {
        "id": "-Ww22xu8mfUc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "No2GRvTpnLBl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "9-zuJLeUnQLB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RxRaiHnh9U",
        "outputId": "7f8c7b31-5f46-4a14-d19b-f8cd237f35f3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([188, 10, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, 26), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxxrxCd2nwoo",
        "outputId": "85f7b01b-ea4b-4a37-d8ce-669474633fc9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "akkpkkkkokkkkkkkkkkkkkkkkkkkkkpkkkkkkkkkkkktkkkkktkkkkkkkkkkkkkkkkkkkkkkkkkokkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkpkkkkkkkkkkkkkkkkkkkkkkkkkkkkokkkkkkkkkkkkkkkkkkkkkkkkkkkkkpkkkkkkkkkkkkkkkkkk\n",
            "ak kktkttttttt tttttttttkkttt ttttttt ttttkt ktttttkttttttttttttttttk tktkttttttt tttttttttttttttttttttttttttttttttttttttttttttktttttttttttttk tktkttttttt tttttttttttttkttttttkttttkttk tttttttttt t\n",
            "     t t  ttt  ttt t tt   ttt ttttttt t t tt tttttttttt ttttt ttt tt    t t  ttt  tt tttt  ttttt  tt ttt t tt tttt tt t ttttt t t tttt ttt tt    t t  ttt  ttt t ttttttt tttttt ttt   t  t ttttttt   \n",
            "                 t        t   t   tt    t  t    tt   t     tt   t                 tt   t           t               t       t    t   tt   t                   t        t       t            t  t t    \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                    t                                                                \n",
            "                 t                             t           t    t                                                          t        t    t                   t                                  t    \n",
            "                 t                             t     t     t    t                      t                                   t        t    t                   t        t                         t    \n",
            "      ar   ah    e                             t   t t    ht    t        ar   ah     t t                              t    t   ar   tr   t        ar   ah    e        t           t    a      t t    \n",
            "      ar   ah   he   t    h        h           t   the   ahe  t e   e    ar   ah     t tr  th                  t   t  t    er  ar   er t e   e    ar   ah   he   th   ar t   ar t t    a   r  the    \n",
            "     aar   ah  the   th  th   t   th      t    t   ther  aher ther  e    ar   ah     ther  tht        a    a   t   t  t    er  ar  her ther  e    ar   ah  the   tht  ar t   ar tht    a  ar  the    \n",
            "     aar   ahe the   th  ahe  t   th      th   t   ther  aher ther her   ar   ahe    ther  the        a    a   t r tr t   her  ar ther ther her   ar   ahe the   the  ar t   ar the   ah tar  aher   \n",
            "     aar   ahe ther rth  ahe  t   ah      th   ah  aher  aher therther  warl  ahe    ther  the    t   ar   ah   he tr re  her  ar ther therther  warl  ahe ther rthe aar t  aar thel  ah thr  aher   \n",
            "     warl  ahe thererth  ahe  t   ah      th   th  aher  aher therther  warl  ahe    ther  the a  a   a    ahe  he trere  har  ar ther therther  warl  ahe thererthe aa  w  aar thel  ah thr  aher   \n",
            "     wall  ahe thererth  aher th  ah      th   th  ther  aher therther  wall  ahe    there the a  a   a    th   he trere  har  ar ther therther  wall  ahe thererthe ae  w  aar whel  wh th   aher   \n",
            "     wal   ahe the erth  are  th  ah      th  ath  ther  aher thertrer  wal   ahe t  the e the a  a   a    th  the trere  her  ar ther thertrer  wal   ahe the erthe ae     aar whtl  wh th   ther   \n",
            " e   wal   ahe the e th  are  th  ah    t th  hth  ther  aher the trer  wal   ahe th the e tht a  a   a    wh  the trere  her  ar ther the trer  wal   ahe the e tht he     aar whtl  wh th   ther   \n",
            " e   wal   are the e th  arer th  ar    t th  hth  ther  aher the trer  wal   are th the e tht a  a   a    wh  tae trere  hen tar ther the trer  wal   are the e tht he  t  tar wht   wa th   ther   \n",
            "re   war   are the e th  aree th  ar  t t th  hth  ther  ther the erer  warl  are th the e tht h      a    wh  tae erere then tar ther the erer  warl  are the e tht he  t  tar watl  wa ta   ther   \n",
            "rel  warl  are the e th  aree th  ar  t t th  hta  aher  ther thererer  warl  are th the e tht h      a    wa  tar erere then tar ther thererer  warl  are the e tht he  w  tar watl  wa ta   then   \n",
            "rels wall  are the e th  aree th  arl t t th  hta  ahen  ther thererer  wall  are th there tht h      a    wa  tar erere then tar ther thererer  wall  are the e tht he  ws war walll aa ta   then   \n",
            "rels wall  are the e th  aree th  arlltat t   hta  ahen  wher thererers wall  are th there tht h      a    wa  tar erete then tar ther thererers wall  are the e tht he  ws aar walll aa tar  then   \n",
            "rels wall  are the e to  aree th  arlltat th  hto  ahen  wher thererens wall  are th there tht h      a    wa  tar ereto then war ther thererens wall  are the e tht hen ws aar walll aa tar  then   \n",
            "rens wall  are the e tor aree th  arl tat th  hto  then  wher thertrenk wall  are th there tht h      a    wh  tar ereto then wal ther thertrenk wall  are the e tht het ws aan walll wa tar  then   \n",
            "rens wall  are the e tor aree th  arl tat th  hto  then  wher thertrenk walls are th there tht h      a    wht ten erewo then wal ther thertrenk walls are the e tht het ws aan whlll wa tar  then   \n",
            "rens walls are the e tor aree th  are t t th  hto  then  wher thertrenk walls are t  there tht h      a    tht tet erewo then wal ther thertrenk walls are the e tht het ws aat whlll wa tan  then   \n",
            "renk walls are the e tor areeeth  are t t t s hto  then  wher thertrenk walls are t  there tht h      a    tht tet erewo then wal ther thertrenk walls are the e tht het ws aat whlll wa tan  then   \n",
            "reck walls are the e tor areeeth  are t t t s hto  then  wher thertrick walls are tt there tht h t us a    the tet erewn then wal ther thertrick walls are the e tht het ws aat wulls wa tan  then s \n",
            "reck walls are there tor areeeth  are t t wus hto  then  wher thertrick walls are tt there tht h t us a    the tet erewn then wal ther thertrick walls are there tht het ws aat wulls wa tan  then s \n",
            "reck walls are there tor areeeth  are t t wusthto  then  whet thertrick walls are tt there th  a t us a    aht tet erewn then wal thet thertrick walls are there th  hew ws aaw wulls wa tal  then s \n",
            "rick walls are there tor areeeth  are t t wusthto  then  whet thertrick walls are tt there th  a t us a    art tet eretn then wal thet thertrick walls are there th  hew ws aaw wulls wa tal  then s \n",
            "rick walls are there tor areeeth  are tat wusthto  then  whet thertrick walls are tt there th  a t us a    art tet eretn then wal thet thertrick walls are there th  hew ws aaw wulls wa tan  then s \n",
            "rick walls are there tor areeeth  ard tat wusthtor then  thet thertrick walls are tt there th  a t us au   but tet eretn then wal thet thertrick walls are there th  hew ws aaw wulls wa tan  then s \n",
            "rick walls are there tor areeeth  ard tat austhtot then  thet thertrick walls are tt there th  art us au   bot retheretn then wal thet thertrick walls are there th  hew ws aaw wulls wa tan  then s \n",
            "rick walls are there tor areeeth  ard kaw austhtot then  thet therbrick walls are tt there th  a t us au   but retheretn then wal thet therbrick walls are there th  haw ws haw wudls wa tan  then s \n",
            "rick walls are there tor anreeth  ard kau aust wot then  thet therbrick walls are tt there th  a k us hu h but retheretn then wal thet therbrick walls are there th  haw ws haw wudls wa tan  thenks \n",
            "rick walls are there tor anreethn ard kau aust wot thin  thet the brick walls are tt there th  a k us hr h but retheretn then wal thet therbrick walls are there th  haw ws haw wudls wa tan  thenks \n",
            "rick walls are there tor anreethn and kau aust wot thin  thet the brick walls are tt there th  a k us hr h but retherebn thes wal thet the brick walls are there th  haw ws haw wudls wa tan  thenks \n",
            "rick walls are there tor anreethn and sau aust wot thin  thet the brick walls are tt there th  a f us hr h but ratherebn this wal thet the brick walls are there th  haw ws haw wudls wa tan  thenks \n",
            "rick walls are there tor anreethn and sau aust wot thin  thet the brick walls are tt thire th ta f us hr h but ratherebn this wal thet the brick walls are there th thaw ws haw wudls wa tan  thenks \n",
            "rick walls are there tor anreethn and sau aust wot thin  thet the brick walls are tt thire th ta w us hr   but ratherebn this wal thet the brick walls are there th thaw ws haw wudly wa tan  thenks \n",
            "rick walls are there tor anreeshn and yau tust wot thin  thet the brick walls are tt there th ta w us hr   but ratherebn this wal thet the brick walls are there th thaw ws how wudly wa tant thenks \n",
            "rick walls are there tor anreeson and yau tust wot thin  thet the brick walls are tt there th ta w us hr   but ratherein this wal thet the brick walls are there th thow ws how wudly wa want thenks \n",
            "rick walls are there tor anreeson and yau tust wot thin  thet the brick walls are tt there th ta w us hr   but ratherein this wal thet the brick walls are there th thow ws how wudly ta want thenks \n",
            "rick walls are there tor anreeson and you tust wot thin  thet the brick walls are tt there th ta w us hr   but ratherein this wal thet the brick walls are there th thow us how wudly ta want thenks \n",
            "rick walls are there tor anreeson and you tust wot think that the brick walls are tt there th taep us hu   but ratherein this wal thet the brick walls are there th thow us how wudly ta want thenks \n",
            "rick walls are there tor anreeson and you tust wot think that the brick walls are tt there th taep us hu   but ratherein this wal thet the brick walls are there th thow us how uudly wa want thinks \n",
            "rick walls are there tor anreeson and you must wot think that the brick walls are tt there th taep us hu   but ratherein this wal thet the brick walls are there th thow us how uudly wa want thinks \n",
            "rick walls are there tor anreeson and you must not think that the brick walls are tt there th taep us hut  but ratherein this wal thet the brick walls are there th thow us how uudly wa want thinks,\n",
            "rick walls are there tor anreeson and you must not think that the brick walls are tt there th taep us hut, but ratherein this wal thet the brick walls are there th thow us how uadly wa want thinks,\n",
            "rick walls are there tor anreeson and you must not think that the brick walls are 't there to taep us aut, but ratherein this wal thet the brick walls are there th thow us how uadly wa want thinks,\n",
            "rick walls are there tor anreeson and you must not think that the brick walls are tt there to  aep us aut, but ratherein this wal thet the brick walls are there to  how us how uadly wa want thinks,\n",
            "rick walls are there tor anreeson and you must not think that the brick walls are tt there to saep us aut, but ratherein this wal thet the brick walls are there to show us how uadly wa want thinks,\n",
            "rick walls are there tor anreeson and you must not think that the brick walls are tt there to seep us aut, but ratherein this wal thet the brick walls are there to show us how uadly wa want thinks,\n",
            "rick walls are there tor anreeson and you must not think that the brick walls are tt there to seep us aut, but ratherein this wal that the brick walls are there to show us how badly wa want thinks,\n",
            "rick walls are there tor anreason and you must not think that the brick walls are 't there to seep us aut, but ratherein this wal that the brick walls are there to show us how badly wa want thinks,\n",
            "rick walls are there tor anreason and you must not think that the brick walls are 't there to seep us aut, but rather in this wal that the brick walls are there to show us how badly wa want thinks,\n",
            "rick walls are there tor anreason and you must not think that the brick walls are 't there to seep us aut, but rather in this wal that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinks,\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinksg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks.\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks.\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "8qUkbiw2t0Il",
        "outputId": "78a9b8a6-29a8-4f41-9fb6-2c1640eaaed0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"rick walls are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to khow us how badly we want thinks.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과가 어떤가요?? 마지막 에폭의 문장이 그럴싸한가요?"
      ],
      "metadata": {
        "id": "PkIzDTdyvTHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task2\n",
        "\n",
        "위 sentence는 제가 임의로 생성한 문장들입니다.\n",
        "\n",
        "마음에 드시는 문구 가져오셔서 문장이 어떻게 생성되는지 확인해보세요! \n",
        "\n",
        "영어가 아닌 한국어로 시도해보는 것도 좋겠죠? \n",
        "\n",
        "수정이 많이 필요(토큰화 등) 할 수 있으나 한번 시도해보시는 것 권장드립니다 :)\n",
        "\n",
        "위 베이스라인은 어디든 수정하셔도 좋고 조금 더 자연스러운 문장이 나올 수 있게 다양한 시도를 해보세요!\n",
        "\n",
        "조건 : 문장 3개 이상, 연결성이 있는 문장을 \" \" 으로 구분하여 ( )에 넣기"
      ],
      "metadata": {
        "id": "kN1zL8Dpvane"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "sentence = (\"인생의 가치는 그 길이에 있지 않다.\"\n",
        "            \"우리는 하루하루를 사용하여 인생을 만들어 나간다.\"\n",
        "            \"오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\")"
      ],
      "metadata": {
        "id": "Zjwnu_C01jhk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOKA4EFU3Xhi",
        "outputId": "06b4b7fe-98aa-451c-efc6-1331c2bf4b6f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {}\n",
        "for i in range(len(world_set)):\n",
        "  vocab[world_set[i]] = i"
      ],
      "metadata": {
        "id": "RKwGmKXq1jhk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c9c9f2-6341-421c-953d-8d615eda6354",
        "id": "vQvCXDyf1jhl"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'있': 0, '다': 1, '가': 2, '하': 3, '는': 4, '래': 5, '꼭': 6, '이': 7, '지': 8, '렇': 9, '용': 10, '걸': 11, '를': 12, '않': 13, '만': 14, '치': 15, '들': 16, '되': 17, '많': 18, '인': 19, '오': 20, '어': 21, '고': 22, '살': 23, '우': 24, '여': 25, '의': 26, '을': 27, '.': 28, '수': 29, '생': 30, '그': 31, ',': 32, '은': 33, '리': 34, '나': 35, ' ': 36, '사': 37, '게': 38, '진': 39, '길': 40, '루': 41, '에': 42, '간': 43, '얻': 44}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae19c66d-3159-41b7-a7fe-0ec172eccee4",
        "id": "j5pr8HNQ1jhl"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
        "\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 6  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "CsPExx941jhl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i:i+sequence_length]\n",
        "  y_str = sentence[i+1: i+sequence_length+1]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7af9885-3f6d-4bb7-dcd6-49190cacc897",
        "id": "T1-uTDmM1jhl"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 인생의 가치 -> 생의 가치는\n",
            "1 생의 가치는 -> 의 가치는 \n",
            "2 의 가치는  ->  가치는 그\n",
            "3  가치는 그 -> 가치는 그 \n",
            "4 가치는 그  -> 치는 그 길\n",
            "5 치는 그 길 -> 는 그 길이\n",
            "6 는 그 길이 ->  그 길이에\n",
            "7  그 길이에 -> 그 길이에 \n",
            "8 그 길이에  ->  길이에 있\n",
            "9  길이에 있 -> 길이에 있지\n",
            "10 길이에 있지 -> 이에 있지 \n",
            "11 이에 있지  -> 에 있지 않\n",
            "12 에 있지 않 ->  있지 않다\n",
            "13  있지 않다 -> 있지 않다.\n",
            "14 있지 않다. -> 지 않다.우\n",
            "15 지 않다.우 ->  않다.우리\n",
            "16  않다.우리 -> 않다.우리는\n",
            "17 않다.우리는 -> 다.우리는 \n",
            "18 다.우리는  -> .우리는 하\n",
            "19 .우리는 하 -> 우리는 하루\n",
            "20 우리는 하루 -> 리는 하루하\n",
            "21 리는 하루하 -> 는 하루하루\n",
            "22 는 하루하루 ->  하루하루를\n",
            "23  하루하루를 -> 하루하루를 \n",
            "24 하루하루를  -> 루하루를 사\n",
            "25 루하루를 사 -> 하루를 사용\n",
            "26 하루를 사용 -> 루를 사용하\n",
            "27 루를 사용하 -> 를 사용하여\n",
            "28 를 사용하여 ->  사용하여 \n",
            "29  사용하여  -> 사용하여 인\n",
            "30 사용하여 인 -> 용하여 인생\n",
            "31 용하여 인생 -> 하여 인생을\n",
            "32 하여 인생을 -> 여 인생을 \n",
            "33 여 인생을  ->  인생을 만\n",
            "34  인생을 만 -> 인생을 만들\n",
            "35 인생을 만들 -> 생을 만들어\n",
            "36 생을 만들어 -> 을 만들어 \n",
            "37 을 만들어  ->  만들어 나\n",
            "38  만들어 나 -> 만들어 나간\n",
            "39 만들어 나간 -> 들어 나간다\n",
            "40 들어 나간다 -> 어 나간다.\n",
            "41 어 나간다. ->  나간다.오\n",
            "42  나간다.오 -> 나간다.오래\n",
            "43 나간다.오래 -> 간다.오래 \n",
            "44 간다.오래  -> 다.오래 살\n",
            "45 다.오래 살 -> .오래 살 \n",
            "46 .오래 살  -> 오래 살 수\n",
            "47 오래 살 수 -> 래 살 수는\n",
            "48 래 살 수는 ->  살 수는 \n",
            "49  살 수는  -> 살 수는 있\n",
            "50 살 수는 있 ->  수는 있지\n",
            "51  수는 있지 -> 수는 있지만\n",
            "52 수는 있지만 -> 는 있지만,\n",
            "53 는 있지만, ->  있지만, \n",
            "54  있지만,  -> 있지만, 그\n",
            "55 있지만, 그 -> 지만, 그렇\n",
            "56 지만, 그렇 -> 만, 그렇다\n",
            "57 만, 그렇다 -> , 그렇다고\n",
            "58 , 그렇다고 ->  그렇다고 \n",
            "59  그렇다고  -> 그렇다고 꼭\n",
            "60 그렇다고 꼭 -> 렇다고 꼭 \n",
            "61 렇다고 꼭  -> 다고 꼭 많\n",
            "62 다고 꼭 많 -> 고 꼭 많은\n",
            "63 고 꼭 많은 ->  꼭 많은 \n",
            "64  꼭 많은  -> 꼭 많은 걸\n",
            "65 꼭 많은 걸 ->  많은 걸 \n",
            "66  많은 걸  -> 많은 걸 얻\n",
            "67 많은 걸 얻 -> 은 걸 얻게\n",
            "68 은 걸 얻게 ->  걸 얻게 \n",
            "69  걸 얻게  -> 걸 얻게 되\n",
            "70 걸 얻게 되 ->  얻게 되진\n",
            "71  얻게 되진 -> 얻게 되진 \n",
            "72 얻게 되진  -> 게 되진 않\n",
            "73 게 되진 않 ->  되진 않는\n",
            "74  되진 않는 -> 되진 않는다\n",
            "75 되진 않는다 -> 진 않는다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
        "\n",
        "print(type(x_data))\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e370c14-2185-42ec-e98d-7d08952d8e37",
        "id": "s54D7rV-1jhl"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "[30, 26, 36, 2, 15, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor: 32비트 부동소수점, LongTesor: 64비트 정수(부호있음) 중 맞는 것은?)\n",
        "X = torch.FloatTensor(x_one_hot) #연산\n",
        "Y = torch.LongTensor(y_data) #label이므로 정수"
      ],
      "metadata": {
        "id": "rsABgRc61jhm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5776c53-3569-4142-a2e5-f1158b183426",
        "id": "t_HcVEh31jhm"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([76, 6, 45])\n",
            "레이블의 크기 : torch.Size([76, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23ddad6-14cd-4857-8619-2827fbab7c6b",
        "id": "hBfkg7Xt1jhm"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520e8f3e-d2e9-4d01-b466-14b6596b2ba5",
        "id": "QfGmDGM51jhm"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([30, 26, 36,  2, 15,  4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.RNN(input_size= input_dim, hidden_size= hidden_dim, num_layers=layers, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x,_ = self.rnn(x) \n",
        "    x = self.fc(x) \n",
        "    return x"
      ],
      "metadata": {
        "id": "KO5KKwCt1jhm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "bo1dB4Jo1jhm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "L0kqUPBW1jhn"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505f6587-f7dc-4f7b-de10-2fde2e9e650a",
        "id": "tN85iAb71jhn"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([76, 6, 45])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, 45), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdbad0b1-e145-4944-9fa3-95d280a2db49",
        "id": "N6wU3jfu1jhn"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭어꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭어꼭어꼭꼭꼭꼭꼭어꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭꼭\n",
            "꼭             꼭                                                                  \n",
            "                                                                                 \n",
            "                                                                                 \n",
            "                                                                                 \n",
            "                                                                                 \n",
            "                                                                                 \n",
            "                                                                                 \n",
            "                                                                                 \n",
            "                                                    는    는                       \n",
            "   하   그  는  하지 그  는   하               는     는      는 그  는    는      그          는\n",
            "   하   그  는  있지 그  는   있              하루  하는 는      는 있  는 그  는 그    있  는 않  않  는\n",
            "   하   그 하는  있지 않 .는 는 있루하 하 하 하  않   하루  있는 는 .   하는 있  는 그  는 그 하  있    있  않  .\n",
            "   있 하 그 하는  있지 않 .  는 있루하 하 하 하  있 하 하루  있간 .오. 하 하  있지 않 그 다는 그 하  있 만  있지 있간 .\n",
            "   있루하 그 많는  있지 않 .는리는 있루하 하 하 하  있루하 있루  있간 .오. 하 하는 있지 않 그 다. 그 하  있 만는 있지 있간 .\n",
            "   있루는 그 많는  있지 않 .는리는 있루하 하 살 하루 있루하 하지  있간 .오. 하 있는 있지 않 그 다. 그 하는 있 만는 있지 않는 .\n",
            "   있들는 그 많는  있지 않 .는리는 있루하 하 살 하루 있생하 만지  있간다.오. 하 있는 있지 않 그 다. 그 하는 있 만는 있지 않는 .\n",
            " 하 하들는 그 하는  있지 않 .는리는 있루하 하 살 하루 있생하 만들  있간다.오. 하 있는 있지 , 그 다. 그 하는 있 하는 있지 않는 .\n",
            " 지 하들는 그 하는  있지 않 .는리는 있루하 하 살 하루 있생하 만들어 있간다.오. 하 있는 있지 , 그 다. 꼭 하는 있 하는 않지 않는..\n",
            " 지 만들는 그 하이에 있지 않 .우리는 하루하루하 하용하루 있생을 만들어 있간다.오래 살 있는 있지 , 않 다. 꼭 하는 있 얻게 않지 않는..\n",
            " 지 만들는 그 만들에 있지 않 .우리는 하루하루하 하용하루 있생을 만들어 나간다.오래 살 있는 있지 , 않렇다. 꼭 하는 있 얻게 않지 않는 .\n",
            "생을 만들는 그 만이에 있지 않 .우리는 하루하루하 하용하루 있생을 만들어 나간다.오래 살 있는 있지 , 않 다. 꼭 하는 있 얻게 않진 않는다.\n",
            "생을 만들는 그 만이에 있지 않다.우리는 하루하루하 하용하루 있생을 만들어 나간다.오래 살 있는 있지만, 않 다. 꼭 하는 있 얻게 되진 않는다.\n",
            "생을 만그는 그 만이에 있지 않다.우리는 하루하루를 사용하여 있생을 만들어 나간다.오래 살 있는 있지만, 않 다. 꼭 하은 있 얻게 되진 않는다.\n",
            "생을 만그는 그 만이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 않 다. 꼭 많은 있 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다. 꼭 많은 있 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 그 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 꼭 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 꼭 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 만들는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 만치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n",
            "생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f98e8f96-d535-4d5f-9cbc-28a973f5faf9",
        "id": "i0-bC_0h1jhn"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'생을 가치는 그 길이에 있지 않다.우리는 하루하루를 사용하여 인생을 만들어 나간다.오래 살 수는 있지만, 그렇다고 꼭 많은 걸 얻게 되진 않는다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J_90E1sr3lPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}