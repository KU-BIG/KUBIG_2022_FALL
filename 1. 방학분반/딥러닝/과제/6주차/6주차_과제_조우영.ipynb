{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6주차_과제_조우영.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nmQ5F7UAeKB_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task1\n",
        "\n",
        "빈 칸을 채워주세요!\n",
        "\n",
        "단계별 output이 github 파일에는 남아있으니 그 output과 동일한 형태인지 확인하면서 진행해주시면 됩니다~"
      ],
      "metadata": {
        "id": "Sgxd6SxmeVcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "sentence = (\"Brick walls are there for a reason and you must not think \"\n",
        "            \"that the brick walls aren't there to keep us out, but rather \"\n",
        "            \"in this way that the brick walls are there to show us how badly we want things.\")"
      ],
      "metadata": {
        "id": "NDvUeC8BoUb6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "# set(sentence) -> sentence에 있는 unique한 것들만 random order로 남겨 {}로 둘러싸인 \n",
        "# set object로 return, 이를 list로 만들어 world_set에 할당\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {token: i for i, token in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "b9lkrKyZf8ie"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0we5Y-gYDq",
        "outputId": "40e78b41-8934-4178-cc67-6c161cd5fb9f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'f': 1, 'n': 2, 's': 3, 'd': 4, 'g': 5, 't': 6, \"'\": 7, 'u': 8, 'l': 9, 'k': 10, 'a': 11, 'm': 12, 'b': 13, 'e': 14, 'c': 15, 'i': 16, ',': 17, 'w': 18, 'p': 19, 'o': 20, 'y': 21, '.': 22, 'h': 23, 'r': 24, 'B': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpKupU6lgpfT",
        "outputId": "a4cc874d-808f-4d22-e020-d454f467fa22"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
        "\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 10  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "wFDZJHSMg9In"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i : (sequence_length + i)]\n",
        "  y_str = sentence[(i + 1) : (sequence_length + i + 1)]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str의 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbDcmJmghN7V",
        "outputId": "c4d10b4a-0ded-4378-afe0-3f376b8a3e63"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Brick wall -> rick walls\n",
            "1 rick walls -> ick walls \n",
            "2 ick walls  -> ck walls a\n",
            "3 ck walls a -> k walls ar\n",
            "4 k walls ar ->  walls are\n",
            "5  walls are -> walls are \n",
            "6 walls are  -> alls are t\n",
            "7 alls are t -> lls are th\n",
            "8 lls are th -> ls are the\n",
            "9 ls are the -> s are ther\n",
            "10 s are ther ->  are there\n",
            "11  are there -> are there \n",
            "12 are there  -> re there f\n",
            "13 re there f -> e there fo\n",
            "14 e there fo ->  there for\n",
            "15  there for -> there for \n",
            "16 there for  -> here for a\n",
            "17 here for a -> ere for a \n",
            "18 ere for a  -> re for a r\n",
            "19 re for a r -> e for a re\n",
            "20 e for a re ->  for a rea\n",
            "21  for a rea -> for a reas\n",
            "22 for a reas -> or a reaso\n",
            "23 or a reaso -> r a reason\n",
            "24 r a reason ->  a reason \n",
            "25  a reason  -> a reason a\n",
            "26 a reason a ->  reason an\n",
            "27  reason an -> reason and\n",
            "28 reason and -> eason and \n",
            "29 eason and  -> ason and y\n",
            "30 ason and y -> son and yo\n",
            "31 son and yo -> on and you\n",
            "32 on and you -> n and you \n",
            "33 n and you  ->  and you m\n",
            "34  and you m -> and you mu\n",
            "35 and you mu -> nd you mus\n",
            "36 nd you mus -> d you must\n",
            "37 d you must ->  you must \n",
            "38  you must  -> you must n\n",
            "39 you must n -> ou must no\n",
            "40 ou must no -> u must not\n",
            "41 u must not ->  must not \n",
            "42  must not  -> must not t\n",
            "43 must not t -> ust not th\n",
            "44 ust not th -> st not thi\n",
            "45 st not thi -> t not thin\n",
            "46 t not thin ->  not think\n",
            "47  not think -> not think \n",
            "48 not think  -> ot think t\n",
            "49 ot think t -> t think th\n",
            "50 t think th ->  think tha\n",
            "51  think tha -> think that\n",
            "52 think that -> hink that \n",
            "53 hink that  -> ink that t\n",
            "54 ink that t -> nk that th\n",
            "55 nk that th -> k that the\n",
            "56 k that the ->  that the \n",
            "57  that the  -> that the b\n",
            "58 that the b -> hat the br\n",
            "59 hat the br -> at the bri\n",
            "60 at the bri -> t the bric\n",
            "61 t the bric ->  the brick\n",
            "62  the brick -> the brick \n",
            "63 the brick  -> he brick w\n",
            "64 he brick w -> e brick wa\n",
            "65 e brick wa ->  brick wal\n",
            "66  brick wal -> brick wall\n",
            "67 brick wall -> rick walls\n",
            "68 rick walls -> ick walls \n",
            "69 ick walls  -> ck walls a\n",
            "70 ck walls a -> k walls ar\n",
            "71 k walls ar ->  walls are\n",
            "72  walls are -> walls aren\n",
            "73 walls aren -> alls aren'\n",
            "74 alls aren' -> lls aren't\n",
            "75 lls aren't -> ls aren't \n",
            "76 ls aren't  -> s aren't t\n",
            "77 s aren't t ->  aren't th\n",
            "78  aren't th -> aren't the\n",
            "79 aren't the -> ren't ther\n",
            "80 ren't ther -> en't there\n",
            "81 en't there -> n't there \n",
            "82 n't there  -> 't there t\n",
            "83 't there t -> t there to\n",
            "84 t there to ->  there to \n",
            "85  there to  -> there to k\n",
            "86 there to k -> here to ke\n",
            "87 here to ke -> ere to kee\n",
            "88 ere to kee -> re to keep\n",
            "89 re to keep -> e to keep \n",
            "90 e to keep  ->  to keep u\n",
            "91  to keep u -> to keep us\n",
            "92 to keep us -> o keep us \n",
            "93 o keep us  ->  keep us o\n",
            "94  keep us o -> keep us ou\n",
            "95 keep us ou -> eep us out\n",
            "96 eep us out -> ep us out,\n",
            "97 ep us out, -> p us out, \n",
            "98 p us out,  ->  us out, b\n",
            "99  us out, b -> us out, bu\n",
            "100 us out, bu -> s out, but\n",
            "101 s out, but ->  out, but \n",
            "102  out, but  -> out, but r\n",
            "103 out, but r -> ut, but ra\n",
            "104 ut, but ra -> t, but rat\n",
            "105 t, but rat -> , but rath\n",
            "106 , but rath ->  but rathe\n",
            "107  but rathe -> but rather\n",
            "108 but rather -> ut rather \n",
            "109 ut rather  -> t rather i\n",
            "110 t rather i ->  rather in\n",
            "111  rather in -> rather in \n",
            "112 rather in  -> ather in t\n",
            "113 ather in t -> ther in th\n",
            "114 ther in th -> her in thi\n",
            "115 her in thi -> er in this\n",
            "116 er in this -> r in this \n",
            "117 r in this  ->  in this w\n",
            "118  in this w -> in this wa\n",
            "119 in this wa -> n this way\n",
            "120 n this way ->  this way \n",
            "121  this way  -> this way t\n",
            "122 this way t -> his way th\n",
            "123 his way th -> is way tha\n",
            "124 is way tha -> s way that\n",
            "125 s way that ->  way that \n",
            "126  way that  -> way that t\n",
            "127 way that t -> ay that th\n",
            "128 ay that th -> y that the\n",
            "129 y that the ->  that the \n",
            "130  that the  -> that the b\n",
            "131 that the b -> hat the br\n",
            "132 hat the br -> at the bri\n",
            "133 at the bri -> t the bric\n",
            "134 t the bric ->  the brick\n",
            "135  the brick -> the brick \n",
            "136 the brick  -> he brick w\n",
            "137 he brick w -> e brick wa\n",
            "138 e brick wa ->  brick wal\n",
            "139  brick wal -> brick wall\n",
            "140 brick wall -> rick walls\n",
            "141 rick walls -> ick walls \n",
            "142 ick walls  -> ck walls a\n",
            "143 ck walls a -> k walls ar\n",
            "144 k walls ar ->  walls are\n",
            "145  walls are -> walls are \n",
            "146 walls are  -> alls are t\n",
            "147 alls are t -> lls are th\n",
            "148 lls are th -> ls are the\n",
            "149 ls are the -> s are ther\n",
            "150 s are ther ->  are there\n",
            "151  are there -> are there \n",
            "152 are there  -> re there t\n",
            "153 re there t -> e there to\n",
            "154 e there to ->  there to \n",
            "155  there to  -> there to s\n",
            "156 there to s -> here to sh\n",
            "157 here to sh -> ere to sho\n",
            "158 ere to sho -> re to show\n",
            "159 re to show -> e to show \n",
            "160 e to show  ->  to show u\n",
            "161  to show u -> to show us\n",
            "162 to show us -> o show us \n",
            "163 o show us  ->  show us h\n",
            "164  show us h -> show us ho\n",
            "165 show us ho -> how us how\n",
            "166 how us how -> ow us how \n",
            "167 ow us how  -> w us how b\n",
            "168 w us how b ->  us how ba\n",
            "169  us how ba -> us how bad\n",
            "170 us how bad -> s how badl\n",
            "171 s how badl ->  how badly\n",
            "172  how badly -> how badly \n",
            "173 how badly  -> ow badly w\n",
            "174 ow badly w -> w badly we\n",
            "175 w badly we ->  badly we \n",
            "176  badly we  -> badly we w\n",
            "177 badly we w -> adly we wa\n",
            "178 adly we wa -> dly we wan\n",
            "179 dly we wan -> ly we want\n",
            "180 ly we want -> y we want \n",
            "181 y we want  ->  we want t\n",
            "182  we want t -> we want th\n",
            "183 we want th -> e want thi\n",
            "184 e want thi ->  want thin\n",
            "185  want thin -> want thing\n",
            "186 want thing -> ant things\n",
            "187 ant things -> nt things.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
        "\n",
        "print(x_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVFlILiOixdc",
        "outputId": "e11b5644-c030-49a4-9fa9-318adf776f86"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25, 24, 16, 15, 10, 0, 18, 11, 9, 9]\n",
            "[24, 16, 15, 10, 0, 18, 11, 9, 9, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xywiH3mW1bxl",
        "outputId": "b19c6e48-55b2-4247-995d-89dad8e2be59"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.eye(len(vocab))[x] for x in x_data]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor, LongTesor 중 맞는 것은?)\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data) # cross entropy loss expects its label to be long tensor type"
      ],
      "metadata": {
        "id": "5lPes1dvjlNb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape)) \n",
        "# 188개의 data에 대해 한 data당 10개의 단어에 해당하는 길이 26의 vector\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMZzZlaymMk8",
        "outputId": "23146e8c-2502-478d-fe1f-8276b000adcc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([188, 10, 26])\n",
            "레이블의 크기 : torch.Size([188, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knx1DE_AmSFB",
        "outputId": "6a0c159b-7ec8-4175-ba7f-65e988e7b123"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pWDiH1SmYT_",
        "outputId": "93ce804c-4ac2-4a0b-a816-37a5bef081aa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([24, 16, 15, 10,  0, 18, 11,  9,  9,  3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.layers = layers\n",
        "    self.rnn = torch.nn.RNN(input_size = input_dim, hidden_size = hidden_dim,\n",
        "                            num_layers = layers)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, 26)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x, hidden = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "-Ww22xu8mfUc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "No2GRvTpnLBl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "9-zuJLeUnQLB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RxRaiHnh9U",
        "outputId": "bae77ddc-01fb-4864-dc68-b8fdb1c61b6b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([188, 10, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opFERgw50PVT",
        "outputId": "be5b58d6-bc1a-43ce-c59e-2dbb49f59f76"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([188, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = outputs.view(-1, 26)\n",
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alet8VXe0XbT",
        "outputId": "42bc852f-0f79-48c1-a439-fff456d03197"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1880, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, 26), Y.view(1880))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxxrxCd2nwoo",
        "outputId": "b48d72ce-336a-4e05-cfb2-93b0f4e5e2d6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "..............r..r..r.r......r...r......r...... r..r.r.r...r.. .r................rr..r.r..r..r.r.......r..r....r...r....r..r........r.. .r................r..r..r..r.........r......r.....r.r. .r.r..\n",
            " r.r  rrrr                                                                                                                                                                                           \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                          h                                                                                                                                          \n",
            "                h     h                             h     h              h     h      h     h  h       h                  h        h              h     h   h     h  h       h         h  h    h     \n",
            "     t      h  th    th     h                       h    th  h h   h    th     h     th    th th    h  h    h   e  e      h        h    h   h    th     h  th    th th       h        th th    he    \n",
            " e   t      h  th    th     h                      th    th  h he th  h th  h th     th    th th    h th    h   e  e      h       th  h he th  h th  h th  th    th th       h   e    th th  h he    \n",
            " e   t      h  th    th   h h      e  te   h       th    th  h he th  a th    th     th    th th    h th   th  te  e   h  he   h  th  h he th  a th    th  th    th th      th   e    th th  h he    \n",
            " e   t     the th    th  th h      e  th   h    h  th    the h he th    th    th     the   th th   th th   th  te  e   h  he   h  th    he th    th    th  th    th th    h th   e    th th   the    \n",
            " e   t     the th    th  th h      e  th  th   the the   the  the th    th    the    the   th th   th th   th  th  e   h the   h  the  the th    th    the th    th th    h th   h    th th   the    \n",
            "ee   t     the the   the th h      e  the th   the the   the  the th    th    the    the   th te   th te   th  th he   h the  ta  the  the th    th    the the   th th   th te  th    ta ta   the    \n",
            "ee   t t   the the   tae th h     ae  the the  the the   the  the the   th    tae    the   thete   th te   th  th he   h the  ta  the  the the   th    tae the   theth   ta te  ta    ta ta   the    \n",
            "ee   t t   tae the   tae thee t   ae  the the  the the   the  the tae   tae   tae    the   thete   th te   th  th he   a the  tae the  the tae   tae   tae the   thethe  ta ta  ta    ta ta   the    \n",
            "ee   t t   tae the e tae taee t  tae  the the athe the   the  the tae   tae   tae to the   theth   ta ta   th  th he   ae he  tae the  the tae   tae   tae the e thethe   a ta  ta    ta ta   the    \n",
            "ee   t t   tae the e tae trte t  tae  the th  athe the   the  the tae k tae   aae to the   theth   aa ta   th tae he   se he  tae the  the tae k tae   aae the e thethe   r ta   a    aa ta   the    \n",
            "ee   t t   tae the e tae trte t  tae  the th  athe the   the  the tae k ta    aae to the e th th   aa te h th tah he   s  he  tae the  the tae k ta    aae the e th the   r aa   a    aa ta   the    \n",
            "ee   t t   are the e toe trte t  tae  tae th  athe the   the  the the k ta    are to the e th te   aa ae h th  th he e s  he  tae the  the the k ta    are the e th the   r ae   r    aa ta   the    \n",
            "ee   t tss are the e toe trte t  tae  the th  athe the   the  the the k ta    are to the e th te   ar ae h to tth he e s  he  tae the  the the k ta    are the e th the   r aa  tr    aa ta   the    \n",
            "ee   t tss are the e toe tthe to tae  the th  athe the   the  the thelk ta    are to the e th th   ar ae h to ttothe   s  he  tae the  the thelk ta    are the e th the   r aa  tr    aa ta   the    \n",
            "eel  t tss are the e toe  the to thel the th  athe the   the  the thelk ta l  aae t  the e th to t ar ae h to taothe   s the  tae the  the thelk ta l  aae the e th the   r aa  tr    aa th   the    \n",
            "eel  t tss are there toe  the to  ael the ta  othe the   the  the thilk ta l  aae t  the e th to   ar aeth to taothe   s the  tae the  the thelk ta l  aae the e th toe   r aa  trl   aa th   the    \n",
            "eel  t tss are there toe  the to  ael the wa   the the   the  the thilk ta ls aae    the e th to   ar aeth to taothe   s ther tai the  the thilk ta ls aae the e th toe  ar aa  trll  aa th   the    \n",
            "eel  t tss are there toe  the to  ael tho wa   th  the   the  the thilk ta ls aae    the e th wo t ar aath to taothe   s thir tal the  the thilk ta ls aae there th whe  ar aa  trlls aa thi  the    \n",
            "eel  t tss are there toe athe t   anl tho war  th  the   the  the thilk talls aae    the e th weil ar aath bo taothe   s thir tal thet the thilk talls aae there th wue  ar aa  trlls aa tan  the    \n",
            "eel  t tss are there toe anhe t   anl tho war  tr  the   the  the thilk walls aae    there th weis ar aath bh kaothe   s this tal thet the thilk walls aae there th wue  as aa  brlls aa tanl the    \n",
            "eel  t tss are there toe anhe t   anl tho war  tr  the   thet the thick walls are    there th weis ar aath bu  aothe   s this tal thet the thick walls are there th wuet as aa  brlls aa tan  the    \n",
            "eel  t tss are there toe anhe t   anl tho war  tr  then  thet the toick walls are    there th weis as aat  but aother  s this tal thet the toick walls are there th wuet as aa  trlls aa tan  thet   \n",
            "eel  w tss are there toe anhe s   anl tho war  tr  then  thet the toick walls are    there th weis as aath but aother  s this tal thet the toick walls are there th wuet as oa  thlls aa tan  thet   \n",
            "eel  w tss are there toe anhe s   anl tho war  tr  then  thet the toick walls are    there th weis as auth but aother  s this tal thet the toick walls are there th wuet as out thlls aa tan  thet   \n",
            "eel  w tss are there toe anhens   anl too was  tr  then  thet the trick walls are    there th beis as auth but aother  s this wal thet the trick walls are there to wuet as out brlls wa wan  thet   \n",
            "eelk w tss are there toe anhens   anl too wus  trt then  thet the trick walls are    there th beis as auth but aother  s this wal thet the trick walls are there to buet as oot brlls wa wan  thetk  \n",
            "aelk w tss are there toe anre s   anl too wus  trt thenk thet the taick walls are    there th beis as auth but aother  n this wal thet the taick walls are there to buet as oot bhlly wa wan  thetkt \n",
            "aelk w tss are there toe anre s   anl too wus  trt thenk thet the brick walls are c  there th bees as aath but arther  n this wal thet the baick walls are there to buet as oot bhlly wa wan  thetkt \n",
            "aelk w tss are there toe anre s   anl too wus  trt thenk thet the trick walls are c  there th bees as auth but arther  n this wal that the brick walls are there to suet as hot bhlly wa wan  thetkts\n",
            "aelk w tss are there toe anre s   anlttoo wus  trt thenk that the trick walls are t  there th sees as outh but arther  n this wal that the trick walls are there to suet us hot bhlly wa wan  thenkts\n",
            "aelk w tss are there toe anre so  anlttoo wus  trt thenk that the brick walls are    there th sees as outh but arther  n this wal that the brick walls are there to suot us hot bally wa wan  thenkts\n",
            "aenk w tss are there toe anreeso  anlttoo wus  trt thenk that the brick walls are  t there to sees as outh but arther  n this wal that the brick walls are there to suot us how bally wa wan  thenkts\n",
            "aenk w tss are there toe anreiso  anlttoo wust trt thenk that the brick walls are  t there to sees as auth but arther  n this wan that the brick walls are there to suot us how bally wa wan  thenkts\n",
            "aenk b tss are there toe anreiso  anlttoo wust trt thenk that the brick walls are  t there to sees as outh but arther  n this wan that the brick walls are there to suot us how bally wa wan  thenkts\n",
            "aenk b tss are there toe anreiso  anlttoo wust trt thenk that the brick walls are tt there to sees as outh but aother  n this wan that the brick walls are there to soow us how bally wo wan  thenkts\n",
            "aenk b tss are there toe a rens   anlttoo wust trt thenk that the brick walls are  t there to sees as outh but aother  n this wan that the brick walls are there to soow us how bally wo wan  thenkts\n",
            "aenk b tss are there toe a renso  anltyoa wus  trt thenk that the brick walls are tt there to seep us outh but aother  n this wan that the brick walls are there to soow us oow bally we wan  thenkt \n",
            "aenk b tss are there toe a renso  anltyoa wus  tot thenk that the brick walls are  t there to seep us out  but aother  n this wan that the brick walls are there to soow us oow bally we wan  thenkt \n",
            "aenk b tss are there toe a renson anltyoa wus  tot think that the brick walls are tt there to seep us outh but aother  n this wan that the brick walls are there to soow us oow bally we wan  thenkt \n",
            "aenk b tss are there toe a renson anltyou wus  tot think that the brick walls are  t there to seep us out  but aother  n this wan that the brick walls are there to soow us oow badly we wan  thenkt \n",
            "aenk b tss are there tor a renson anl you wus  tot think that the brick walls are tt there to seep us outh but aother  n this way that the brick walls are there to soow us oow badly we wan  thenkts\n",
            "aenk b tss are there tor a renson anl you wus  not think that the brick walls are tt there to seep us outh but aother  n this way that the brick walls are there to soow us oow badly we wan  thenktc\n",
            "aenk b tss are there tor a reason anl you wus  not think that the brick walls are tt there to seep us outh but aother  n this way that the brick walls are there to soow us how badly we wan  think  \n",
            "aenk b tss are there tor a reason anl you mus  not think that the brick walls arentt there to seep us outh but uother  n this way that the brick walls arenthere to soow us how badly we wan  think c\n",
            "aenk b tss are there tor a reason anl you mus  not think that the brick walls are  t there to seep us outk but aother  n this way that the brick walls are there to soow us how badly we wan  think  \n",
            "aenk b tss are there tor a reason anl you must not think that the brick walls are 't there to seep us outk but aother  n this way that the brick walls are there to soow us how badly we wan  think  \n",
            "aenk b tss are there tor a reason anl you must not think that the brick walls aren't there to seep us outh but aother  n this way that the brick walls arenthere to soow us how badly we wan  thinktc\n",
            "aenk b tss are there tor a reason and you must not think that the brick walls are 't there to seep us out, but aother  n this way that the brick walls are there to soow us how badly we wan  thinkt \n",
            "aenk b tss are there tor a reason and you must not think that the brick walls are 't there to keep us out, but aother  n this way that the brick walls are there to soow us how badly we wan  thinkt \n",
            "aenk b tss are there tor a reason and you must not think that the brick walls are tt there to seep us out, but aather  n this way that the brick walls are there to soow us how badly we wan  thinktc\n",
            "aenk b tss are there tor a reason and you must not think that the brick walls are 't there to keep us out, but aather  n this way that the brick walls are there to show us how badly we wan  thinktc\n",
            "aenk b tss are there tor a reason and you must not think that the brick walls are 't there to keep us out, but aather  n this way that the brick walls are there to soow us how badly we wan  thinkt \n",
            "renk b tss are there tor a reason and you must not think that the brick walls arentt there to keep us out, but aather  n this way that the brick walls arenthere to soow us how badly we wan  thinkt'\n",
            "renk b tss are there tor a reason and you must not think that the brick walls aren't there to keep us out, but aather  n this way that the brick walls arenthere to show us how badly we want thinks'\n",
            "renk b tss are there tor a reason and you must not think that the brick walls are 't there to keep us out, but aather  n this way that the brick walls are there to show us how badly we wan  thinks'\n",
            "renk b tss are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather  n this way that the brick walls are there to show us how badly we wan  thinks'\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather  n this way that the brick walls arenthere to show us how badly we want thinks'\n",
            "renk b tss are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather  n this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there tor a reason and you must not think that the brick walls are 't there to keep us out, but rather  n this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather  n this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls arenthere to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather  n this way that the brick walls arenthere to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather  n this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls arenthere to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls arenthere to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls arenthere to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls arenthere to show us how badly we want thinksc\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thinkss\n",
            "renk b tss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls arenthere to show us how badly we want thinkss\n",
            "reck b lss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thingsc\n",
            "reck b lss are there for a reason and you must not think that the brick walls are 't there to keep us out, but rather in this way that the brick walls are there fo show us how badly we want thingsc\n",
            "reck b lss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thingsc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(X)\n",
        "results = outputs.argmax(dim=2)\n",
        "[world_set[t] for t in result]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fgJP0Ehi3al",
        "outputId": "bba5d639-c9c0-47d5-f5d4-78a6c727dbb5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n', 't', ' ', 't', 'h', 'i', 'n', 'g', 's', 'c']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "8qUkbiw2t0Il",
        "outputId": "8fb09097-c5b6-4b16-ed78-17bcd8a9889a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"reck b lss are there for a reason and you must not think that the brick walls aren't there to keep us out, but rather in this way that the brick walls are there to show us how badly we want thingsc\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과가 어떤가요?? 마지막 에폭의 문장이 그럴싸한가요?"
      ],
      "metadata": {
        "id": "PkIzDTdyvTHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task2\n",
        "\n",
        "위 sentence는 제가 임의로 생성한 문장들입니다.\n",
        "\n",
        "마음에 드시는 문구 가져오셔서 문장이 어떻게 생성되는지 확인해보세요! \n",
        "\n",
        "영어가 아닌 한국어로 시도해보는 것도 좋겠죠? \n",
        "\n",
        "수정이 많이 필요(토큰화 등) 할 수 있으나 한번 시도해보시는 것 권장드립니다 :)\n",
        "\n",
        "위 베이스라인은 어디든 수정하셔도 좋고 조금 더 자연스러운 문장이 나올 수 있게 다양한 시도를 해보세요!\n",
        "\n",
        "조건 : 문장 3개 이상, 연결성이 있는 문장을 \" \" 으로 구분하여 ( )에 넣기"
      ],
      "metadata": {
        "id": "kN1zL8Dpvane"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 영어"
      ],
      "metadata": {
        "id": "2zG7pECnVjUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 구문의 brick walls를 보고 Pink Floyd의 Another Brick In The Wall이라는 노래가 생각이 나서 해당 노래의 가사를 가지고 왔습니다."
      ],
      "metadata": {
        "id": "wHbT11dAVvef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "sentence = (\"We don't need no education \"\n",
        "            \"We don't need no thought control \"\n",
        "            \"No dark sarcasm in the classroom \"\n",
        "            \"Teachers, leave them kids alone \"\n",
        "            \"Hey! Teacher! Leave us kids alone!\")"
      ],
      "metadata": {
        "id": "d9kAsK2UVnfs"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "# set(sentence) -> sentence에 있는 unique한 것들만 random order로 남겨 {}로 둘러싸인 \n",
        "# set object로 return, 이를 list로 만들어 world_set에 할당\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {token: i for i, token in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "VEVX4pFkVnfs"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7dc99a4-5051-413e-e5f0-212de5673801",
        "id": "CPbejKdyVnfs"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, 'n': 1, 's': 2, 'd': 3, 'g': 4, 't': 5, \"'\": 6, 'u': 7, 'H': 8, 'l': 9, 'W': 10, 'k': 11, 'a': 12, 'm': 13, '!': 14, 'e': 15, 'L': 16, 'c': 17, 'i': 18, ',': 19, 'N': 20, 'v': 21, 'o': 22, 'T': 23, 'y': 24, 'h': 25, 'r': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d3704d-b16d-4527-a76f-325ad03114e6",
        "id": "1tkJMGK0Vnfs"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
        "\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 8  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "2Fvh4l-yVnft"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i : (sequence_length + i)]\n",
        "  y_str = sentence[(i + 1) : (sequence_length + i + 1)]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451b8401-d6e9-405d-8a61-0ed43133b0fb",
        "id": "t9hNuQvuVnft"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 We don't -> e don't \n",
            "1 e don't  ->  don't n\n",
            "2  don't n -> don't ne\n",
            "3 don't ne -> on't nee\n",
            "4 on't nee -> n't need\n",
            "5 n't need -> 't need \n",
            "6 't need  -> t need n\n",
            "7 t need n ->  need no\n",
            "8  need no -> need no \n",
            "9 need no  -> eed no e\n",
            "10 eed no e -> ed no ed\n",
            "11 ed no ed -> d no edu\n",
            "12 d no edu ->  no educ\n",
            "13  no educ -> no educa\n",
            "14 no educa -> o educat\n",
            "15 o educat ->  educati\n",
            "16  educati -> educatio\n",
            "17 educatio -> ducation\n",
            "18 ducation -> ucation \n",
            "19 ucation  -> cation W\n",
            "20 cation W -> ation We\n",
            "21 ation We -> tion We \n",
            "22 tion We  -> ion We d\n",
            "23 ion We d -> on We do\n",
            "24 on We do -> n We don\n",
            "25 n We don ->  We don'\n",
            "26  We don' -> We don't\n",
            "27 We don't -> e don't \n",
            "28 e don't  ->  don't n\n",
            "29  don't n -> don't ne\n",
            "30 don't ne -> on't nee\n",
            "31 on't nee -> n't need\n",
            "32 n't need -> 't need \n",
            "33 't need  -> t need n\n",
            "34 t need n ->  need no\n",
            "35  need no -> need no \n",
            "36 need no  -> eed no t\n",
            "37 eed no t -> ed no th\n",
            "38 ed no th -> d no tho\n",
            "39 d no tho ->  no thou\n",
            "40  no thou -> no thoug\n",
            "41 no thoug -> o though\n",
            "42 o though ->  thought\n",
            "43  thought -> thought \n",
            "44 thought  -> hought c\n",
            "45 hought c -> ought co\n",
            "46 ought co -> ught con\n",
            "47 ught con -> ght cont\n",
            "48 ght cont -> ht contr\n",
            "49 ht contr -> t contro\n",
            "50 t contro ->  control\n",
            "51  control -> control \n",
            "52 control  -> ontrol N\n",
            "53 ontrol N -> ntrol No\n",
            "54 ntrol No -> trol No \n",
            "55 trol No  -> rol No d\n",
            "56 rol No d -> ol No da\n",
            "57 ol No da -> l No dar\n",
            "58 l No dar ->  No dark\n",
            "59  No dark -> No dark \n",
            "60 No dark  -> o dark s\n",
            "61 o dark s ->  dark sa\n",
            "62  dark sa -> dark sar\n",
            "63 dark sar -> ark sarc\n",
            "64 ark sarc -> rk sarca\n",
            "65 rk sarca -> k sarcas\n",
            "66 k sarcas ->  sarcasm\n",
            "67  sarcasm -> sarcasm \n",
            "68 sarcasm  -> arcasm i\n",
            "69 arcasm i -> rcasm in\n",
            "70 rcasm in -> casm in \n",
            "71 casm in  -> asm in t\n",
            "72 asm in t -> sm in th\n",
            "73 sm in th -> m in the\n",
            "74 m in the ->  in the \n",
            "75  in the  -> in the c\n",
            "76 in the c -> n the cl\n",
            "77 n the cl ->  the cla\n",
            "78  the cla -> the clas\n",
            "79 the clas -> he class\n",
            "80 he class -> e classr\n",
            "81 e classr ->  classro\n",
            "82  classro -> classroo\n",
            "83 classroo -> lassroom\n",
            "84 lassroom -> assroom \n",
            "85 assroom  -> ssroom T\n",
            "86 ssroom T -> sroom Te\n",
            "87 sroom Te -> room Tea\n",
            "88 room Tea -> oom Teac\n",
            "89 oom Teac -> om Teach\n",
            "90 om Teach -> m Teache\n",
            "91 m Teache ->  Teacher\n",
            "92  Teacher -> Teachers\n",
            "93 Teachers -> eachers,\n",
            "94 eachers, -> achers, \n",
            "95 achers,  -> chers, l\n",
            "96 chers, l -> hers, le\n",
            "97 hers, le -> ers, lea\n",
            "98 ers, lea -> rs, leav\n",
            "99 rs, leav -> s, leave\n",
            "100 s, leave -> , leave \n",
            "101 , leave  ->  leave t\n",
            "102  leave t -> leave th\n",
            "103 leave th -> eave the\n",
            "104 eave the -> ave them\n",
            "105 ave them -> ve them \n",
            "106 ve them  -> e them k\n",
            "107 e them k ->  them ki\n",
            "108  them ki -> them kid\n",
            "109 them kid -> hem kids\n",
            "110 hem kids -> em kids \n",
            "111 em kids  -> m kids a\n",
            "112 m kids a ->  kids al\n",
            "113  kids al -> kids alo\n",
            "114 kids alo -> ids alon\n",
            "115 ids alon -> ds alone\n",
            "116 ds alone -> s alone \n",
            "117 s alone  ->  alone H\n",
            "118  alone H -> alone He\n",
            "119 alone He -> lone Hey\n",
            "120 lone Hey -> one Hey!\n",
            "121 one Hey! -> ne Hey! \n",
            "122 ne Hey!  -> e Hey! T\n",
            "123 e Hey! T ->  Hey! Te\n",
            "124  Hey! Te -> Hey! Tea\n",
            "125 Hey! Tea -> ey! Teac\n",
            "126 ey! Teac -> y! Teach\n",
            "127 y! Teach -> ! Teache\n",
            "128 ! Teache ->  Teacher\n",
            "129  Teacher -> Teacher!\n",
            "130 Teacher! -> eacher! \n",
            "131 eacher!  -> acher! L\n",
            "132 acher! L -> cher! Le\n",
            "133 cher! Le -> her! Lea\n",
            "134 her! Lea -> er! Leav\n",
            "135 er! Leav -> r! Leave\n",
            "136 r! Leave -> ! Leave \n",
            "137 ! Leave  ->  Leave u\n",
            "138  Leave u -> Leave us\n",
            "139 Leave us -> eave us \n",
            "140 eave us  -> ave us k\n",
            "141 ave us k -> ve us ki\n",
            "142 ve us ki -> e us kid\n",
            "143 e us kid ->  us kids\n",
            "144  us kids -> us kids \n",
            "145 us kids  -> s kids a\n",
            "146 s kids a ->  kids al\n",
            "147  kids al -> kids alo\n",
            "148 kids alo -> ids alon\n",
            "149 ids alon -> ds alone\n",
            "150 ds alone -> s alone!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
        "\n",
        "print(x_data[0])\n",
        "print(y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125f6604-612e-427b-c550-c8ff03eb4cc3",
        "id": "Tlhox0E_Vnft"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10, 15, 0, 3, 22, 1, 6, 5]\n",
            "[15, 0, 3, 22, 1, 6, 5, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1caca71f-8987-440b-8d6d-4f0359374c2e",
        "id": "4l4cb2sLVnft"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.eye(len(vocab))[x] for x in x_data]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor, LongTesor 중 맞는 것은?)\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data) # cross entropy loss expects its label to be long tensor type"
      ],
      "metadata": {
        "id": "AfE360ANVnft"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape)) \n",
        "# 188개의 data에 대해 한 data당 10개의 단어에 해당하는 길이 26의 vector\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f0c13a-e4fc-45b0-a13b-f12250cce642",
        "id": "LFeYA76XVnfu"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([151, 8, 27])\n",
            "레이블의 크기 : torch.Size([151, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14812abc-a1c4-4b34-bae6-be9cc832f1ca",
        "id": "t6-3E0znVnfu"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f772e68-86ad-4309-e40e-f57f0a08b8e4",
        "id": "xHsi6Il3Vnfu"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15,  0,  3, 22,  1,  6,  5,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.layers = layers\n",
        "    self.rnn = torch.nn.RNN(input_size = input_dim, hidden_size = hidden_dim,\n",
        "                            num_layers = layers)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, 27)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x, hidden = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "HqQrEm57Vnfu"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "eWyFB0aRVnfu"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "Vquj55UyVnfu"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3313456-e49c-42a4-91d9-4f8392cc713c",
        "id": "YpS9TG9SVnfv"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([151, 8, 27])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8e86cb-562c-420c-a8e7-bcb2c47526c8",
        "id": "8_blINcZVnfv"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([151, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, 27), Y.view(151 * 8))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99e565f-c965-4143-bcfe-33847ff935bc",
        "id": "gIp2ow6GVnfv"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seeessTsee,,,,,,e,,,,,,W,,,ee,,,,,,ee,,,,,,eee,s,e,e,,,,W,ee,se,,,,e,T,,,,,,We,,W,,,,,,,,,W,ese,,,T,,,,ee,,W,eWW,eee,,,,,e,,,,,,W,W,,,,T,,eW,,,a,,,a,e,,,,,e,,\n",
            "eeeeeeseeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
            "eeeeeeeeeee                                                                                                                                                   \n",
            "eeeeee eee                                                                                                                                                    \n",
            "eee ee ee                                                                                                                                                     \n",
            "e e  e  ee                                                                                                                                                    \n",
            "e e  e  ee                                                                                                                                                    \n",
            "e e  e  ee                 e                                                                          n                                                       \n",
            "e n  e  ne    ee           e        e    e                 n       n       n         n                ne    n                    ne       ne    n             \n",
            "e n  e  ne    ee   s       e n      e    ee      e         n       n       n         n  s e  e s e    ne    n e   e     en     n ne s e   ne s  n         en  \n",
            "e e  e  ee    ee   s       e n      e    ee      e         n       n  s    nee       s  s e  e s e    ne s  see   ee    en  ne s ne s e   ne s  se s      en  \n",
            "e e  e  ee s  ee   se  e   e s      e s  ee e    e  e      ne    s ne s    seene   e s  s e  e see    se s  see   ee    ene se s  e se    ne se se se    nen  \n",
            "e e  e  ee s  eene se ne   e se s  ne s  eene s  e  e      se s  s ne ce   seese   e se she  e sees   se se see   ee   eene se s  e se s  se se se se s  sene \n",
            "e e ee  ee s  eene ce ees  e se s  ee s  eene s  e ne      se s  s ne ce   seese   e se che  e cees   se se cee  see  shene se c ne se s  se se ce se s  sene \n",
            "e e ee  ne s  eene ce ees  e se o  ee s  eene s  e ne      se s  s se ce   ceese  ce se che  e cee c  se ce cee  see  chene ce c ne cee c ne ce ce se s chene \n",
            "e e ee  ne s  eene ce e s  e se    ee s  eene    e se      ce d  s se c r  ceesee ce se che se cee c  ce ce cee  see  chene ce c ne cee c ne ce ce se   chene \n",
            "e n oe  ne s  e de ch   s te ce    ee s  e eee  he ce      ceed  c se c    ceedee ce sh che ce cee c  ce ce cee cle s  lene ce c ne cee c ne ce ce sh   clene \n",
            "e n oe  ne s  e ee c    d te ce    ne d  e eee   e ce      ce d  c se c    ceedee ce ch che ce cee c  ce ce cee cle s  lene ce c ce cee c ne ce ce ch d clene \n",
            "e n oe  ne s  e ee c  o d ce ce    ne d  e eee   e ce   d  ce d rc ce c r  ce dee ce ch ch  ce cee c  ce ce cee cleds clene ce c ce cee c ne ce ce ch s clene \n",
            "e n oe  ne c ne ee c  e d ce ce    ne d  e ee    e ce   s  ce d rc cerc d  ce dee ch ce c   ce cee c  le ce ce   leds clene ce c ce che c ce ce ce ce s clene \n",
            "e n oe  ne c ne ee c need ce ce    ne d ne ee  che ce   s  ce d rc nerc d  ce dee cl se c   ce che c  le ce ce   leds clene ce c ce che c Te ce ce ce s rlene \n",
            "e n oe  ne c ne eerchne s te ce    ne d ne ee  che ce   s  ce d rc nerc n  ce tee cl sh c   ce che c  le ce ch   leds  lene ce c ce che c Te ce ce ch s  lene \n",
            "e n ne  ne c ne eerchne s te ce    ne d ne ee rche ce   s  te d rc nerc ns ce tee cl sh s   ve cherc  le ce ch   leds  lene ce c ce cherc Te ce se ch s  lene \n",
            "e n ne  ne s ne eerc ne s te ce    ne d ne ee r he chee c  te d rc nerc ds ce tee cl sh s   ve cherc  lerce sh   leds  l ne ce c ce cherc ne ce se ch s  lene \n",
            "e n ne  ne d ne eerc ni s te sen   ne d ne eeer  e chee c  te d rl derl d  ke tee cl sh s   ve cherc  lerce she  leds  l ne ce c ce cherc Te ce se ch s  l ne \n",
            "e n n   ne d ne eerc nies te den   ne d ne eeer  e chee c  te d rl derl ds ke the cl sh d   ve cherc  lerce shn  keds  l ne cerc ce chers Te ce ds ch s  l ne \n",
            "e n n   ne d ne eerc nies te d n   ne d ne eeer he chee cl te d rl derl ds ke the cl ss d   ve chers  le ce thn  keds  lene cerc ce chers Te ce ds kh s  lene \n",
            "e n n o ne d ne eerc ties te d n   ne d ne eeerc e che  cl te d rl derl ds ke the cl ss d   ke chers  le ce thed keds  lene cerc ceachers Te ce ds kh s  lene \n",
            "e n n o ne d ne eerc ties te d n   ne d ne eeerc e che  co te d rl d rl ds ke the cl ss t   ke chers  le ce thed keds  l ne cerc ceachers Te ce ds kids  l ne \n",
            "e n n o ne d ne eerc ties te d n t ne d ne eeerche che  no te d rl d rl ds ke the cl ss t   keachers  le ce the  kids  lene cerc ceachers Te ce ds kids  lene \n",
            "e n n o ne d no eerc ties te d n t ne d no eeerche cee  no te t rl d rl ds ke the cl ss t   keachers  le ce the  kids  lene cerc ceachers Te ce ds kids  lene \n",
            "e n n o ne d no eerc tien te d n t ne d no t eughe cee  ol te t rl d rl ds ie the cl ss t   Teachers  le ce thn  kids  lene ceak ceachers Te ce ds kids alene \n",
            "e n n o ne d no terc tien te d n't ne d no t eughe chet  l to t rl d rl ss ie the cl ss to  Teachers, leace thn  kids alene ceak Teachers Te ce ds kids alene \n",
            "e n n o ne d no terc tien te d n't ne d no t eughe ceet  l to t rl d rl ss ie the cl ss on  Teachers, leace thn  kids alene ceak Teachers Te ce ds kids alene \n",
            "e n n o ne d no terc tien te d n't ne d no t eughe ceet  l to t rl s rl ss ie the cl ss on  Teachers, leace the  kids alene ceak Teachers Te ce ds kids alene \n",
            "e n n o ne d no tdrcatien te d n't ne d no t eughe ceet  l to t rl s rl ss ie the cl ss on  Teachers, leace the  kids alene ceac Teachers Te ce ds kids alene \n",
            "e n n o ne d no tdrcatien te d n't need no t eughe ceet  l to d rl s rl ss ie the cl ssron  Teacher!, leace the  kids alene ceak Teacher! Teace ds kids alene \n",
            "e n n o ne d no edrcatien te don't need no t eughe coet ol to d rk s rc s  ie the cl ssronm Teacher!, leace the  kids alene ceak Teacher! Teace ds kids alene \n",
            "e n n o ne d no edrcation te don't need no t eughe cont ol to d rk s rc s  ie the cl ssronm Teacher!, leace the  kids alene cea! Teacher! Teace ds kids alene \n",
            "e n n o ne d no edrcation te don't need no tteughe coet ol No d rl s rc s  ie the cl ss onm Teacher!, leace the  kids alene cea! Teacher! Teace us kids alone \n",
            "e n n o ne d no edrcation te don't need no t eught cont ol No d rk s rc s  ie the cl ssronm Teacher!, leace them kids alene cea! Teacher! Teace us kids alene \n",
            "e n n o ne d no edrcation te don't need no theught cont ol No d rk s rc s  ie the cl ssronm Teacher!, leace them kids alene cer! Teacher! Teace us kids alone \n",
            "e n n o ne d no edrcation te don't need no theught cont ol No d rk s rc s  io the cl ssronm Teacher!, leace them kids alene cer! Teacher! Teace us kids alone \n",
            "e n n o need no edrcation te don't need no thought cont ol No d rk s rcas  io the cl ssronm Teachers, leace them kids alene cea! Teacher! Teace us kids alone \n",
            "e n n o need no education te don't need no thought cont ol No d rk s rcas  io the classronm Teacher!, leace them kids alone cer! Teacher! Teace us kids alone \n",
            "e non o need no education te don't need no thought cont ol No d rk s rcas  io the classroom Teachers, leace them kids alone kea! Teacher! Teace us kids alone \n",
            "e non o need no education te don't need no thought cont ol No d rk s rcas  io the cl ssroom Teachers, leace them kids alone kea! Teacher! Teace us kids alone \n",
            "e non o need no education te don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone cer! Teacher! Teace us kids alone \n",
            "e non o need no education Ne don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone cea! Teacher! Teace us kids alone \n",
            "e non thneed no education Ne don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone kea! Teacher! Teace us kids alone \n",
            "e non thneed no education Ne don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone Hey! Teacher! Teave us kids alone \n",
            "e non thneed no education Ne don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone Hey! Teacher! Teave us kids alone \n",
            "e non thneed no education Ne don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone Hey! Teacher! Teave us kids alone \n",
            "e non t need no education Ne don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone Hey! Teacher! Teave us kids alone \n",
            "e non t need no education Ne don't need no thought control No d rk sarcasm io the classroom Teachers, leave them kids alone Hey! Teacher! Teave us kids alone \n",
            "e non t need no education Ne don't need no thought control No dark sarcasm io the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education Ne don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education Ne don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education Ne don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education Ne don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e non t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids alone \n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don t need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n",
            "e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a9b60864-fcf3-41a2-b18d-8c2688d03ee6",
        "id": "EQDF6QkSVnfw"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"e don't need no education We don't need no thought control No dark sarcasm in the classroom Teachers, leave them kids alone Hey! Teacher! Leave us kids aloner\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "큰 수정 없이 sequence length와 shape만 조금 바꿔줘어서 돌렸는데 크게 나쁘지는 않은 결과가 나온 것 같다."
      ],
      "metadata": {
        "id": "2Nx8YDVmVnfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 한국어"
      ],
      "metadata": {
        "id": "ancZiOIFYkyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 사용한 가사를 번역해서 사용"
      ],
      "metadata": {
        "id": "yOUuupXS3cqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"우리는 교육이 필요 없습니다 \"\n",
        "            \"우리는 사고 통제가 필요하지 않습니다 \"\n",
        "            \"교실에서 어두운 풍자 금지 \"\n",
        "            \"선생님, 아이들은 그냥 두세요 \"\n",
        "            \"이봐! 선생님! 아이들을 그냥 내버려 두세요!\")"
      ],
      "metadata": {
        "id": "oPHDPhCSYMjz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTRWJXNFip7_",
        "outputId": "9649f678-75fe-43c5-c99c-e1034b8fbf1c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "띄어쓰기만으로도 어느 정도의 토큰화가 가능한 영어와는 달리, 조사, 어미 등이 존재하는 한국어는 형태소 단위로 토큰화를 진행해주어야한다고 한다. 따라서 한국어 토큰화를 위해 한국어 자연어처리를 위한 패키지인 KoNLPy의 다양한 클래스를 사용해보았다."
      ],
      "metadata": {
        "id": "9wvsXusZZULl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t14m5t_FZaIT",
        "outputId": "05aa21e0-be7a-492d-a8ca-9eca8894016a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "wH4lvcsU_OyT"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.chdir('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "id": "qz3YyNZk_IZx"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 한나눔"
      ],
      "metadata": {
        "id": "YvP5JCpijgCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Hannanum\n",
        "hannanum=Hannanum()"
      ],
      "metadata": {
        "id": "FszS2WqggJp_"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hannanum.morphs(sentence))"
      ],
      "metadata": {
        "id": "cb0U_qWbicJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595988ee-b613-4f29-aae3-30659efadbad"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['우리', '는', '교육', '이', '필요', '없', '습니다', '우리', '는', '사', '고', '통제', '가', '필요', '하', '지', '않', '습니다', '교실', '에서', '어둡', '은', '풍자', '금지', '선생님', ',', '아이들', '은', '그냥', '두', '이', '세', '요', '이봐', '!', '선생님', '!', '아이들', '을', '그냥', '내', '어', '버리', '어', '두', '세', '요', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사고를 동사 사고로 인식해서 사 + 고로 분리한 듯 하다.  \n",
        "아이 + 들이 아닌 아이들로 토큰화했다.  \n",
        "선생 + 님이 아닌 선생님으로 토큰화했다.\n",
        "두세요를 두 + 시 + 어요가 아닌 두 + 이 + 세 + 요, 두 + 세 + 요 등 서로 다른 잘못된 방법으로 분리하고 있다.  \n",
        "내버려두다를 내버리 + 어 + 두다가 아닌 내 + 어 + 버리 + 어 + 두로 분리하고 있다.\n"
      ],
      "metadata": {
        "id": "Xgp5V2KKj6ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 꼬꼬마"
      ],
      "metadata": {
        "id": "SjjF-oQ9jlv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Kkma\n",
        "kkma=Kkma()"
      ],
      "metadata": {
        "id": "Bpio27udijhQ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kkma.morphs(sentence))"
      ],
      "metadata": {
        "id": "a7ZA3UZvjrjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e6c0b3-64f2-4a7a-9b89-4a6163ec52e5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['우리', '는', '교육', '이', '필요', '없', '습니다', '우리', '는', '사고', '통제', '가', '필요', '하', '지', '않', '습니다', '교실', '에서', '어둡', 'ㄴ', '풍자', '금지', '선생님', ',', '아이', '들', '은', '그냥', '두', '세요', '이봐', '!', '선생님', '!', '아이', '들', '을', '그냥', '내버리', '어', '두', '세요', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한나눔과는 다르게 사고를 사 + 고가 아닌 사고로 잘 분리했다.  \n",
        "아이들도 아이 + 들로 잘 토큰화했다.  \n",
        "선생님은 여전히 선생 + 님이 아닌 선생님으로 분리되어있다.\n",
        "한나눔은 어두운을 어둡 + 은으로 잘 분리했으나 꼬꼬마에서는 어둡 + ㄴ으로 분리하고 있다.  \n",
        "두세요는 두 + 시 + 어요가 아닌 두+세요로 분리되어있다.   \n",
        "내버려두다는 내버리 + 어 + 두다로 잘 분리되어있다.\n"
      ],
      "metadata": {
        "id": "e41dyd0ykLJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 코모란"
      ],
      "metadata": {
        "id": "NNkmxPTEmVJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Komoran\n",
        "komoran=Komoran()"
      ],
      "metadata": {
        "id": "veEoPhySjtZZ"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(komoran.morphs(sentence))"
      ],
      "metadata": {
        "id": "fiIcRe58mbAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5e22e1-db02-4c00-d3a3-dc5ce3f4724f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['우리', '는', '교육', '이', '필요', '없', '습니다', '우리', '는', '사고', '통제', '가', '필요', '하', '지', '않', '습니다', '교실', '에서', '어둡', 'ㄴ', '풍자', '금지', '선생님', ',', '아이들', '은', '그냥', '두', '시', '어요', '이봐', '!', '선생님', '!', '아이', '들', '을', '그냥', '내버리', '어', '두', '시', '어요', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "어두운이 꼬꼬마와 마찬가지로 어둡 + ㄴ 으로 분리되어있다.  \n",
        "선셍님도 선생 + 님이 아닌 선생님으로 분리되어있다.  \n",
        "뒤에 나오는 아이들은 아이 + 들로 잘 분리되어있지만 처음 나오는 아이들은 한나눔 때와 마찬가지로 아이들로 토큰화되었다.  \n",
        "두세요의 경우 두 + 시 + 어요로 잘 분리되어있다."
      ],
      "metadata": {
        "id": "-g6os7tOmYfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Okt"
      ],
      "metadata": {
        "id": "CGnob6_mn3fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt=Okt()"
      ],
      "metadata": {
        "id": "wYLOp9WAnwQc"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(okt.morphs(sentence))"
      ],
      "metadata": {
        "id": "A_tSDObpn9rx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125926ef-26ce-4012-bef6-d5b31e53e382"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['우리', '는', '교육', '이', '필요', '없습니다', '우리', '는', '사고', '통제', '가', '필요하지', '않습니다', '교실', '에서', '어', '두운', '풍자', '금지', '선생님', ',', '아이', '들', '은', '그냥', '두세요', '이', '봐', '!', '선생님', '!', '아이', '들', '을', '그냥', '내버려', '두세요', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "언뜻 보기에도 형태소 분리가 이루어지지 않은 단어들이 많아 위와 같은 주석은 안 달았음"
      ],
      "metadata": {
        "id": "YScht4JRoGsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mecab"
      ],
      "metadata": {
        "id": "qANK7KuRy-Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩용 Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "id": "MFzrsb9eyMSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "# 런타임 재시작 안하면 계속 install이 안됐다고 오류 뜸"
      ],
      "metadata": {
        "id": "8Sm8J5stzatq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mecab.morphs(sentence))"
      ],
      "metadata": {
        "id": "Sjxg0-zDz0nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a4983c-88d3-40b2-f424-610810b0bde4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['우리', '는', '교육', '이', '필요', '없', '습니다', '우리', '는', '사고', '통제', '가', '필요', '하', '지', '않', '습니다', '교실', '에서', '어두운', '풍자', '금지', '선생', '님', ',', '아이', '들', '은', '그냥', '두', '세요', '이봐', '!', '선생', '님', '!', '아이', '들', '을', '그냥', '내버려', '두', '세요', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "어두운이 형태소 분리가 안돼있음  \n",
        "선생님이 처음으로 선생 + 님으로 잘 분리가 되었다.  \n",
        "내버려가 내버리 + 어로 분리가 안돼있음\n",
        "두세요도 두 + 시 + 어요 로 분리가 안돼있음"
      ],
      "metadata": {
        "id": "uzv3DEb21-7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토큰화"
      ],
      "metadata": {
        "id": "r6IShjU2Unzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "패키지들의 성능이 엇비슷하지만 그래도 내 경우의 가장 성능이 좋았다고 생각되는 코모란을 샤용하겠음"
      ],
      "metadata": {
        "id": "lKTPNzZQ2e5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Komoran\n",
        "komoran = Komoran()"
      ],
      "metadata": {
        "id": "_rXby8bm2lwf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordset = komoran.morphs(sentence)"
      ],
      "metadata": {
        "id": "kYoQCP0ow8On"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordset)"
      ],
      "metadata": {
        "id": "YR70a0fQ2qIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a03f15c-d510-4a9e-88c7-5afcd237cd3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['우리', '는', '교육', '이', '필요', '없', '습니다', '우리', '는', '사고', '통제', '가', '필요', '하', '지', '않', '습니다', '교실', '에서', '어둡', 'ㄴ', '풍자', '금지', '선생님', ',', '아이들', '은', '그냥', '두', '시', '어요', '이봐', '!', '선생님', '!', '아이', '들', '을', '그냥', '내버리', '어', '두', '시', '어요', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordset[20] = '은'\n",
        "\n",
        "for i in range(len(wordset)):\n",
        "  if wordset[i] == \"선생님\":\n",
        "    wordset[i] = \"선생\"\n",
        "    wordset.insert(i + 1, \"님\")\n",
        "\n",
        "for i in range(len(wordset)):\n",
        "  if wordset[i] == \"아이들\":\n",
        "    wordset[i] = \"아이\"\n",
        "    wordset.insert(i + 1, \"들\")\n",
        "\n",
        "wordset.append(' ')"
      ],
      "metadata": {
        "id": "ScZplUgwShoN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코모란을 이용한 후 부족하다고 생각되는 부분들은 직접 바꿔주거나 분리해주었음"
      ],
      "metadata": {
        "id": "bV7N1QRwyB3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt1zq6WuTVM8",
        "outputId": "32233c34-246a-44c4-b77e-107b2ba3026e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['우리', '는', '교육', '이', '필요', '없', '습니다', '우리', '는', '사고', '통제', '가', '필요', '하', '지', '않', '습니다', '교실', '에서', '어둡', '은', '풍자', '금지', '선생', '님', ',', '아이', '들', '은', '그냥', '두', '시', '어요', '이봐', '!', '선생', '님', '!', '아이', '들', '을', '그냥', '내버리', '어', '두', '시', '어요', '!', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# u_wordset = list(set(wordset))\n",
        "u_wordset = list(pd.unique(wordset))"
      ],
      "metadata": {
        "id": "KIT-p-YG3S0m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "input의 unique한 값들을 랜덤한 순서로 return하는 set을 쓸 때보다 원래 가지고 있던 고유한 순서대로 return하는 pd.unique를 썼을 때가 더 그럴듯한 문장이 예측되었음.  \n",
        "우연에 의한 것인지, 아니면 일부러 무작위성 부여를 위해 set을 쓰는 거라서 이런 방법을 쓰면 안되는 건지 모르겠지만 우선 이렇게 진행함"
      ],
      "metadata": {
        "id": "Dao3LNxnlIqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token: i for i, token in enumerate(u_wordset)}\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-izK3JSo7su",
        "outputId": "5b77e215-5536-439d-b628-93089ce5fc2b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'우리': 0, '는': 1, '교육': 2, '이': 3, '필요': 4, '없': 5, '습니다': 6, '사고': 7, '통제': 8, '가': 9, '하': 10, '지': 11, '않': 12, '교실': 13, '에서': 14, '어둡': 15, '은': 16, '풍자': 17, '금지': 18, '선생': 19, '님': 20, ',': 21, '아이': 22, '들': 23, '그냥': 24, '두': 25, '시': 26, '어요': 27, '이봐': 28, '!': 29, '을': 30, '내버리': 31, '어': 32, ' ': 33}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Smoqz1yIRe",
        "outputId": "409aee6a-e630-4ec8-f2dd-fe3d45ea35d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequence 길이 단위 자르기"
      ],
      "metadata": {
        "id": "7OVaPjsjyUsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #5. seqence 길이 단위 자르기\n",
        "\n",
        "# # 데이터 구성을 위한 리스트\n",
        "# x_data = []\n",
        "# y_data = []\n",
        "\n",
        "# ## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "# for i in range(0, len(sentence) - sequence_length):\n",
        "#   x_str = sentence[i : (sequence_length + i)]\n",
        "#   y_str = sentence[(i + 1) : (sequence_length + i + 1)]\n",
        "#   print(i, x_str, \"->\", y_str)\n",
        "\n",
        "#   # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "#   x_data.append([vocab[c] for c in x_str])\n",
        "#   y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "id": "-EoIKXFUySJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 코드를 그대로 사용했을 경우에 발생하는 문제\n",
        "\n",
        "\n",
        "\n",
        "*   x_str = sentence[i : (sequence_length + i)]:  \n",
        "현재 나는 형태소 단위의 sequencing을 하고자 했는데 이 방식을 사용 시, 그냥 길이에 맞게끔 단어가 중간에 잘려버리는 문제가 발생함 \n",
        "*   x_data.append([vocab[c] for c in x_str]):  \n",
        "이 역시 형태소 한 단위단위가 매 루프마다 추가되길 원하지만 이 코드를 그대로 사용했을 시, 한 글자씩 잘려서 들어가게 되기 때문에(예를 들어 '우리'가 아닌 '우'를 추가하려고 함) vocab에 해당 단어가 존재하지 않아 오류를 발생시키게 된다.  \n",
        "\n",
        "\n",
        "따라서 아래와 같은 방법으로 위 코드의 기능을 수행함\n",
        "\n"
      ],
      "metadata": {
        "id": "ko4hIqjKyqqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = wordset[:-1]\n",
        "y = wordset[1:]"
      ],
      "metadata": {
        "id": "oJgXFFgUpAIz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_voc = []\n",
        "y_voc = []\n",
        "\n",
        "for c in x:\n",
        "  for key, value in vocab.items():\n",
        "    if key == c:\n",
        "      x_voc.append(value)\n",
        "\n",
        "for d in y:\n",
        "  for key, value in vocab.items():\n",
        "    if key == d:\n",
        "      y_voc.append(value)"
      ],
      "metadata": {
        "id": "y1DuyhdzpD5R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 8  # 너무 길거나 너무 짧게 잡으면 안됩니다!\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "N83Kr5f6Ub1_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_seq = []\n",
        "y_seq = []\n",
        "\n",
        "for i in range(len(x_voc) - sequence_length + 1):\n",
        "  x_seq.append(x_voc[i: i + sequence_length])\n",
        "  y_seq.append(y_voc[i: i + sequence_length])"
      ],
      "metadata": {
        "id": "LjodFKemsf0e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_seq)\n",
        "print(y_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLZJqDxPtTSr",
        "outputId": "5058ad42-8146-4db1-cad0-b05f7af478f1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2, 3, 4, 5, 6, 0], [1, 2, 3, 4, 5, 6, 0, 1], [2, 3, 4, 5, 6, 0, 1, 7], [3, 4, 5, 6, 0, 1, 7, 8], [4, 5, 6, 0, 1, 7, 8, 9], [5, 6, 0, 1, 7, 8, 9, 4], [6, 0, 1, 7, 8, 9, 4, 10], [0, 1, 7, 8, 9, 4, 10, 11], [1, 7, 8, 9, 4, 10, 11, 12], [7, 8, 9, 4, 10, 11, 12, 6], [8, 9, 4, 10, 11, 12, 6, 13], [9, 4, 10, 11, 12, 6, 13, 14], [4, 10, 11, 12, 6, 13, 14, 15], [10, 11, 12, 6, 13, 14, 15, 16], [11, 12, 6, 13, 14, 15, 16, 17], [12, 6, 13, 14, 15, 16, 17, 18], [6, 13, 14, 15, 16, 17, 18, 19], [13, 14, 15, 16, 17, 18, 19, 20], [14, 15, 16, 17, 18, 19, 20, 21], [15, 16, 17, 18, 19, 20, 21, 22], [16, 17, 18, 19, 20, 21, 22, 23], [17, 18, 19, 20, 21, 22, 23, 16], [18, 19, 20, 21, 22, 23, 16, 24], [19, 20, 21, 22, 23, 16, 24, 25], [20, 21, 22, 23, 16, 24, 25, 26], [21, 22, 23, 16, 24, 25, 26, 27], [22, 23, 16, 24, 25, 26, 27, 28], [23, 16, 24, 25, 26, 27, 28, 29], [16, 24, 25, 26, 27, 28, 29, 19], [24, 25, 26, 27, 28, 29, 19, 20], [25, 26, 27, 28, 29, 19, 20, 29], [26, 27, 28, 29, 19, 20, 29, 22], [27, 28, 29, 19, 20, 29, 22, 23], [28, 29, 19, 20, 29, 22, 23, 30], [29, 19, 20, 29, 22, 23, 30, 24], [19, 20, 29, 22, 23, 30, 24, 31], [20, 29, 22, 23, 30, 24, 31, 32], [29, 22, 23, 30, 24, 31, 32, 25], [22, 23, 30, 24, 31, 32, 25, 26], [23, 30, 24, 31, 32, 25, 26, 27], [30, 24, 31, 32, 25, 26, 27, 29]]\n",
            "[[1, 2, 3, 4, 5, 6, 0, 1], [2, 3, 4, 5, 6, 0, 1, 7], [3, 4, 5, 6, 0, 1, 7, 8], [4, 5, 6, 0, 1, 7, 8, 9], [5, 6, 0, 1, 7, 8, 9, 4], [6, 0, 1, 7, 8, 9, 4, 10], [0, 1, 7, 8, 9, 4, 10, 11], [1, 7, 8, 9, 4, 10, 11, 12], [7, 8, 9, 4, 10, 11, 12, 6], [8, 9, 4, 10, 11, 12, 6, 13], [9, 4, 10, 11, 12, 6, 13, 14], [4, 10, 11, 12, 6, 13, 14, 15], [10, 11, 12, 6, 13, 14, 15, 16], [11, 12, 6, 13, 14, 15, 16, 17], [12, 6, 13, 14, 15, 16, 17, 18], [6, 13, 14, 15, 16, 17, 18, 19], [13, 14, 15, 16, 17, 18, 19, 20], [14, 15, 16, 17, 18, 19, 20, 21], [15, 16, 17, 18, 19, 20, 21, 22], [16, 17, 18, 19, 20, 21, 22, 23], [17, 18, 19, 20, 21, 22, 23, 16], [18, 19, 20, 21, 22, 23, 16, 24], [19, 20, 21, 22, 23, 16, 24, 25], [20, 21, 22, 23, 16, 24, 25, 26], [21, 22, 23, 16, 24, 25, 26, 27], [22, 23, 16, 24, 25, 26, 27, 28], [23, 16, 24, 25, 26, 27, 28, 29], [16, 24, 25, 26, 27, 28, 29, 19], [24, 25, 26, 27, 28, 29, 19, 20], [25, 26, 27, 28, 29, 19, 20, 29], [26, 27, 28, 29, 19, 20, 29, 22], [27, 28, 29, 19, 20, 29, 22, 23], [28, 29, 19, 20, 29, 22, 23, 30], [29, 19, 20, 29, 22, 23, 30, 24], [19, 20, 29, 22, 23, 30, 24, 31], [20, 29, 22, 23, 30, 24, 31, 32], [29, 22, 23, 30, 24, 31, 32, 25], [22, 23, 30, 24, 31, 32, 25, 26], [23, 30, 24, 31, 32, 25, 26, 27], [30, 24, 31, 32, 25, 26, 27, 29], [24, 31, 32, 25, 26, 27, 29, 33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원핫인코딩"
      ],
      "metadata": {
        "id": "-HNuov7XVWmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.eye(len(vocab))[x] for x in x_seq]\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor, LongTesor 중 맞는 것은?)\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_seq) # cross entropy loss expects its label to be long tensor type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oI4VDgQnEnS",
        "outputId": "0189c406-82d0-4cb9-f0e7-d0e7fb5eaca7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape)) \n",
        "# 188개의 data에 대해 한 data당 10개의 단어에 해당하는 길이 26의 vector\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e255d20e-7e7f-4a7e-871f-d8d0b8fd94bf",
        "id": "aG97Kp49nEnS"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([41, 8, 34])\n",
            "레이블의 크기 : torch.Size([41, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1d377d-90e1-4c37-8e66-e8a7f8aa0dba",
        "id": "KKxVPQDGnEnS"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5be0803-ecec-4c4d-a977-ef64fa0fa9bc",
        "id": "ojg7dn9dnEnS"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델"
      ],
      "metadata": {
        "id": "sYmIz0QGmp8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.layers = layers\n",
        "    self.rnn = torch.nn.RNN(input_size = input_dim, hidden_size = hidden_dim,\n",
        "                            num_layers = layers)\n",
        "    self.fc = torch.nn.Linear(hidden_dim, 34)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x, hidden = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "QzKO59s2nEnS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2)"
      ],
      "metadata": {
        "id": "c7eklOuZnEnS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "N8Nh2DfQnEnS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731f5fb3-bca0-47bc-bf06-199c980b3f01",
        "id": "lC-yS9vSnEnT"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([41, 8, 34])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725fd5c6-cd1a-49a5-e6d4-89362f0631b1",
        "id": "hMjGbg0PnEnT"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([41, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, 34), Y.view(41 * 8))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([wordset[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += wordset[result[-1]]\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70529a6-00e7-45f9-f841-d9f057b3a85c",
        "id": "XjtXd49anEnT"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "필요어요어요않않않않필요이필요필요않가않않않통제않통제어요가,않않통제않않어요통제이않통제않통제통제않통제사고통제어요통제통제않통제않통제않통제\n",
            "필요은은은않은은필요,은은은은사고은은은사고은은사고은은은사고사고사고어둡사고사고은사고사고은사고사고않사고사고어둡은은은은은어둡사고습니다\n",
            "은은은은은은은은,은은은은습니다습니다은어둡습니다습니다습니다어둡습니다은은습니다어둡금지습니다금지습니다은어둡어둡습니다어둡습니다습니다금지습니다습니다금지습니다은은은어둡습니다습니다\n",
            "은은은은은은은은,은,은은선생습니다은어둡습니다습니다습니다어둡습니다선생은선생금지선생습니다선생습니다은들선생습니다어둡선생습니다금지선생습니다금지습니다선생,은어둡선생습니다\n",
            "은은은은은은은은,은,은은선생그냥은어둡선생습니다습니다어둡습니다어둡은선생금지선생습니다님,은들선생그냥어둡선생그냥금지선생습니다님,님,은들선생그냥\n",
            "은은은은은습니다은은,은,은들아이그냥은하선생그냥습니다어둡그냥그냥은그냥금지선생습니다님,아이들아이그냥어둡은그냥금지선생습니다님,님,아이들아이그냥\n",
            "는은은은은습니다은는,는,필요들가그냥습니다하선생그냥습니다어둡그냥그냥은그냥금지선생습니다님,아이들아이그냥어둡은그냥금지선생습니다님,님,아이들아이그냥\n",
            "는은은은은습니다은는우리는,필요통제가그냥습니다하은않습니다교실그냥어둡은그냥금지선생습니다님,아이들은그냥어둡은그냥금지선생습니다님,님,아이들은그냥\n",
            "는은은필요은습니다습니다는우리는,필요통제가그냥습니다하지않습니다교실그냥어둡은그냥금지선생습니다님,아이들은그냥어둡선생그냥금지선생습니다님,아이,아이들은그냥\n",
            "는우리은필요은습니다습니다는우리는우리필요통제가필요습니다하지않습니다교실그냥어둡은그냥금지선생습니다님,아이들은그냥어둡은그냥금지선생습니다님,아이,아이들은그냥\n",
            "는우리는필요은습니다습니다는우리는우리필요통제가필요습니다하지않습니다교실그냥어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생습니다님,아이,아이들은그냥\n",
            "는우리는필요은습니다습니다는우리는우리필요통제가필요습니다하지않습니다교실그냥어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생습니다님,아이,아이들은그냥\n",
            "는우리는필요은습니다습니다는우리는우리필요통제가필요습니다하지않습니다교실그냥어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생습니다님,아이,아이들은그냥\n",
            "는우리는필요은습니다습니다는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생습니다님,아이,아이들은그냥\n",
            "는우리는필요은습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리는필요은습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리는필요은습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리는필요은습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리는필요은습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리는필요금지습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리는필요금지습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리이필요없습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님,아이,아이들은그냥\n",
            "는우리이필요없습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들은그냥\n",
            "는우리이필요없습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들은그냥\n",
            "는우리이필요없습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들은그냥\n",
            "는우리이필요없습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥습니다\n",
            "는우리이필요없습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥금지\n",
            "는우리이필요없습니다는는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥금지\n",
            "는우리이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥금지\n",
            "는우리이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥금지\n",
            "는우리이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥금지\n",
            "는우리이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥습니다\n",
            "는우리이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥그냥\n",
            "는우리이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥그냥\n",
            "는우리이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥그냥\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥그냥\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥그냥\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥그냥\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥그냥\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는교육는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n",
            "는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d962d450-05b6-48ac-85c3-5af08e85b9cc",
        "id": "s5Ng3QNYnEnT"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'는교육이필요없습니다우리는우리는사고필요통제가필요습니다하지않습니다교실에서어둡은풍자금지선생습니다님,아이들은그냥어둡은그냥금지선생두님시어요,아이들그냥이봐'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장이 그럴 듯하지는 못하지만 해보았다는 것에 의의!"
      ],
      "metadata": {
        "id": "S0w-umLLm__a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyKoSpacing을 이용한 띄어쓰기 해보기"
      ],
      "metadata": {
        "id": "yx1fxUaKnE99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "metadata": {
        "id": "1TZY_Znxg4gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pykospacing import Spacing\n",
        "spacing = Spacing()"
      ],
      "metadata": {
        "id": "xshzBWWahc6_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prd_str_sp = spacing(predict_str)\n",
        "print(prd_str_sp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luwr70Nvhlt0",
        "outputId": "4d82de10-5315-4417-c8dc-24b9f5f4c4b8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "는 교육이 필요 없습니다 우리는 우리는 사고 필요 통제가 필요습니다 하지 않습니다교실에서 어둡은 풍자금지 선생습니다님, 아이들은 그냥 어둡은 그냥 금지 선생 두님시어요, 아이들 그냥이 봐\n"
          ]
        }
      ]
    }
  ]
}