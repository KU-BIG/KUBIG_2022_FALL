{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6주차_과제_우명진.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nmQ5F7UAeKB_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task1\n",
        "\n",
        "빈 칸을 채워주세요!\n",
        "\n",
        "단계별 output이 github 파일에는 남아있으니 그 output과 동일한 형태인지 확인하면서 진행해주시면 됩니다~"
      ],
      "metadata": {
        "id": "Sgxd6SxmeVcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "sentence = (\"Brick walls are there for a reason and you must not think \"\n",
        "            \"that the brick walls aren't there to keep us out, but rather \"\n",
        "            \"in this way that the brick walls are there to show us how badly we want things.\")"
      ],
      "metadata": {
        "id": "NDvUeC8BoUb6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(sentence))\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {c: i for i, c in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "b9lkrKyZf8ie"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0we5Y-gYDq",
        "outputId": "17de0a6f-8948-44d4-f1c6-dfcd373be5e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'b': 0, 't': 1, 'o': 2, 'w': 3, \"'\": 4, 'r': 5, ' ': 6, ',': 7, 'a': 8, 'n': 9, 'f': 10, 'c': 11, 'l': 12, 'B': 13, 'k': 14, 'y': 15, 'i': 16, 'h': 17, 'p': 18, 'u': 19, 'm': 20, '.': 21, 'g': 22, 's': 23, 'e': 24, 'd': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpKupU6lgpfT",
        "outputId": "b23096ba-7509-4b93-ddb9-76bf3afa4511"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정(자유롭게 수정해보세요!)\n",
        "\n",
        "hidden_size = vocab_size # 같아야 하는 것 확인!\n",
        "sequence_length = 10  # 너무 길거나 너무 짧게 잡으면 안됩니다! #앞서 만든 샘플을 10개의 단위로 끊어서 샘플을 만드는 것\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "wFDZJHSMg9In"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "## 문제(2): 반복문 내에서의 인덱싱을 사용하여 sequence_length 값 단위로 샘플을 잘라 데이터 만들기, y_str은 x_str은 한 칸씩 쉬프트된 sequnce\n",
        "\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "  x_str = sentence[i:i + sequence_length] \n",
        "  y_str = sentence[i + 1: i + sequence_length + 1]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbDcmJmghN7V",
        "outputId": "677e374f-1d10-4e73-d1ce-530aca652c72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Brick wall -> rick walls\n",
            "1 rick walls -> ick walls \n",
            "2 ick walls  -> ck walls a\n",
            "3 ck walls a -> k walls ar\n",
            "4 k walls ar ->  walls are\n",
            "5  walls are -> walls are \n",
            "6 walls are  -> alls are t\n",
            "7 alls are t -> lls are th\n",
            "8 lls are th -> ls are the\n",
            "9 ls are the -> s are ther\n",
            "10 s are ther ->  are there\n",
            "11  are there -> are there \n",
            "12 are there  -> re there f\n",
            "13 re there f -> e there fo\n",
            "14 e there fo ->  there for\n",
            "15  there for -> there for \n",
            "16 there for  -> here for a\n",
            "17 here for a -> ere for a \n",
            "18 ere for a  -> re for a r\n",
            "19 re for a r -> e for a re\n",
            "20 e for a re ->  for a rea\n",
            "21  for a rea -> for a reas\n",
            "22 for a reas -> or a reaso\n",
            "23 or a reaso -> r a reason\n",
            "24 r a reason ->  a reason \n",
            "25  a reason  -> a reason a\n",
            "26 a reason a ->  reason an\n",
            "27  reason an -> reason and\n",
            "28 reason and -> eason and \n",
            "29 eason and  -> ason and y\n",
            "30 ason and y -> son and yo\n",
            "31 son and yo -> on and you\n",
            "32 on and you -> n and you \n",
            "33 n and you  ->  and you m\n",
            "34  and you m -> and you mu\n",
            "35 and you mu -> nd you mus\n",
            "36 nd you mus -> d you must\n",
            "37 d you must ->  you must \n",
            "38  you must  -> you must n\n",
            "39 you must n -> ou must no\n",
            "40 ou must no -> u must not\n",
            "41 u must not ->  must not \n",
            "42  must not  -> must not t\n",
            "43 must not t -> ust not th\n",
            "44 ust not th -> st not thi\n",
            "45 st not thi -> t not thin\n",
            "46 t not thin ->  not think\n",
            "47  not think -> not think \n",
            "48 not think  -> ot think t\n",
            "49 ot think t -> t think th\n",
            "50 t think th ->  think tha\n",
            "51  think tha -> think that\n",
            "52 think that -> hink that \n",
            "53 hink that  -> ink that t\n",
            "54 ink that t -> nk that th\n",
            "55 nk that th -> k that the\n",
            "56 k that the ->  that the \n",
            "57  that the  -> that the b\n",
            "58 that the b -> hat the br\n",
            "59 hat the br -> at the bri\n",
            "60 at the bri -> t the bric\n",
            "61 t the bric ->  the brick\n",
            "62  the brick -> the brick \n",
            "63 the brick  -> he brick w\n",
            "64 he brick w -> e brick wa\n",
            "65 e brick wa ->  brick wal\n",
            "66  brick wal -> brick wall\n",
            "67 brick wall -> rick walls\n",
            "68 rick walls -> ick walls \n",
            "69 ick walls  -> ck walls a\n",
            "70 ck walls a -> k walls ar\n",
            "71 k walls ar ->  walls are\n",
            "72  walls are -> walls aren\n",
            "73 walls aren -> alls aren'\n",
            "74 alls aren' -> lls aren't\n",
            "75 lls aren't -> ls aren't \n",
            "76 ls aren't  -> s aren't t\n",
            "77 s aren't t ->  aren't th\n",
            "78  aren't th -> aren't the\n",
            "79 aren't the -> ren't ther\n",
            "80 ren't ther -> en't there\n",
            "81 en't there -> n't there \n",
            "82 n't there  -> 't there t\n",
            "83 't there t -> t there to\n",
            "84 t there to ->  there to \n",
            "85  there to  -> there to k\n",
            "86 there to k -> here to ke\n",
            "87 here to ke -> ere to kee\n",
            "88 ere to kee -> re to keep\n",
            "89 re to keep -> e to keep \n",
            "90 e to keep  ->  to keep u\n",
            "91  to keep u -> to keep us\n",
            "92 to keep us -> o keep us \n",
            "93 o keep us  ->  keep us o\n",
            "94  keep us o -> keep us ou\n",
            "95 keep us ou -> eep us out\n",
            "96 eep us out -> ep us out,\n",
            "97 ep us out, -> p us out, \n",
            "98 p us out,  ->  us out, b\n",
            "99  us out, b -> us out, bu\n",
            "100 us out, bu -> s out, but\n",
            "101 s out, but ->  out, but \n",
            "102  out, but  -> out, but r\n",
            "103 out, but r -> ut, but ra\n",
            "104 ut, but ra -> t, but rat\n",
            "105 t, but rat -> , but rath\n",
            "106 , but rath ->  but rathe\n",
            "107  but rathe -> but rather\n",
            "108 but rather -> ut rather \n",
            "109 ut rather  -> t rather i\n",
            "110 t rather i ->  rather in\n",
            "111  rather in -> rather in \n",
            "112 rather in  -> ather in t\n",
            "113 ather in t -> ther in th\n",
            "114 ther in th -> her in thi\n",
            "115 her in thi -> er in this\n",
            "116 er in this -> r in this \n",
            "117 r in this  ->  in this w\n",
            "118  in this w -> in this wa\n",
            "119 in this wa -> n this way\n",
            "120 n this way ->  this way \n",
            "121  this way  -> this way t\n",
            "122 this way t -> his way th\n",
            "123 his way th -> is way tha\n",
            "124 is way tha -> s way that\n",
            "125 s way that ->  way that \n",
            "126  way that  -> way that t\n",
            "127 way that t -> ay that th\n",
            "128 ay that th -> y that the\n",
            "129 y that the ->  that the \n",
            "130  that the  -> that the b\n",
            "131 that the b -> hat the br\n",
            "132 hat the br -> at the bri\n",
            "133 at the bri -> t the bric\n",
            "134 t the bric ->  the brick\n",
            "135  the brick -> the brick \n",
            "136 the brick  -> he brick w\n",
            "137 he brick w -> e brick wa\n",
            "138 e brick wa ->  brick wal\n",
            "139  brick wal -> brick wall\n",
            "140 brick wall -> rick walls\n",
            "141 rick walls -> ick walls \n",
            "142 ick walls  -> ck walls a\n",
            "143 ck walls a -> k walls ar\n",
            "144 k walls ar ->  walls are\n",
            "145  walls are -> walls are \n",
            "146 walls are  -> alls are t\n",
            "147 alls are t -> lls are th\n",
            "148 lls are th -> ls are the\n",
            "149 ls are the -> s are ther\n",
            "150 s are ther ->  are there\n",
            "151  are there -> are there \n",
            "152 are there  -> re there t\n",
            "153 re there t -> e there to\n",
            "154 e there to ->  there to \n",
            "155  there to  -> there to s\n",
            "156 there to s -> here to sh\n",
            "157 here to sh -> ere to sho\n",
            "158 ere to sho -> re to show\n",
            "159 re to show -> e to show \n",
            "160 e to show  ->  to show u\n",
            "161  to show u -> to show us\n",
            "162 to show us -> o show us \n",
            "163 o show us  ->  show us h\n",
            "164  show us h -> show us ho\n",
            "165 show us ho -> how us how\n",
            "166 how us how -> ow us how \n",
            "167 ow us how  -> w us how b\n",
            "168 w us how b ->  us how ba\n",
            "169  us how ba -> us how bad\n",
            "170 us how bad -> s how badl\n",
            "171 s how badl ->  how badly\n",
            "172  how badly -> how badly \n",
            "173 how badly  -> ow badly w\n",
            "174 ow badly w -> w badly we\n",
            "175 w badly we ->  badly we \n",
            "176  badly we  -> badly we w\n",
            "177 badly we w -> adly we wa\n",
            "178 adly we wa -> dly we wan\n",
            "179 dly we wan -> ly we want\n",
            "180 ly we want -> y we want \n",
            "181 y we want  ->  we want t\n",
            "182  we want t -> we want th\n",
            "183 we want th -> e want thi\n",
            "184 e want thi ->  want thin\n",
            "185  want thin -> want thing\n",
            "186 want thing -> ant things\n",
            "187 ant things -> nt things.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력해서 한 칸씩 쉬프트된 것 확인하기!\n",
        "\n",
        "print(x_data[0]) #Brick wall\n",
        "print(y_data[0]) #rick walls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVFlILiOixdc",
        "outputId": "1a48c183-0bab-4196-a5ff-6a35128bb8f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13, 5, 16, 11, 14, 6, 3, 8, 12, 12]\n",
            "[5, 16, 11, 14, 6, 3, 8, 12, 12, 23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "## 문제(4) : x_data를 원핫인코딩 > numpy의 eye를 쓸 수 있지 않을까?\n",
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data] #np.eye:(n x m)크기의 2차원 행렬을 만드는 함수\n",
        "\n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## 문제(5) : x_one_hot과 y_data 텐서로 변환 : 둘 다 같은 형식의 텐서로 변환하면 될까?? (FloatTensor, LongTesor 중 맞는 것은?)\n",
        "X = torch.FloatTensor(x_one_hot) \n",
        "Y = torch.LongTensor(y_data) \n",
        "\n",
        "#데이터 타입에 따라 텐서의 자료형 다름\n",
        " #floattensor - 32 bit floating point\n",
        " #longtensor - 64-bit integer"
      ],
      "metadata": {
        "id": "5lPes1dvjlNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dcadce8-2d37-48d6-ace3-5e47e55ee3b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMZzZlaymMk8",
        "outputId": "646a7894-88e2-43e9-a192-6161d9e067f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([188, 10, 26])\n",
            "레이블의 크기 : torch.Size([188, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knx1DE_AmSFB",
        "outputId": "141da109-90a9-400a-a803-6785713d7b96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0]) #rick walls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pWDiH1SmYT_",
        "outputId": "f51a34fc-c004-4b01-eb82-2389ec07ee89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5, 16, 11, 14,  6,  3,  8, 12, 12, 23])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "##문제(6) : 기본 pytorch 인자 넣기 연습 + forward 채우기\n",
        "### 조건 : rnn layer 2개 쌓기 + 마지막은 fc layer\n",
        "### batch_fisrt 설정 필요할까? (유튜브 강의 참고)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True) #num_layers: 쌓을 은닉층의 개수\n",
        "    self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x, _status = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "-Ww22xu8mfUc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) #num_layers:2 -> 층 두개 "
      ],
      "metadata": {
        "id": "No2GRvTpnLBl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss() #비용함수 선언\n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate) #옵티마이저 Adam 선언"
      ],
      "metadata": {
        "id": "9-zuJLeUnQLB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X) #3차원 텐서 \n",
        "print(outputs.shape) #(배치 차원, 시점, 출력의 크기) = (188, 10, 26)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RxRaiHnh9U",
        "outputId": "4ad7efa6-b44e-4c24-e456-f26c08d90265"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([188, 10, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X) #(188, 10, 26) 크기를 가진 텐서를 매 epoch마다 모델의 입력으로 사용\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1)) #2차원 텐서로 변환 #view를 이용해 배치 차원과 시점 차원을 하나로 만듦\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxxrxCd2nwoo",
        "outputId": "1a88e1e3-ea5d-486f-d54c-72101618707a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iibiibibibiiiibiibbibiiimbiiibiiibmiiiiiimibbiibibibibbiibibiibibbiiibiibibibiiiibibibibbibiiibibiiiiiiibibmiiibibibbibiiiibbiiiiiiibiibibbiiibiibibibiiiibiibbibiiibiiibiiiiiibiiiibibibiiiiibibbiii\n",
            "i     u        u     ua   u                         a     i    u         a          u i    u                           u  a    a   u    u         a        u     u                     a  a   ua     \n",
            "u                                                                                                                                                                                                    \n",
            "s                                                                                                                                                                                                    \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "                                                                                                                                                                                                     \n",
            "      a            e                                                e    a               e                           e                       e    a            e                                     \n",
            "     ta     a   he e  a               th       t    he   the   a    e   ta     a       e e e                a        e     e   a   h    a    e   ta     a   he e  h              h     a  a    h     \n",
            "     ta    aa  the   ta   h        r  th   h   ta  the   tae   h   re   ta    aa       e e ta      aa  h   ta  ta    e t   e   a   he   h   re   ta    aa  the   ta       h  a   ht   ta  at  the    \n",
            "     ta    aa  tae   ta   ha    t tr  ta   ha  ta  tae   tae   ae  re   ta    aa   aatre e ta      aa  h   ta  ta    eat  her  a   he   ae  re   ta    aa  tae   ta   a   h aa   at   ta  at  tae   t\n",
            "     ta    aa  taa   ta   haa   t th  ta   ha  ta  tae   tae  tae  re   ta    aa   aatre e ta      aa  h   ta  ta   reat  her ta  the  tae  re   ta    aa  taa   ta   ar  h aa  taa   ta  at  tae   t\n",
            "     ta    aa  tae   ta   haa   t th  ta   aa  ta  tae   tae  tae  he   ta    aa   aatre   ta      aa th   ta  ta   reaa  her ta  the  tae  he   ta    aa  tae   ta   ar th ta  taa   ta tat  tae   a\n",
            "     ta    aa  the   ta   hta t t th  ta   ha  ta  the   the  the  he   tan   aa   aathe   ta      aa th   ta  ta   reaa  her tat the  the  he   tan   aa  the   ta   er th ta  tht t ta tat  the    \n",
            " e   tat   tre the   ta   hta t t th  ta   h  ata  ther  ther the the   tat   tre    the   the     ta th   th  ta  e eaa ther tat ther the the   tat   tre the   the  er th ta  tht t ta tat  ther   \n",
            " e   tat   tre the e ta   hth t t th  th   h  atr  theh  ther the the   tat   tre    the   the     ta tr   the ta  e eaa treh tat ther the the   tat   tre the e the  er th ta  tht t ta tat  ther   \n",
            " e   tatss tre the e to   h h t t th  th   h  hth  theh  theh the tre   tatss tre    the e tre     ta tr   the ta  e eah treh tat ther the tre   tatss tre the e tre  er th ta  tht t ta tat  theh   \n",
            " e   tatss tre the e to   h h t t th  th  th  hth  theh  theh the the   tatss tre t  the e tre     to tr   tht to  e eah theh tat ther the the   tatss tre the e tre  er th ta  tht t ta tot  theh   \n",
            " e   tanss tre the e to   h t t t th  tht th  hth  theh  theh the the   tanss tre t  the e tot     to th   tht to  e ean theh tat ther the the   tanss tre the e tot her th tat tht t ta tot  theh   \n",
            " e   tanss are toe e to   hat t t th  tot th  hth  theh  theh the the   tanss are t  the e tot     to to   tht to  e ean theh tat ther the the   tanss are toe e tot her to tot tht t ta ton  theh   \n",
            " e   tants are toe e to   hat t t th  tot th tath  theh  thes the the   tants are t  the e tot     to to   tht to se ean theh tan thes the the   tants are toe e tot her to tot thn t ta ton  theh   \n",
            " e   tanls are toe e to   hat t t ta  ton th tath  thes  thes the the   tanls are t  the e tot     ta to   ths to se ean theh tan thes the the   tanls are toe e to  har to tot tan t ta ton  theh  e\n",
            " ea  tanls are the e to   hat tan ta  tan th thth  theh  thes the the   tanls are t  there to      ta ao   tht to se ean theh tan thes the the   tanls are the e to  tar to ton tan t ta ton  theh  e\n",
            " ea  tanls are the e to   hre tan th  tan th thth  theh  thes the ther  tanls are t  there the     t  ah   tht to se ean theh tan then the ther  tanls are the e the tan to tot thn t ta tan  theh  e\n",
            " ea  tanls are the e to  ahre ton th  tan th thth  theh  thes the ther  tanls are t  there the     t  ah   tht to re ean theh tan then the ther  tanls are the e the tan to tot thn t ta tan  theh  e\n",
            "rea  tanls are the e to  anle ton thl tat thrthth  then  thes the ther  tanls are t  there the     t  ar   tht ao re ean theh tal then the ther  tanls are the e the tan to tot thn t ta tanl theh  t\n",
            "rea  talls are the e ta  anle ton thl tat thrtanh  then  thes the trea  talls are t  there the     t  ar   tht aotre ean theh tal then the trea  talls are the e the han th tot thnlt ta tanl theh  t\n",
            "rea  talls are the e ta  anle ton thl tat thrtanh  then  thes the trea  talls are t  there tht     tr ar   tht aotre ean then tal then the trea  talls are the e th  han th tot thnlt ta tan  then  t\n",
            "rea  talls are the e ta  anle tan thl tat ahreano  then  thel the trea  talls are t  there tht     tr ar   tht aotre ean then tal then the trea  talls are the e th  han th tot thnlt ta tal  then  t\n",
            "rea  talls are there tar anle tan thl tat ahreano  then  thel thertrea  talls are t  there th      th ah   tht aotre ean then aal thet the trea  talls are there th  han th tot thnlt ta tal  then  t\n",
            "reak talls are there tar anle ton thl tat ahreano  then  thel thertreck talls are t  there to      th ah   tht aotre ean then aal that thertreck talls are there to  han th tot thnlt ta tal  then  t\n",
            "reck talls are there ta  anre ton thl tot ahreano  then  thel thertreck talls are t  there to      ts ah   tht aotre ean then aol that thertreck talls are there to  han ts tot tanlt ta tal  thin  t\n",
            "reck talls are there ta  anre ton thl tot ahrtanot then  thel thertrick talls are wh there to      ts ah   tht aotre ean then aol that thertrick talls are there to  han ts tot tadlt ta tall thin  t\n",
            "reck talls are there ta  anre ton thl wot ahrtanot then  thet thertrick talls are bh there th      ts ah   tht aotre ean then aol that thertrick talls are there th  han ts tot tadlt te tall thin  t\n",
            "reck talls are there tor anre ton thl wot ahrtanot then  thet thertrick talls are bh there th      ts aht  tht aotre ean then aol that thertrick talls are there th  han ts tot tadlt te tale thin  t\n",
            "reck talls are there tor anre ton thl yot ahrtanot then  thet thertrick talls are bh there th      ts aht  tht aothe ean then aol that thertrick talls are there th  han ts tot tadlw te tale thin ra\n",
            "reck talls are there tor anre ton thl yot ahrtanot then  thet thertrick talls are  t there to      ts aht  tht aothe ean then aol that thertrick talls are there th  han ts uot tadlw te tale thin ta\n",
            "reck talls are there tor anre ton thd yot ahstanot then  thet thertrick talls are  t there to      ts aht  tht aathe ean then aol that thertrick talls are there th  han ts uot tadlw te tale thin ta\n",
            "reck talls are there tor anre ton thd yot ahst not then  that thertrick talls are  t there to      ts aht  bht aathe ean then aol that thertrick talls are there to  han ts uot tadly te tale thin ta\n",
            "reck talls are there tor a re ton thd yow ahst tot then  that thertrick talls are  t there to      ts aht  bht aathe ean then aol that thertrick talls are there to  han ts hot tadly te tale thenkta\n",
            "rick talls are there tor a re ton thd yow aust tot thenk that thertrick talls are  t there to te   ts aht  bht aathe ean then aol that thertrick talls are there to than ts how uadly te talt thenkta\n",
            "rick talls are there tor a re tan trd yow aust tot thenk that thertrick talls are  t there to te   ts ant  bht aathe ean then aol that thertrick talls are there to than ts how uadly te tall thenkta\n",
            "rick talls are there tor a re ton trd yow aust tot thenk that thertrick talls are  t there to tee  us ant  bht aathe ean then wol that thertrick talls are there th thon ts uow uadly te talt thinkta\n",
            "rick talls are there tor a re ton ard yow aust tot think that thertrick talls are  t there to tee  us ant  bht aathe ean thin wal that thertrick talls are there th thow ts uow uadly te talt thinkta\n",
            "rick talls are there tor a re ton ard yow aust tot think that thertrick talls are  t there to tee  us ant  bht aathe ean thin wal that thertrick talls are there th thow ts uow uadly te talt thinkta\n",
            "rick talls are there tor a re son ard yow aust not think that thertrick talls are kt there to tee  us ant  bht aatherean thin wal that thertrick talls are there th thow ts uow uadly te talt thinkta\n",
            "rick talls are there tor a re son and yot aust not think that thertrick talls are kt there to tee  us ant  bht aatherean thin wal that thertrick talls are there th thow us uow uadly te talt thinkta\n",
            "rick talls are there tor a re son and yow aust not think that thertrick talls are kt there to tee  us ant  brt ratherein thin wal that thertrick talls are there th thow us uow uadly te talt thinkra\n",
            "rick talls are there tor a re son and yow must not think that thertrick talls are kt there to tee  us ant  brt ratherein thin wal that thertrick talls are there th thow us uow uadly we talt thinkra\n",
            "rick talls are there tor a re son and yow must not think that thertrick talls are kt there to tee  us ant  brt ratherein thin wal that the trick talls are there to thow us uow uadly we talt thinkra\n",
            "rick talls are there tor a re son and yow must not think that the trick talls are  t there to tee  us ant  brt rathe ein thin wal that the trick talls are there to thow us aow uadly we talt thinkra\n",
            "rick talls are there tor a re son and yow must not think that thertrick talls are  t there to tee  us aut  brt ratherein this wal that the trick talls are there to thow us aow uadly we talt thinkra\n",
            "rick talls are there tor a re son and yow must not think that thertrick talls are 't there to teep us aut  brt rather in this way that the trick talls are there to thow us how uadly we talt thinkra\n",
            "rick talls are there tor a re son and yow must not think that therbrick talls are 't there to teep us aut  brt rather in this way that the brick talls are there to thow us how uadly we talt thinkra\n",
            "rick walls are there tor a re son and yow must not think that therbrick walls are 't there th teep us aut  bht rather in this way that therbrick walls are there to thow us how uadly we tant thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there th teep us aut  bht rather in this way that therbrick walls are there to thow us how uadly we tant thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there to teep us aut, but rather in this way that therbrick walls are there to thow us how uadly we tant thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there to teep us aut, but rather in this way that therbrick walls are there to thow us how uadly we tant thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there to teep us aut, but rather in this way that therbrick walls are there to thow us how uadly we tant thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there to teep us aut, but rather in this way that therbrick walls are there to thow us how uadly we tant thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there to teep us aut, but rather in this way that therbrick walls are there to thow us how badly we tant thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there to seep us aut, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a re son and you must not think that therbrick walls are 't there to seep us aut, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a re son and you must not think that the brick walls are 't there to seep us aut, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a re son and you must not think that the brick walls are 't there to seep us aut, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinksa\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkso\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thinkso\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingso\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsc\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsg\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n",
            "rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "8qUkbiw2t0Il",
        "outputId": "e265bed6-772c-4ac7-c162-ce4d7a4e7ba8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"rick walls are there tor a reason and you must not think that the brick walls are 't there to seep us out, but rather in this way that the brick walls are there to show us how badly we want thingsb\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과가 어떤가요?? 마지막 에폭의 문장이 그럴싸한가요?"
      ],
      "metadata": {
        "id": "PkIzDTdyvTHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task2\n",
        "\n",
        "위 sentence는 제가 임의로 생성한 문장들입니다.\n",
        "\n",
        "마음에 드시는 문구 가져오셔서 문장이 어떻게 생성되는지 확인해보세요! \n",
        "\n",
        "영어가 아닌 한국어로 시도해보는 것도 좋겠죠? \n",
        "\n",
        "수정이 많이 필요(토큰화 등) 할 수 있으나 한번 시도해보시는 것 권장드립니다 :)\n",
        "\n",
        "위 베이스라인은 어디든 수정하셔도 좋고 조금 더 자연스러운 문장이 나올 수 있게 다양한 시도를 해보세요!\n",
        "\n",
        "조건 : 문장 3개 이상, 연결성이 있는 문장을 \" \" 으로 구분하여 ( )에 넣기"
      ],
      "metadata": {
        "id": "kN1zL8Dpvane"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "id": "IKp-lKrjvXR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f7e348-2b55-4540-f544-5e7fde299310"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-08-16 13:21:04--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22c0:3470, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNB7DQI3K2&Signature=k7n3YlddkmiXQ1ujJk1ZHjpASsc%3D&x-amz-security-token=FwoGZXIvYXdzEH8aDFR392jVN51HqU2eXiK%2BAe5KEuIRAfjk%2BsnAAhW9jlwCWDG7KIjTp9evPjkWQg07JjlQVy6Nnzb4bLtoCL0geJmAoun%2FPyNi9Dm%2FaydtFJTeHSF6c7uK6hQZAmw0uP5SBrvsdfnnAMDYjJOTHSYEXrlnD0BL04A7WB7bE4aBzC42cn3nuQKwa1kOzL63Dyj0t0TUTMJZF7VHFcLH9KjluDTFG%2Fx9T1FECGAlVrcDTesQmvPVECdwfDkDQupIeBUfPDCeTQ1iq13uvKz%2FAeUoza3ulwYyLTz271%2BYvWsgBNMAD6hyQB1BQlAuMlwDfkw4%2BlLbmygtzON0nSzUZ76BtX3OgQ%3D%3D&Expires=1660657109 [following]\n",
            "--2022-08-16 13:21:05--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNB7DQI3K2&Signature=k7n3YlddkmiXQ1ujJk1ZHjpASsc%3D&x-amz-security-token=FwoGZXIvYXdzEH8aDFR392jVN51HqU2eXiK%2BAe5KEuIRAfjk%2BsnAAhW9jlwCWDG7KIjTp9evPjkWQg07JjlQVy6Nnzb4bLtoCL0geJmAoun%2FPyNi9Dm%2FaydtFJTeHSF6c7uK6hQZAmw0uP5SBrvsdfnnAMDYjJOTHSYEXrlnD0BL04A7WB7bE4aBzC42cn3nuQKwa1kOzL63Dyj0t0TUTMJZF7VHFcLH9KjluDTFG%2Fx9T1FECGAlVrcDTesQmvPVECdwfDkDQupIeBUfPDCeTQ1iq13uvKz%2FAeUoza3ulwYyLTz271%2BYvWsgBNMAD6hyQB1BQlAuMlwDfkw4%2BlLbmygtzON0nSzUZ76BtX3OgQ%3D%3D&Expires=1660657109\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.89.116\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.89.116|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.57MB/s    in 0.4s    \n",
            "\n",
            "2022-08-16 13:21:05 (3.57 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-08-16 13:21:28--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c0:3470, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKNLSAINS&Signature=dENBoSOFHd%2BYPE%2Bs3k6pzl6zM3Q%3D&x-amz-security-token=FwoGZXIvYXdzEH8aDOzyThsbh5uYDAFT0iK%2BAQZEMOurKrGLwmjHtAagNbqbkTh5H%2FpNob%2BvCIhK9VS2Hlvm0HHCH0aq7wYrOrS%2FEcAmlsgGeE0%2FY3qUjtrMONxjciFKxD90k6QQJ6xQNu5jJg9VbqAPEt8lLtqowIfkPtf60FGzSZnyiuQQ70wvq4R5iaucn37iM7257lRqwNkT%2BsbPAsWqpL9UhIXoBWqEtgqbeP45GOLVasLO8j7h0nlWbKikZ0y4at1Lq%2B9R543V3pb67Ie%2FkRrAv%2FhedFAora7ulwYyLVRAUrmiolHPSbiRDnrJ9UNhaek9%2Be9pLWRJsG3hMMVadF5iMurtSMuEkugKsg%3D%3D&Expires=1660657205 [following]\n",
            "--2022-08-16 13:21:28--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKNLSAINS&Signature=dENBoSOFHd%2BYPE%2Bs3k6pzl6zM3Q%3D&x-amz-security-token=FwoGZXIvYXdzEH8aDOzyThsbh5uYDAFT0iK%2BAQZEMOurKrGLwmjHtAagNbqbkTh5H%2FpNob%2BvCIhK9VS2Hlvm0HHCH0aq7wYrOrS%2FEcAmlsgGeE0%2FY3qUjtrMONxjciFKxD90k6QQJ6xQNu5jJg9VbqAPEt8lLtqowIfkPtf60FGzSZnyiuQQ70wvq4R5iaucn37iM7257lRqwNkT%2BsbPAsWqpL9UhIXoBWqEtgqbeP45GOLVasLO8j7h0nlWbKikZ0y4at1Lq%2B9R543V3pb67Ie%2FkRrAv%2FhedFAora7ulwYyLVRAUrmiolHPSbiRDnrJ9UNhaek9%2Be9pLWRJsG3hMMVadF5iMurtSMuEkugKsg%3D%3D&Expires=1660657205\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.235.9\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.235.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  28.0MB/s    in 1.7s    \n",
            "\n",
            "2022-08-16 13:21:30 (28.0 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 생성할 문장 데이터\n",
        "\n",
        "kor_text= (\"나의 자라나는 마음을 못 본채 꺾어 버릴 수는 없네\"\n",
        "            \"미련 남길바엔 그리워 아픈게 나아\"\n",
        "            \"서둘러 안겨본 그 품은 따스할 테니\")"
      ],
      "metadata": {
        "id": "Fn6bKb5qt7kk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab, Okt"
      ],
      "metadata": {
        "id": "c2GIY_jf1RRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Okt()\n",
        "word = tokenizer.morphs(kor_text)"
      ],
      "metadata": {
        "id": "t6ZLIgCs0tEc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zbtA-_r00_d",
        "outputId": "f6d53238-96ac-4b0c-ef5f-326482cc6c77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '의', '자라나는', '마음', '을', '못', '본채', '꺾어', '버릴', '수', '는', '없네', '미련', '남길', '바', '엔', '그리워', '아픈게', '나아', '서둘러', '안겨', '본', '그', '품은', '따스할', '테', '니']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Mecab()\n",
        "word  = tokenizer.morphs(kor_text)"
      ],
      "metadata": {
        "id": "RFNjYUlsxV7t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word) #형태소 분류를 더 잘하는 Mecab 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vbb90suyCuu",
        "outputId": "54331791-0f9d-4b61-d750-4310c0cb0664"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '의', '자라나', '는', '마음', '을', '못', '본', '채', '꺾', '어', '버릴', '수', '는', '없', '네', '미련', '남길', '바', '엔', '그리워', '아픈', '게', '나아서', '둘러', '안겨', '본', '그', '품', '은', '따스', '할', '테', '니']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 문자 집합 만들기\n",
        "world_set = list(set(kor_text))\n",
        "\n",
        "## 문제(1): 각 문자에 정수 인코딩 (공백도 하나의 원소로 포함)\n",
        "vocab = {c: i for i, c in enumerate(world_set)}"
      ],
      "metadata": {
        "id": "wtiUSZ4mw-kg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQHUXR8fyKS9",
        "outputId": "06e6b2fa-23ea-44f1-84ef-a95134698c0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'미': 0, '없': 1, '은': 2, '리': 3, '수': 4, '바': 5, '게': 6, '겨': 7, '러': 8, '할': 9, '본': 10, '네': 11, '아': 12, '품': 13, '마': 14, '채': 15, '테': 16, ' ': 17, '엔': 18, '을': 19, '꺾': 20, '못': 21, '음': 22, '어': 23, '릴': 24, '워': 25, '의': 26, '자': 27, '픈': 28, '스': 29, '남': 30, '길': 31, '나': 32, '버': 33, '련': 34, '안': 35, '라': 36, '니': 37, '둘': 38, '서': 39, '그': 40, '는': 41, '따': 42}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. 문자 집합 크기 확인\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print('문자 집합 크기 : {}'.format(vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlvJntnZyK1M",
        "outputId": "29f27c86-41d8-4b1e-d642-61039f3a3777"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합 크기 : 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 하이퍼 파라미터 설정\n",
        "\n",
        "hidden_size = vocab_size \n",
        "sequence_length = 10\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "9yrkoB8uyOe6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. seqence 길이 단위 자르기\n",
        "\n",
        "# 데이터 구성을 위한 리스트\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "for i in range(0, len(kor_text) - sequence_length):\n",
        "  x_str = kor_text[i:i + sequence_length] \n",
        "  y_str = kor_text[i + 1: i + sequence_length + 1]\n",
        "  print(i, x_str, \"->\", y_str)\n",
        "\n",
        "  # x_str과 y_str이 문자집합에 해당하는 인덱스를 각각 x_data, y_data에 append\n",
        "  x_data.append([vocab[c] for c in x_str])\n",
        "  y_data.append([vocab[d] for d in y_str])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maC3BBERyT-F",
        "outputId": "c4c132c7-ffa8-4d28-d505-4bbded17a888"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 나의 자라나는 마음 -> 의 자라나는 마음을\n",
            "1 의 자라나는 마음을 ->  자라나는 마음을 \n",
            "2  자라나는 마음을  -> 자라나는 마음을 못\n",
            "3 자라나는 마음을 못 -> 라나는 마음을 못 \n",
            "4 라나는 마음을 못  -> 나는 마음을 못 본\n",
            "5 나는 마음을 못 본 -> 는 마음을 못 본채\n",
            "6 는 마음을 못 본채 ->  마음을 못 본채 \n",
            "7  마음을 못 본채  -> 마음을 못 본채 꺾\n",
            "8 마음을 못 본채 꺾 -> 음을 못 본채 꺾어\n",
            "9 음을 못 본채 꺾어 -> 을 못 본채 꺾어 \n",
            "10 을 못 본채 꺾어  ->  못 본채 꺾어 버\n",
            "11  못 본채 꺾어 버 -> 못 본채 꺾어 버릴\n",
            "12 못 본채 꺾어 버릴 ->  본채 꺾어 버릴 \n",
            "13  본채 꺾어 버릴  -> 본채 꺾어 버릴 수\n",
            "14 본채 꺾어 버릴 수 -> 채 꺾어 버릴 수는\n",
            "15 채 꺾어 버릴 수는 ->  꺾어 버릴 수는 \n",
            "16  꺾어 버릴 수는  -> 꺾어 버릴 수는 없\n",
            "17 꺾어 버릴 수는 없 -> 어 버릴 수는 없네\n",
            "18 어 버릴 수는 없네 ->  버릴 수는 없네미\n",
            "19  버릴 수는 없네미 -> 버릴 수는 없네미련\n",
            "20 버릴 수는 없네미련 -> 릴 수는 없네미련 \n",
            "21 릴 수는 없네미련  ->  수는 없네미련 남\n",
            "22  수는 없네미련 남 -> 수는 없네미련 남길\n",
            "23 수는 없네미련 남길 -> 는 없네미련 남길바\n",
            "24 는 없네미련 남길바 ->  없네미련 남길바엔\n",
            "25  없네미련 남길바엔 -> 없네미련 남길바엔 \n",
            "26 없네미련 남길바엔  -> 네미련 남길바엔 그\n",
            "27 네미련 남길바엔 그 -> 미련 남길바엔 그리\n",
            "28 미련 남길바엔 그리 -> 련 남길바엔 그리워\n",
            "29 련 남길바엔 그리워 ->  남길바엔 그리워 \n",
            "30  남길바엔 그리워  -> 남길바엔 그리워 아\n",
            "31 남길바엔 그리워 아 -> 길바엔 그리워 아픈\n",
            "32 길바엔 그리워 아픈 -> 바엔 그리워 아픈게\n",
            "33 바엔 그리워 아픈게 -> 엔 그리워 아픈게 \n",
            "34 엔 그리워 아픈게  ->  그리워 아픈게 나\n",
            "35  그리워 아픈게 나 -> 그리워 아픈게 나아\n",
            "36 그리워 아픈게 나아 -> 리워 아픈게 나아서\n",
            "37 리워 아픈게 나아서 -> 워 아픈게 나아서둘\n",
            "38 워 아픈게 나아서둘 ->  아픈게 나아서둘러\n",
            "39  아픈게 나아서둘러 -> 아픈게 나아서둘러 \n",
            "40 아픈게 나아서둘러  -> 픈게 나아서둘러 안\n",
            "41 픈게 나아서둘러 안 -> 게 나아서둘러 안겨\n",
            "42 게 나아서둘러 안겨 ->  나아서둘러 안겨본\n",
            "43  나아서둘러 안겨본 -> 나아서둘러 안겨본 \n",
            "44 나아서둘러 안겨본  -> 아서둘러 안겨본 그\n",
            "45 아서둘러 안겨본 그 -> 서둘러 안겨본 그 \n",
            "46 서둘러 안겨본 그  -> 둘러 안겨본 그 품\n",
            "47 둘러 안겨본 그 품 -> 러 안겨본 그 품은\n",
            "48 러 안겨본 그 품은 ->  안겨본 그 품은 \n",
            "49  안겨본 그 품은  -> 안겨본 그 품은 따\n",
            "50 안겨본 그 품은 따 -> 겨본 그 품은 따스\n",
            "51 겨본 그 품은 따스 -> 본 그 품은 따스할\n",
            "52 본 그 품은 따스할 ->  그 품은 따스할 \n",
            "53  그 품은 따스할  -> 그 품은 따스할 테\n",
            "54 그 품은 따스할 테 ->  품은 따스할 테니\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#쉬프트 확인\n",
        "\n",
        "print(x_data[0]) #Brick wall\n",
        "print(y_data[0]) #rick walls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvOa5ZMVyap7",
        "outputId": "c4189751-bc91-439b-d731-b29183c25343"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 26, 17, 27, 36, 32, 41, 17, 14, 22]\n",
            "[26, 17, 27, 36, 32, 41, 17, 14, 22, 19]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##6. 입력 시퀀스에 대해 원핫인코딩 수행\n",
        "\n",
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data] \n",
        "##7. 입력 데이터, 레이블데이터 텐서로 변환\n",
        "\n",
        "## x_one_hot과 y_data 텐서로 변환 \n",
        "X = torch.FloatTensor(x_one_hot) \n",
        "Y = torch.LongTensor(y_data) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgs5mXHUyfl7",
        "outputId": "bb0653be-9dc7-405d-8b09-d3df55473c81"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##8. 크기 확인\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블의 크기 : {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZkT3TjqymOB",
        "outputId": "30722308-6824-492a-8ec5-221de16baec4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([55, 10, 43])\n",
            "레이블의 크기 : torch.Size([55, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##9.원핫인코딩 결과 샘플 확인하기\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gngJonDcyqUJ",
        "outputId": "19278b8b-ac81-44e3-a0c3-c32385fd63f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         1., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##10. 레이블 데이터 샘플 확인하기\n",
        "print(Y[0]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhCVZ31tyups",
        "outputId": "c49c7a84-8a64-4964-da9e-8702983d5b33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([26, 17, 27, 36, 32, 41, 17, 14, 22, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##11. RNN 모델 구현\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layers):\n",
        "    super(Net, self).__init__()\n",
        "    self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True) #num_layers: 쌓을 은닉층의 개수\n",
        "    self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x, _status = self.rnn(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "aW72HOOVzIuj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(vocab_size, hidden_size, 2) "
      ],
      "metadata": {
        "id": "M5KOp25kzcix"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##12. loss function\n",
        "criterion = torch.nn.CrossEntropyLoss() \n",
        "\n",
        "##13. optimizer\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate) "
      ],
      "metadata": {
        "id": "xqhI9Ylczfmo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##14. 출력 크기 점검\n",
        "outputs = net(X) #3차원 텐서 \n",
        "print(outputs.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThmrLXVazjqw",
        "outputId": "186639d7-d5a5-46b9-f679-181264df6a4a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([55, 10, 43])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##15. Training 시작\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X) #(188, 10, 26) 크기를 가진 텐서를 매 epoch마다 모델의 입력으로 사용\n",
        "    ##문제(7) : outputs, Y 형태 그대로 넣으면 안되죠. view 함수를 이용해 loss값을 계산해봅시다.\n",
        "    loss = criterion(outputs.view(-1, vocab_size), Y.view(-1)) #2차원 텐서로 변환 #view를 이용해 배치 차원과 시점 차원을 하나로 만듦\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #16. 예측결과 확인\n",
        "    results = outputs.argmax(dim=2)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오기\n",
        "            predict_str += ''.join([world_set[t] for t in result])\n",
        "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
        "            predict_str += world_set[result[-1]]\n",
        "\n",
        "    print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki8ljY2Dzt2Y",
        "outputId": "33c7f271-1fe1-441d-c9e8-4999ed16167d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아을을미워마미꺾을을그을미을워워을미을워미을꺾을워워워미을꺾을을미미을워을미미을미을마을미미꺾워을을미바을워을을미을을겨을미꺾아\n",
            "아    아     그     아                          아        그         아\n",
            "아                                                               \n",
            "                                                                \n",
            "                                                                \n",
            "                                                                \n",
            "                                                                \n",
            "                                                                \n",
            "  그    그는  그       그는 그는 그는   그    그   그         그   그    그   그 \n",
            "  그는   그는  그 그  그어 그는 그는 그는   남    그는  그픈  그  그러 그   그는그  그는  그는\n",
            "  그는 아 그는  그 그   어 그는 그는 그는   남 그  그리본 그픈본 그  그러 그 본 그리그  그는  그는\n",
            "  그 본아 그리  그 그 본 어 그는 그는 그는   그 그  그리본 그리본 그  그러 그 본 그 그  그리  그리\n",
            "  그 본아 그리  못 그는 그어 그는 그는 그는   그 본는 그리워 그리본 그  그러 그 본 그 그  그리  그리\n",
            "  그리 아 그는  못 그는 그는 그는 그는 그는   그 본는 그리워 그픈게 본  그러 그 본 그 그는 그리  그겨\n",
            "  그리 아 그리워 못 본는 없어 그는 그는 그는   못 본는 그리워 그픈워 본  그러 그 본 본 그픈 그리워 그겨\n",
            "  그리본는 그리워 못 그는 없어 그는 그는 없네 본 못 본는 그리워 그 워 본  둘러 그 본 본 그은 그리워 그겨\n",
            "  그리나는 그리워 못 그는 없어 그릴 그는 없네 본 못길바는 그리워 아픈워 나  둘러 그 본 본 그은 그리워 못겨\n",
            "  못리나는 그네워 못 본는 없어 그릴 그는 없네미바 못길바는 그리워 아픈게 나아 둘러 그겨본 본 품은 따리워 못네\n",
            "  못리나는 그음워 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아  러 그겨본 본 품은 따스워 따네\n",
            "  못길나는 그음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아 둘러 그겨본 본 품은 따스워 못네\n",
            "  못길나는 그음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈본 나아 둘러 안겨본 본 품은 따스워 남네\n",
            "  못길나는 그음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈본 나아서둘러 안겨본 본 품은 수스워 남음\n",
            "아 못릴나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈본 나아서둘러 안겨본 본 품은 따스을 남음\n",
            "아 버릴나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈본 나아서둘러 안겨본 본 품은 따스할 남음\n",
            "아 버길나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 본 품은 따스할 남음\n",
            "아 버리나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 본 품은 따스할 남음\n",
            "아 버리나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남음\n",
            "아 버리나는 마네을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남음\n",
            "아 버리나는 없네을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남길\n",
            "아 버리나는 없음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남길\n",
            "아 버리나는 없음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남길\n",
            "아 버리나는 없음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 버길나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 버길나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 버길나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 버길나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 버라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 버라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 따라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 남스\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테스\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "의 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "의 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "의 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "의 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "의 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "의 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n",
            "아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7wo3TSIzzxxd",
        "outputId": "777144c3-28c1-4d49-9f9b-8dd19955e0e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'아 자라나는 마음을 못 본채 꺾어 버릴 수는 없네미련 남길바엔 그리워 아픈게 나아서둘러 안겨본 그 품은 따스할 테니'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}