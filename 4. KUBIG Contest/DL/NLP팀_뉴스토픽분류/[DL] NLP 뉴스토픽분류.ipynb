{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[NLP]뉴스토픽분류.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-BoHmkxtg-c6",
        "XeZOMl9yuXGF",
        "2N4K6TpMt3CD",
        "la1hu94gxt3E",
        "ZKA7QdWdzKFU",
        "5eAooH9WyUmN",
        "_G6Ia0sxh3Sn",
        "WWuy6a-vh3Zm"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **뉴스 토픽 분류 AI 경진대회**"
      ],
      "metadata": {
        "id": "8K7WO8jo3I5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://dacon.io/competitions/official/235747/overview/description"
      ],
      "metadata": {
        "id": "gfkULzi83NtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "-BoHmkxtg-c6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install packages"
      ],
      "metadata": {
        "id": "XeZOMl9yuXGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkS1cnaEHgXj"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3\n",
        "!pip install torch\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "!pip install hanja\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install adabelief-pytorch\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "qaxmQnCOag9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAl2lJVkCfkt",
        "outputId": "63299a7f-e2e1-4b1c-b46b-0e964b269903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  GPU setting"
      ],
      "metadata": {
        "id": "2N4K6TpMt3CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(777)"
      ],
      "metadata": {
        "id": "TFIm-_GWuFuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "wCWj5R3xqZSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import library"
      ],
      "metadata": {
        "id": "la1hu94gxt3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re #regular expression\n",
        "from konlpy.tag import Okt,Mecab # 형태소 분석\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # tokenizer\n",
        "\n",
        "\n",
        "import hanja\n",
        "from hanja import hangul\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "from transformers import RobertaTokenizerFast\n",
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
        "from transformers import AutoTokenizer, AdamW, RobertaForSequenceClassification,get_cosine_schedule_with_warmup\n",
        "\n",
        "\n",
        "from adabelief_pytorch import AdaBelief\n"
      ],
      "metadata": {
        "id": "q_Ayy4i9xl3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "ZKA7QdWdzKFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "afZL03kExl3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7fea13-c13a-4a8a-d14d-74c840a59d01",
        "id": "Fj1Ng975xl3H"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/data/\"\n",
        "\n",
        "\n",
        "topic_dic = pd.read_csv(path+\"topic_dict.csv\")\n",
        "train = pd.read_csv(path + \"train_data.csv\")\n",
        "test = pd.read_csv(path + \"test_data.csv\")\n",
        "subm = pd.read_csv(path + \"sample_submission.csv\")\n",
        "\n",
        "STOPWORDSPATH = '/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/2주차_Baseline 심화/지호/stopwords.txt'"
      ],
      "metadata": {
        "id": "XVzOLj_Fxl3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "5eAooH9WyUmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. 품사 태깅\n",
        "2. 숫자, 특수문자 + 한 글자 미만 제거\n",
        "3. 문장부호 제거\n",
        "4. 영어, 한자 -> 한글로 변환\n",
        "5. 불용어 처리\n",
        "6. 추가 전처리 - 이상문자열 제거"
      ],
      "metadata": {
        "id": "4pP9l2p9ybzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 품사 태깅 "
      ],
      "metadata": {
        "id": "n4DuloMQybzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt() # 형태소 분석기\n",
        "\n",
        "def clean1(text):\n",
        "   clean = []\n",
        "\n",
        "   for word in okt.pos(text, stem = True): #어간 추출\n",
        "    if word[1] not in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
        "      clean.append(word[0])\n",
        "    \n",
        "   return \" \".join(clean)"
      ],
      "metadata": {
        "id": "fqq9kaIkybzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 숫자, 특수문자 제거 + 한 글자 미만 제거"
      ],
      "metadata": {
        "id": "yffT2jSYybzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean2(text):\n",
        "  sent_clean = re.sub(r\"[^a-zA-Z가-힣]\",\" \",text) #substraction 숫자, 특수문자 제거\n",
        "  clean =[]\n",
        "  for word in sent_clean.split(\" \"):\n",
        "    if len(word)>1: #한글자 미만 제거\n",
        "      clean.append(word)\n",
        "\n",
        "  return \" \".join(clean)"
      ],
      "metadata": {
        "id": "B7Kpa0A5ybzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.title = train.title.apply(lambda x : clean1(x)) \n",
        "test.title = test.title.apply(lambda x : clean1(x))\n",
        "train.title = train.title.apply(lambda x : clean2(x))\n",
        "test.title = test.title.apply(lambda x : clean2(x))"
      ],
      "metadata": {
        "id": "GeDi1XogybzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문장부호 제거"
      ],
      "metadata": {
        "id": "YmHIgwnFybzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
        "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
        "\n",
        "def clean_punc(text, punct, mapping):\n",
        "    for p in mapping:\n",
        "        text = text.replace(p, mapping[p])\n",
        "    \n",
        "    for p in punct:\n",
        "        text = text.replace(p, f' {p} ')\n",
        "    \n",
        "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}\n",
        "    for s in specials:\n",
        "        text = text.replace(s, specials[s])\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "cleaned_train_corpus = []\n",
        "cleaned_test_corpus = []\n",
        "train.title = train.title.apply(lambda x : hanja.translate(x, 'substitution'))\n",
        "test.title = test.title.apply(lambda x : hanja.translate(x, 'substitution'))\n",
        "\n",
        "for sent in train['title']:\n",
        "    cleaned_train_corpus.append(clean_punc(sent, punct, punct_mapping))\n",
        "    \n",
        "for sent in test['title']:\n",
        "    cleaned_test_corpus.append(clean_punc(sent, punct, punct_mapping))\n"
      ],
      "metadata": {
        "id": "O8khF0V3ybzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 영어/한자 -> 한글로 변환"
      ],
      "metadata": {
        "id": "YHMBxYS3ybzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(texts):\n",
        "    corpus = []\n",
        "    for i in range(0, len(texts)):\n",
        "        texts[i] = texts[i].replace(\"外人\",\"외국인\")\n",
        "        texts[i] = texts[i].replace(\"日\",\"일본\")\n",
        "        texts[i] = texts[i].replace(\"美\",\"미국\")\n",
        "        texts[i] = texts[i].replace(\"北\",\"북한\")\n",
        "        texts[i] = texts[i].replace(\"英\",\"영국\")\n",
        "        texts[i] = texts[i].replace(\"中\",\"중국\")\n",
        "        texts[i] = texts[i].replace(\"與\",\"여당\")\n",
        "        texts[i] = texts[i].replace(\"靑\",\"청와대\")\n",
        "        texts[i] = texts[i].replace(\"野\",\"야당\")\n",
        "        texts[i] = texts[i].replace(\"伊\",\"이탈리아\")\n",
        "        texts[i] = texts[i].replace(\"韓\",\"한국\")\n",
        "        texts[i] = texts[i].replace(\"南\",\"한국\")\n",
        "        texts[i] = texts[i].replace(\"獨\",\"독일\")\n",
        "        texts[i] = texts[i].replace(\"佛\",\"프랑스\")\n",
        "        texts[i] = texts[i].replace(\"檢\",\"검찰\")\n",
        "        texts[i] = texts[i].replace(\"銀\",\"은행\")\n",
        "        texts[i] = texts[i].replace(\"亞\",\"아시아\")\n",
        "        texts[i] = texts[i].replace(\"人\",\"사람\")\n",
        "        texts[i] = texts[i].replace(\"孫\",\"손혜원\")\n",
        "        texts[i] = texts[i].replace(\"企\",\"기업\")\n",
        "        texts[i] = texts[i].replace(\"前\",\"이전\")\n",
        "        texts[i] = texts[i].replace(\"反\",\"반대\")\n",
        "        texts[i] = texts[i].replace(\"安\",\"안철수\")\n",
        "        texts[i] = texts[i].replace(\"展\",\"전시회\")\n",
        "        texts[i] = texts[i].replace(\"故\",\"사망\")\n",
        "        texts[i] = texts[i].replace(\"文\",\"문재인\")\n",
        "        texts[i] = texts[i].replace(\"新\",\"새로운\")\n",
        "        texts[i] = texts[i].replace(\"曺\",\"조국\")\n",
        "        texts[i] = texts[i].replace(\"朴\",\"박근혜\")\n",
        "        texts[i] = texts[i].replace(\"株\",\"주식\")\n",
        "        texts[i] = texts[i].replace(\"男\",\"남자\")\n",
        "        texts[i] = texts[i].replace(\"硏\",\"연구\")\n",
        "        texts[i] = texts[i].replace(\"車\",\"자동차\")\n",
        "        texts[i] = texts[i].replace(\"軍\",\"군대\")\n",
        "        texts[i] = texts[i].replace(\"重\",\"중공업\")       \n",
        "\n",
        "        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(texts[i])) #remove punctuation\n",
        "        review = re.sub(r'1보','', str(review))\n",
        "        review = re.sub(r'\\d+','', str(review))# remove number\n",
        "        review = re.sub(r'→','에서 ', str(review))\n",
        "        review = re.sub(r'…',' ', str(review))\n",
        "        review = re.sub(r'NYT','뉴욕 타임스', str(review))\n",
        "        review = re.sub(r'KAIST','카이스트', str(review))\n",
        "        review = re.sub(r'WMO','세계 기상 기구', str(review))\n",
        "        review = re.sub(r'KBL','한국 프로 농구', str(review))\n",
        "        review = re.sub(r'UAE','아랍에미리트', str(review))\n",
        "        review = re.sub(r'EU','유럽 연합', str(review))\n",
        "        review = re.sub(r'NBA','농구 연맹', str(review))\n",
        "        review = re.sub(r'CIA','중앙정보국', str(review))\n",
        "        review = re.sub(r'ECB','유럽 중앙 은행', str(review))\n",
        "        review = re.sub(r'AFC','아시아 축구 연맹', str(review))\n",
        "        review = re.sub(r'ITU','국제전기통신연합', str(review))\n",
        "        review = re.sub(r'MVP','최우수 선수', str(review))\n",
        "        #review = re.sub(r'MB','이명박', str(review))\n",
        "        review = re.sub(r'APEC','아시아 태평량 경제협력체', str(review))\n",
        "        review = re.sub(r'PSG','파리 셍제르망', str(review))\n",
        "        review = re.sub(r'IMO','국제해사기구', str(review))\n",
        "        review = re.sub(r'MLB','프로 야구 리그 ', str(review))\n",
        "        review = re.sub(r'MOU','양해각서', str(review))\n",
        "        review = re.sub(r'FA','자유계약선수제도', str(review))\n",
        "        review = re.sub(r'EPL','잉글랜드프리미어리그', str(review))\n",
        "        review = re.sub(r'KBO','한국야구위원회', str(review))\n",
        "        review = re.sub(r'IPU','국제 의회 연맹', str(review))\n",
        "        review = re.sub(r'AG','아시안게임', str(review))\n",
        "        review = re.sub(r'PS','포스트시즌', str(review))\n",
        "        review = re.sub(r'PO','플레이오프', str(review))\n",
        "        #review = re.sub(r'닷컴','사이트', str(review))\n",
        "        review = re.sub(r'OUT','방출', str(review))\n",
        "        review = re.sub(r'IN','영입', str(review))\n",
        "        review = re.sub(r'TPP',' 환태평양 경제 동반자협정', str(review))\n",
        "        review = re.sub(r'EAS','동아시아 정상회의', str(review))\n",
        "        review = re.sub(r'DC','', str(review))\n",
        "        review = re.sub(r'①','', str(review))\n",
        "        review = re.sub(r'②','', str(review))\n",
        "        review = re.sub(r'⑤','', str(review))\n",
        "        review = re.sub(r'·',' 및 ', str(review))\n",
        "        #sent = re.sub(r'G20','', str(sent))\n",
        "        review = re.sub(r'↑','상승 ', str(review))\n",
        "        review = re.sub(r'↓','하락 ', str(review))\n",
        "        review = re.sub(r'ITF','국제태권도연맹 ', str(review))\n",
        "        review = re.sub(r'IS','이슬람 ', str(review))\n",
        "        review = re.sub(r'러','러시아 ', str(review))\n",
        "        review = re.sub(r'W농구','한국여자농구', str(review))\n",
        "        review = re.sub(r'C팰리스','크리스탈팰리스', str(review))\n",
        "        review = re.sub(r'SLBM','잠수함발사탄도미사일', str(review))\n",
        "        review = re.sub(r'VNL','배구네이션스리그', str(review))\n",
        "        #sent = re.sub(r'D','하루전', str(sent))\n",
        "        review = re.sub(r'LA타임스','로스엔젤레스타임스', str(review))\n",
        "        review = re.sub(r'V리그','배구리그', str(review))\n",
        "        review = re.sub(r'KOVO','한국배구연맹', str(review))\n",
        "        review = re.sub(r'ℓ','리터', str(review))\n",
        "        review = re.sub(r'SUN','선동열', str(review))\n",
        "        review = re.sub(r'WSJ',' 월스트리트 저널', str(review))\n",
        "        review = re.sub(r'ERA',' 평균자책점', str(review))\n",
        "        review = re.sub(r'IoT',' 사물인터넷', str(review))\n",
        "        review = re.sub(r'QS',' 선발 6이닝 이상 3자책점 이하 투구', str(review))\n",
        "        review = re.sub(r'NL','내셔널리그', str(review))\n",
        "        review = re.sub(r'UFG20','한미 합동 군사', str(review))\n",
        "        review = re.sub(r'F35','전투기', str(review))\n",
        "        review = re.sub(r'WP','워싱턴포스트', str(review))\n",
        "        review = re.sub(r'TK','대구와 경북', str(review))\n",
        "        review = re.sub(r'ACL','아시아축구연맹 챔피언스리그', str(review))\n",
        "        review = re.sub(r'IT','정보기술', str(review))\n",
        "        review = re.sub(r'AI','인공지능', str(review))\n",
        "        review = re.sub(r'TF','태스크포스', str(review))\n",
        "        review = re.sub(r'ML','메이저리그', str(review))\n",
        "        review = re.sub(r'FC','축구 클럽', str(review))\n",
        "        review = re.sub(r'SI','스포츠 일러스트레이티드', str(review))\n",
        "        review = re.sub(r'㈜','', str(review))\n",
        "        review = re.sub(r'MS','마이크로소프트', str(review))\n",
        "        review = re.sub(r'SNS','소셜 네트워크 서비스', str(review))\n",
        "        review = re.sub(r'B52','', str(review))\n",
        "        review = re.sub(r'VR','가상현실', str(review))\n",
        "        review = re.sub(r'ELB','주가연계파생결합사채', str(review))\n",
        "        review = re.sub(r'CES','국제전자제품박람회', str(review))\n",
        "        review = re.sub(r'NPL','부실채권', str(review))\n",
        "        review = re.sub(r'IPO','기업공개', str(review))\n",
        "        review = re.sub(r'ERA','방어율', str(review))\n",
        "        review = re.sub(r'MWC','모바일 산업 박람회', str(review))\n",
        "        review = re.sub(r'NSC','국가안전보장회의', str(review))\n",
        "        review = review.lower() #lower case\n",
        "        review = re.sub(r'\\s+', ' ', review) #remove extra space\n",
        "        review = re.sub(r'<[^>]+>','',review) #remove Html tags\n",
        "        review = re.sub(r'\\s+', ' ', review) #remove spaces\n",
        "        review = re.sub(r\"^\\s+\", '', review) #remove space from start\n",
        "        review = re.sub(r'\\s+$', '', review) #remove space from the end\n",
        "        review = re.sub(\"[一-龥]\",'', review)\n",
        "        corpus.append(review)\n",
        "    return corpus\n",
        "\n",
        "basic_preprocessed_train_corpus = clean_text(cleaned_train_corpus)\n",
        "basic_preprocessed_test_corpus = clean_text(cleaned_test_corpus)"
      ],
      "metadata": {
        "id": "uzUuKLPGybzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 불용어 제거"
      ],
      "metadata": {
        "id": "kambWDjRybzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = []\n",
        "with open(STOPWORDSPATH) as f:\n",
        "    for line in f:\n",
        "        stopwords.append(line.strip())\n",
        "\n",
        "\n",
        "removed_stopword_train_corpus = []\n",
        "removed_stopword_test_corpus = []\n",
        "\n",
        "for tagged in basic_preprocessed_train_corpus:\n",
        "    tagged=mecab.pos(tagged)\n",
        "    \n",
        "    temp = []\n",
        "    for tag in tagged:\n",
        "        if tag[0] in stopwords or tag[1] not in [\"NNG\", \"NNP\", \"VV\", \"VA\", \"VCP\", \"VCN\", \"MM\", \"MAG\", \"XPN\", \"SL\", \"SH\"]:\n",
        "            continue\n",
        "        temp.append(tag[0])\n",
        "\n",
        "    removed_stopword_train_corpus.append(' '.join(temp))\n",
        "    \n",
        "for tagged in basic_preprocessed_test_corpus:\n",
        "    tagged=mecab.pos(tagged)\n",
        "    \n",
        "    temp = []\n",
        "    for tag in tagged:\n",
        "        if tag[0] in stopwords or tag[1] not in [\"NNG\", \"NNP\", \"VV\", \"VA\", \"VCP\", \"VCN\", \"MM\", \"MAG\", \"XPN\", \"SL\", \"SH\"]:\n",
        "            continue\n",
        "        temp.append(tag[0])\n",
        "\n",
        "    removed_stopword_test_corpus.append(' '.join(temp))\n",
        "\n",
        "\n",
        "train_text = removed_stopword_train_corpus\n",
        "test_text = removed_stopword_test_corpus\n",
        "train_label = np.asarray(train.topic_idx)"
      ],
      "metadata": {
        "id": "3SlJCfmiybzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 추가 전처리 - 이상문자열 제거 "
      ],
      "metadata": {
        "id": "AsNvSWchybzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"k 이슬람 t\"라는 이상 문자열이 106개 row에서 발견되어 이를 제거하는 작업을 추가적으로 진행했습니다."
      ],
      "metadata": {
        "id": "1hROQK_vybzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'k 이슬람 t' 제거 \n",
        "train[\"clear_title\"] = train[\"clear_title\"].str.replace(\"k 이슬람 t\", \"\")\n",
        "test[\"clear_title\"] = test[\"clear_title\"].str.replace(\"k 이슬람 t\", \"\")"
      ],
      "metadata": {
        "id": "fi_bXjOhybzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 결과 확인"
      ],
      "metadata": {
        "id": "XNIOzC8OybzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_seq_items', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "np.set_printoptions(threshold = np.inf, linewidth = np.inf )\n",
        "\n",
        "train['clear_title'] = train_text\n",
        "test['clear_title'] = test_text\n",
        "\n",
        "train = train[['index','clear_title','topic_idx']]\n",
        "test = test[['index','clear_title']]"
      ],
      "metadata": {
        "id": "UWDmRG-rybzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train 최종 데이터 확인\n",
        "train[['clear_title']]"
      ],
      "metadata": {
        "id": "0Rd7IxFuybzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test 최종 데이터 확인\n",
        "test[['clear_title']]"
      ],
      "metadata": {
        "id": "1nytUINTybzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv(\"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/data/최종 데이터셋/fin_train.csv\", index =False)\n",
        "test.to_csv(\"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/data/최종 데이터셋/fin_test.csv\", index =False)"
      ],
      "metadata": {
        "id": "YPC6LO-uybzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Dataset Loading"
      ],
      "metadata": {
        "id": "viG1qxRyqSoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/data/최종 데이터셋/\""
      ],
      "metadata": {
        "id": "QNzfQXGDzWzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for Training**"
      ],
      "metadata": {
        "id": "hv30e7wHqe1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train = load_dataset(\"csv\", data_files = path + \"fin_train.csv\")\n",
        "Test = load_dataset(\"csv\", data_files = path + \"fin_test.csv\")"
      ],
      "metadata": {
        "id": "cyLaYUIrA50r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_dataset = datasets.DatasetDict({\"train\" : Train[\"train\"],\n",
        "                                      \"test\" : Test[\"train\"]})\n",
        "total_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzN7rClaqUbS",
        "outputId": "facf4ce8-a408-43dc-bdaa-4fbd8c1e7842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['index', 'clear_title', 'topic_idx'],\n",
              "        num_rows: 45654\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['index', 'clear_title'],\n",
              "        num_rows: 9131\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**for Testing**"
      ],
      "metadata": {
        "id": "zGPluo8hqgWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(path + \"fin_train.csv\")\n",
        "test = pd.read_csv(path + \"fin_test.csv\")\n",
        "submission = pd.read_csv(path + \"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "eSECz2t0lLwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "JELftYauhnv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter"
      ],
      "metadata": {
        "id": "-D7CZSNAoDLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "MAX_LEN = 46\n",
        "batch_size = 32\n",
        "num_cores = 2\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "\n",
        "lr = 1e-5\n",
        "log_interval = 200\n"
      ],
      "metadata": {
        "id": "8HKGtxy7a5OQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6561a1e6-0f3e-42e6-dfc7-6f405c65e678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Functions & Class"
      ],
      "metadata": {
        "id": "N0-Va0Ngo6oA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizing**"
      ],
      "metadata": {
        "id": "1UHJ2KQOp3WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(tokenizer, total_dataset):\n",
        "  tokenized = total_dataset.map(lambda x :tokenizer(text = x[\"clear_title\"], add_special_tokens = True,\n",
        "                   max_length = MAX_LEN, padding = \"max_length\",\n",
        "                   truncation = True) , batched = True)\n",
        "  \n",
        "  tokenized = tokenized.remove_columns([\"index\", \"clear_title\"])\n",
        "  \n",
        "  tokenized[\"train\"] = tokenized[\"train\"].rename_column(\"topic_idx\", \"labels\")\n",
        "  if \"valid\" in tokenized.keys():\n",
        "    tokenized[\"valid\"] = tokenized[\"valid\"].rename_column(\"topic_idx\", \"labels\")\n",
        "\n",
        "  #torch tensor로 바꾸기\n",
        "  tokenized.set_format(\"torch\")\n",
        "\n",
        "  if \"valid\" in tokenized.keys():\n",
        "    return tokenized[\"train\"], tokenized[\"valid\"], tokenized[\"test\"]\n",
        "  else:\n",
        "    return tokenized[\"train\"], tokenized[\"test\"]"
      ],
      "metadata": {
        "id": "8TL2ROVLBlUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenzing and Dataset**"
      ],
      "metadata": {
        "id": "FK690kg_p-vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "    def __getitem__(self, index):\n",
        "        # get the sentence from the dataframe\n",
        "        sentence = self.df_data.loc[index, 'clear_title']\n",
        "        encoded_dict = tokenizer(\n",
        "          text = sentence,\n",
        "          add_special_tokens = True, \n",
        "          max_length = MAX_LEN,\n",
        "          pad_to_max_length = True,\n",
        "          truncation=True,           # Pad & truncate all sentences.\n",
        "          return_tensors=\"pt\")\n",
        "\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        token_type_id = encoded_dict['token_type_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        target = torch.tensor(self.df_data.loc[index, \"topic_idx\"])\n",
        "        sample = (padded_token_list, token_type_id , att_mask, target)\n",
        "        return sample\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)"
      ],
      "metadata": {
        "id": "pNFs_RIzlJht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "    def __getitem__(self, index):\n",
        "        # get the sentence from the dataframe\n",
        "        sentence = self.df_data.loc[index, 'clear_title']\n",
        "        encoded_dict = tokenizer(\n",
        "          text = sentence,\n",
        "          add_special_tokens = True, \n",
        "          max_length = MAX_LEN,\n",
        "          pad_to_max_length = True,\n",
        "          truncation=True,           # Pad & truncate all sentences.\n",
        "          return_tensors=\"pt\")\n",
        "\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        token_type_id = encoded_dict['token_type_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        sample = (padded_token_list, token_type_id , att_mask)\n",
        "        return sample\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)"
      ],
      "metadata": {
        "id": "lz8sg3-4lISB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**accuracy**"
      ],
      "metadata": {
        "id": "v-Z5x8_8p6YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "Zrtj7ToxBqGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "0bYUXAdrp8B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Training(model, train_dataloader, optimizer, scheduler, num_epochs, device):\n",
        "\n",
        "  model.train()\n",
        "  Acc = []\n",
        "  for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "\n",
        "    for batch_id, batch in enumerate(tqdm(train_dataloader)):\n",
        "      optimizer.zero_grad() # 가중치 초기화\n",
        "\n",
        "      batch = {k:v.to(device) for k,v in batch.items()} #한번에 값들 넣기\n",
        "      label = batch[\"labels\"]\n",
        "\n",
        "      #forward\n",
        "      out = model(**batch) #iterator로\n",
        "      loss = out.loss #model의 method로 loss 제공\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      scheduler.step() #update learning rate schedule\n",
        "\n",
        "      train_acc +=calc_accuracy(out.logits, label) # 누적으로 계산\n",
        "\n",
        "      #출력문\n",
        "      if batch_id % log_interval == 0:\n",
        "        print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1))) # 누적으로 평균값\n",
        "\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1))) # epoch 마다 평균 정확도\n",
        "    Acc.append(train_acc / (batch_id +1))\n",
        "\n",
        "  return sum(Acc) / len(Acc), model"
      ],
      "metadata": {
        "id": "bdkXzzRKBtD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 : Roberta - small"
      ],
      "metadata": {
        "id": "PqVDicEShv0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'klue/roberta-small'"
      ],
      "metadata": {
        "id": "VcFTXvQfoCoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-small')\n",
        "\n",
        "train_data1 = TrainDataset(train)\n",
        "\n",
        "test_data1 = TestDataset(test)\n",
        "\n",
        "train_dataloader1 = torch.utils.data.DataLoader(train_data1,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                      num_workers=NUM_CORES)\n",
        "test_dataloader1 = torch.utils.data.DataLoader(test_data1,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=False,\n",
        "                                      num_workers=NUM_CORES)"
      ],
      "metadata": {
        "id": "TQcV4W6tqtjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained('klue/roberta-small',num_labels =7)\n",
        "model.to(device)\n",
        "\n",
        "# for scheduling\n",
        "warmup_ratio = 0.1\n",
        "t_total = len(train_dataloader1) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "optimizer = AdaBelief(model.parameters(), lr = lr,\n",
        "                     eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = True)\n",
        "\n",
        "\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps =warmup_step,\n",
        "                                            num_training_steps = t_total)\n",
        "\n",
        "train_acc_mean ,trained_model= Training(model, train_dataloader1, optimizer, scheduler, num_epochs, device)\n",
        "print(\"Average : \", train_acc_mean)\n",
        "\n",
        "#save model\n",
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/민경\"\n",
        "trained_model.save_pretrained(model_path + \"/{}\".format(model_name))\n"
      ],
      "metadata": {
        "id": "2V78EvTgqw06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trained_model)"
      ],
      "metadata": {
        "id": "GE2f7-3Rq015"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Roberta - base"
      ],
      "metadata": {
        "id": "yaWWQUjQh3OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained('klue/roberta-base', num_labels=7)\n",
        "model_name = 'klue/roberta-base'"
      ],
      "metadata": {
        "id": "pTORlBNsxM8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "Train_dataset2, Test_dataset2 = tokenized(tokenizer, total_dataset)\n",
        "\n",
        "#data loader\n",
        "\n",
        "train_dataloader2 = torch.utils.data.DataLoader(Train_dataset2,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                      num_workers=NUM_CORES)\n",
        "\n",
        "test_dataloader2 = torch.utils.data.DataLoader(Test_dataset2,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=False,\n",
        "                                      num_workers=NUM_CORES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "9229a5626f2a47bca3f5b2fbb0bea5f0",
            "24886713cbee4763a4733e4c3818dac7",
            "42f28af79b93445592878bf78c3f1d4a",
            "e73ef8ba75f94ab1bce5bcfa9d9bba56",
            "1a1c9c03b69440ddb461050da0850355",
            "f9823e9b338747e6a126a4e08a62854f",
            "95e3021100254d76a0f0733cf26626fa",
            "c73f6df44969422cba57aaa7a33f61bf",
            "d5f461f6daf7436abb5554f413e016de",
            "11d9ddfcb21544deaeed7bf007ec491c",
            "a910d525ebca41aa89d044380af28bd7",
            "9eceef0a86684c988c8bc6c50196633d",
            "ed559714a1754ef9883297fb39471244",
            "af2411ee0d3542ad8e5265edec56dbe1",
            "e187d84181ee452ea9e5194e47be7b0d",
            "e9002dd446f548888dbde86e3634ff45",
            "4d79b58cbbb74cafae361c3c18399def",
            "9908edb84f124668972091411419680c",
            "e33e1d135d8e48a9ad4802514b147c06",
            "2f5f6773bd83482e81f6268ba83befb0",
            "af987ac741c44293b1d6903e89dc634b",
            "fb0d8e276ba743058f3375d07e6583b8"
          ]
        },
        "id": "KEtEwYquylz8",
        "outputId": "23c8ebf9-55e8-4585-fa9a-3a5fb70db530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/46 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9229a5626f2a47bca3f5b2fbb0bea5f0"
            },
            "application/json": {
              "n": 0,
              "total": 46,
              "elapsed": 0.017885208129882812,
              "ncols": null,
              "nrows": null,
              "prefix": "",
              "ascii": false,
              "unit": "ba",
              "unit_scale": false,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1000,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eceef0a86684c988c8bc6c50196633d"
            },
            "application/json": {
              "n": 0,
              "total": 10,
              "elapsed": 0.017424583435058594,
              "ncols": null,
              "nrows": null,
              "prefix": "",
              "ascii": false,
              "unit": "ba",
              "unit_scale": false,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1000,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained('klue/roberta-base', num_labels=7)\n",
        "model.to(device)\n",
        "\n",
        "# for scheduling\n",
        "warmup_ratio = 0.1\n",
        "t_total = len(train_dataloader2) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "optimizer = AdaBelief(model.parameters(), lr = lr,\n",
        "                     eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = True)\n",
        "\n",
        "\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps =warmup_step,\n",
        "                                            num_training_steps = t_total)\n",
        "\n",
        "train_acc_mean ,trained_model= Training(model, train_dataloader2, optimizer, scheduler, num_epochs, device)\n",
        "print(\"Average : \", train_acc_mean)\n",
        "\n",
        "#save model\n",
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/윤\"\n",
        "trained_model.save_pretrained(model_path + \"/{}\".format(model_name))\n"
      ],
      "metadata": {
        "id": "77QD2Hbv0ih2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Roberta - large"
      ],
      "metadata": {
        "id": "_G6Ia0sxh3Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"klue/roberta-large\""
      ],
      "metadata": {
        "id": "wneKpNGJk6Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer =AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "Train_dataset3, Test_dataset3 = tokenized(tokenizer, total_dataset)\n",
        "\n",
        "#data loader\n",
        "\n",
        "train_dataloader3 = torch.utils.data.DataLoader(Train_dataset3,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True,\n",
        "                                      num_workers=num_cores)\n",
        "\n",
        "test_dataloader3 = torch.utils.data.DataLoader(Test_dataset3,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False,\n",
        "                                      num_workers=num_cores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "81f849f929114a6a848fd27274462e6d",
            "37bf6fb0685142a990b2e6d8493579b3",
            "0d9d5b83a16e48cfb8b600ee00ca5e76",
            "c11bc6a9bd534eaabcdb7b4e5fcf2c2d",
            "a113010524fd4aa4ae44c6a2902930a7",
            "d9f1c59b3a554865bf9b9c73e0969f25",
            "4ea70d720e594ce9a8d043bfd3aaab74",
            "1a6493bd6df14494ba712466358fed66",
            "be832c95ea9c4f16aeef3eee9b2b98f4",
            "55a969e0a57d405ebe099033a8015e53",
            "f6fba942d20148e78c7ad39bde8063be",
            "5ff744e4a9454d6780582c561c4a67e8",
            "6363916d96f043f0bc88aec85fd4064f",
            "ab3a54e49ac24670a7055a1ff145024e",
            "4d956d3ab0bd4dfcb8d6df42750cc422",
            "c2f26777eabc4609bbb8c3b6c4cb5c4a",
            "2144e18b1a5349e28e63d5d84deec600",
            "8ce2425372f54eaeae6b5976b284cc22",
            "f6b0665a3bfa4ab39cc42f2980862c32",
            "698b592b5de74412bc748848e203b399",
            "56cc8cf10a6644279bd57aee4e25ffb2",
            "5328429ba72b45c083b0a52d0a9c8524",
            "4ee5c1bbdb5a4edd8c223f1eb43635e0",
            "50f8d86351a546f68e89ee5f0cc7836c",
            "0d29cda4faf44df7a56d96dc970f6602",
            "ab5b53acf01c4b8eb6f43c17b1f6476c",
            "9228d314aa4545a6b49a41e7894c72cd",
            "b5b6aa915f65404289053c1d96116a04",
            "15d94acb38114fcab231c9a79b269764",
            "abae19b82622488fa298bb2444ebc172",
            "8a995c569e7c4ef69780b6f5b1816f9b",
            "1ad4c27a01e041c7b72ed859c9817f2e",
            "37530e3fdb3f40bdab7ed4200d0d750f",
            "081d8275b4264b5ab32bfafa8b6e7c9d",
            "2829dae120bc40aa80633ee57fd898a5",
            "aedf172943f74280a554b3b7bcec56ed",
            "f0f72819e6f549e8ab70d2da96d8106a",
            "1fd5ff51d1c04c3d976136ea66d9293e",
            "aa08dccfe9cb4fc2aecc4c6a151973fc",
            "2403747ccf374ded8d602d5f042bca61",
            "083fee4ee77c4a0880dd83b6cbee1637",
            "f7b5ce15f1294cda9242bf6df0b84552",
            "aea44bd3b36d4eadb227387c8a774abc",
            "fff570f44fcf43b1ae7a4eca45da2cfb",
            "0f9852cb50764b7399cbbd51a5b81995",
            "7e55b505b67a425cb9841a8a120a06f2",
            "25a848ce940d4782b02063f0a0605ffc",
            "70d0f5f4e4dd4497887c0111d1f71e46",
            "e142f3b6a5f545058efeb6a006108f10",
            "f60493dd4c5a43deaa7632ef9f172673",
            "47b6edd73b6c446fb8d301e6ac097bef",
            "ab1bd4b5dd38414d98b0406b33f9bca5",
            "8f3acc4b25944effbf59459efccb36f6",
            "62cf5444b40142efa77d443c244710fd",
            "05144695916b4791af5f0016ac794882",
            "5f6f66c0c0de4b32b16fe93b6ed2e703",
            "06acc44f8a254bc2bb8802815c483ab0",
            "34eab5033ff74a1ca425b1e6a760fc6c",
            "283568457ed54b85804dbc3c4e773c87",
            "bd3eba32943c4b2ca61efc16be9fccf0",
            "024b41ea419845d79dbdb8b9dc319d47",
            "10b6409da9cf49b5a1717144fbba5628",
            "6fc784abb569475ab0f66be8a6165e34",
            "5b58554bee5f46f2ac95457f67b25865",
            "484cfa482bf34faeb20f89d9d5c21331",
            "446a03845eab431ba88a0391a3ef35e6"
          ]
        },
        "id": "JQBgF3_FB8KS",
        "outputId": "f3c06a54-661d-4cf8-c181-91cb4ca11666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81f849f929114a6a848fd27274462e6d"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/243k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5328429ba72b45c083b0a52d0a9c8524"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37530e3fdb3f40bdab7ed4200d0d750f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fff570f44fcf43b1ae7a4eca45da2cfb"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/46 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05144695916b4791af5f0016ac794882"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "446a03845eab431ba88a0391a3ef35e6"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained('klue/roberta-large', num_labels=7)\n",
        "model.to(device)\n",
        "\n",
        "# for scheduling\n",
        "warmup_ratio = 0.1\n",
        "t_total = len(train_dataloader3) * epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "optimizer = AdaBelief(model.parameters(), lr=1e-5, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = False)\n",
        "\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps =warmup_step,\n",
        "                                            num_training_steps = t_total)\n",
        "\n",
        "train_acc_mean ,trained_model= Training(model, train_dataloader3, optimizer, scheduler, epochs, device)\n",
        "print(\"Average : \", train_acc_mean)\n",
        "\n",
        "#save model\n",
        "trained_model.save_pretrained(model_path + \"/{}\".format(model_name))"
      ],
      "metadata": {
        "id": "Lf7pmnpiCS3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trained_model)"
      ],
      "metadata": {
        "id": "m5IOZJa9-IGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4 : Koelectra - base"
      ],
      "metadata": {
        "id": "WWuy6a-vh3Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"monologg/koelectra-base-v3-discriminator\""
      ],
      "metadata": {
        "id": "k7KYVAxJlXqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer =ElectraTokenizer.from_pretrained(model_name)\n",
        "\n",
        "Train_dataset4, Test_dataset4 = tokenized(tokenizer, total_dataset)\n",
        "\n",
        "#data loader\n",
        "\n",
        "train_dataloader4 = torch.utils.data.DataLoader(Train_dataset4,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                      num_workers=NUM_CORES)\n",
        "\n",
        "test_dataloader4 = torch.utils.data.DataLoader(Test_dataset4,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=False,\n",
        "                                      num_workers=NUM_CORES)"
      ],
      "metadata": {
        "id": "NuMwf1SfsK_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels =7)\n",
        "model.to(device)\n",
        "\n",
        "# for scheduling\n",
        "warmup_ratio = 0.1\n",
        "t_total = len(train_dataloader4) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "optimizer = AdaBelief(model.parameters(), lr = lr,\n",
        "                     eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = True)\n",
        "\n",
        "\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps =warmup_step,\n",
        "                                            num_training_steps = t_total)\n",
        "\n",
        "train_acc_mean ,trained_model= Training(model, train_dataloader4, optimizer, scheduler, num_epochs, device)\n",
        "print(\"Average : \", train_acc_mean)\n",
        "\n",
        "#save model\n",
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/염\"\n",
        "trained_model.save_pretrained(model_path + \"/{}\".format(model_name))\n"
      ],
      "metadata": {
        "id": "aO5FPtFxtHv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trained_model)"
      ],
      "metadata": {
        "id": "eWCAaaZWoyX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction (Voting Ensemble)"
      ],
      "metadata": {
        "id": "z873cNbPh3b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roberta - large : 데이콘 결과 0.85454 114위(public) "
      ],
      "metadata": {
        "id": "9X6-nWY8mB1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/지호\"\n",
        "model_name = 'klue/roberta-large'\n",
        "save_path = model_path + \"/\"+ model_name\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=7).to(device)"
      ],
      "metadata": {
        "id": "1nIbfPkAnIJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "prediction_list =[]\n",
        "for batch in test_dataloader3:\n",
        "  batch = {k:v.to(device) for k, v in batch.items()}\n",
        "  with torch.no_grad():\n",
        "    output = model(**batch)\n",
        "\n",
        "  logits = output.logits\n",
        "  predictions = torch.argmax(logits, dim = 1)\n",
        "  prediction_list.extend(predictions.cpu().tolist()) # list.extend(iterator = list)항목들을 모두 바깥쪽에 넣는다.\n",
        "\n",
        "len(prediction_list)"
      ],
      "metadata": {
        "id": "VL7PUdRJ-NUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e9ad99-79f7-4626-80f3-5581602c6d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9131"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(path +\"sample_submission.csv\")\n",
        "print(submission.head())\n",
        "\n",
        "submission[\"topic_idx\"] = prediction_list\n",
        "print(submission.head())\n",
        "result_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/지호\"\n",
        "submission.to_csv(result_path + \"/result_robertlarge_adabelief.csv\", index = False)"
      ],
      "metadata": {
        "id": "lLPugXSE-Pp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893a22e6-8c43-4343-e415-44aef182af29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   index  topic_idx\n",
            "0  45654          0\n",
            "1  45655          0\n",
            "2  45656          0\n",
            "3  45657          0\n",
            "4  45658          0\n",
            "   index  topic_idx\n",
            "0  45654          0\n",
            "1  45655          3\n",
            "2  45656          2\n",
            "3  45657          0\n",
            "4  45658          3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble : koelectra(0.1) +large(0.3) + small(0.5) +  base(0.1) 0.84030 145등(public)"
      ],
      "metadata": {
        "id": "QTsmfguYmgR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. saved models calling \n",
        "2. prediction\n",
        "3. voting"
      ],
      "metadata": {
        "id": "DSKgV2F4tf7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. roberta-small"
      ],
      "metadata": {
        "id": "KCVtHv7xuG8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/민경\"\n",
        "model_name = 'klue/roberta-small'\n",
        "save_path = model_path + \"/\"+ model_name\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=7).to(device)"
      ],
      "metadata": {
        "id": "_eeo2sqehvE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [] \n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "for batch_id, (input_id,token_type_id,attention_mask) in enumerate(tqdm_notebook(test_dataloader1)):\n",
        "    input_id = input_id.long().to(device)\n",
        "    token_type_id = token_type_id.long().to(device)\n",
        "    attention_mask = attention_mask.long().to(device)\n",
        "    outputs = model(input_ids=input_id, token_type_ids=token_type_id, attention_mask=attention_mask)\n",
        "    out = outputs[0]\n",
        "    for inp in out:\n",
        "      preds.append(inp.detach().cpu().numpy())\n",
        "Preds = np.array(preds)"
      ],
      "metadata": {
        "id": "_ReNnV_Gi9u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Roberta_small = Preds \n",
        "Roberta_small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtiFQQ2Zn01P",
        "outputId": "b19b3f1e-9ca7-47ba-f8c8-6392b88d1341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.4591779 , -0.4251818 ,  2.4956343 , ..., -1.6797501 ,\n",
              "        -2.6218424 , -3.5937283 ],\n",
              "       [-1.8771108 , -2.0249472 , -0.42838815, ..., -0.3232079 ,\n",
              "        -1.694827  , -0.9351825 ],\n",
              "       [ 0.21637736, -0.4042029 ,  5.5209312 , ..., -0.7444878 ,\n",
              "        -3.1604404 ,  1.0278183 ],\n",
              "       ...,\n",
              "       [-2.1031325 , -2.6757224 ,  5.038392  , ..., -1.3883253 ,\n",
              "        -1.8889341 , -1.2277019 ],\n",
              "       [ 1.7475202 ,  4.318581  ,  3.544428  , ..., -1.9515331 ,\n",
              "        -1.9929845 , -3.3142335 ],\n",
              "       [ 0.63582855, -0.31544095,  3.3627174 , ..., -3.1467037 ,\n",
              "        -1.3221827 ,  4.0676026 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Roberta-base"
      ],
      "metadata": {
        "id": "T33xqDmWuyzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/윤\"\n",
        "model_name = 'klue/roberta-base'\n",
        "save_path = model_path + \"/\"+ model_name\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=7).to(device)"
      ],
      "metadata": {
        "id": "nRGFojE_u17_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [] \n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "for batch_id, (input_id,token_type_id,attention_mask) in enumerate(tqdm_notebook(test_dataloader2)):\n",
        "    input_id = input_id.long().to(device)\n",
        "    token_type_id = token_type_id.long().to(device)\n",
        "    attention_mask = attention_mask.long().to(device)\n",
        "    outputs = model(input_ids=input_id, token_type_ids=token_type_id, attention_mask=attention_mask)\n",
        "    out = outputs[0]\n",
        "    for inp in out:\n",
        "      preds.append(inp.detach().cpu().numpy())\n",
        "Preds = np.array(preds)"
      ],
      "metadata": {
        "id": "R9EKI3e9o5CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Roberta_base = Preds \n",
        "Roberta_base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8926a02f-b152-4627-ff22-70f0c9f87d66",
        "id": "2e_Ef80Do5CM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.0617213 ,  0.27876177,  0.83959943, ..., -0.88148355,\n",
              "        -2.8046308 , -4.221271  ],\n",
              "       [-1.7503253 , -2.1899025 ,  0.49846193, ..., -0.9193513 ,\n",
              "        -2.1130798 , -1.1184703 ],\n",
              "       [-0.4292372 , -0.5965223 ,  6.4967976 , ..., -1.253781  ,\n",
              "        -3.665053  , -0.33771127],\n",
              "       ...,\n",
              "       [-2.413768  , -1.745429  ,  6.0806003 , ..., -1.5730447 ,\n",
              "        -2.9930644 , -1.4727268 ],\n",
              "       [ 1.6451037 , -0.35484675,  5.686179  , ..., -2.446513  ,\n",
              "        -1.5499816 , -2.3602057 ],\n",
              "       [ 0.08038241, -0.64108   ,  3.8814101 , ..., -3.916439  ,\n",
              "        -2.161689  ,  4.197057  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Roberta-large"
      ],
      "metadata": {
        "id": "DxCDFWKiub_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/지호\"\n",
        "model_name = 'klue/roberta-large'\n",
        "save_path = model_path + \"/\"+ model_name\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=7).to(device)"
      ],
      "metadata": {
        "id": "apMHuLAGufPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [] \n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "for batch_id, (input_id,token_type_id,attention_mask) in enumerate(tqdm_notebook(test_dataloader3)):\n",
        "    input_id = input_id.long().to(device)\n",
        "    token_type_id = token_type_id.long().to(device)\n",
        "    attention_mask = attention_mask.long().to(device)\n",
        "    outputs = model(input_ids=input_id, token_type_ids=token_type_id, attention_mask=attention_mask)\n",
        "    out = outputs[0]\n",
        "    for inp in out:\n",
        "      preds.append(inp.detach().cpu().numpy())\n",
        "Preds = np.array(preds)"
      ],
      "metadata": {
        "id": "ulBcZWhboloZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Roberta_large = Preds \n",
        "Roberta_large"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7364b4f2-0c05-4dcf-f3b2-3d0136ddd385",
        "id": "V0UjuiC9oloa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.031582  ,  0.4835413 , -1.9664816 , ...,  0.3080583 ,\n",
              "        -2.69096   , -4.206146  ],\n",
              "       [-1.6322936 , -2.8785484 ,  0.7724615 , ..., -1.456878  ,\n",
              "        -1.2276715 , -1.3078557 ],\n",
              "       [-1.2246324 ,  0.32183525,  7.322132  , ..., -1.5378554 ,\n",
              "        -3.302623  , -0.6921514 ],\n",
              "       ...,\n",
              "       [-1.9306413 , -2.5169573 ,  4.128827  , ..., -0.8494464 ,\n",
              "        -2.9713948 , -3.04489   ],\n",
              "       [-1.858782  ,  1.9159635 ,  7.9690804 , ..., -2.6619954 ,\n",
              "        -2.4259474 , -2.994513  ],\n",
              "       [-1.1642442 , -1.1757185 ,  5.481288  , ..., -3.4326966 ,\n",
              "        -2.480573  ,  5.0481915 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Koelectra-base"
      ],
      "metadata": {
        "id": "TrQh7ahSvFx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/염\"\n",
        "model_name = 'monologg/koelectra-base-v3-discriminator'\n",
        "save_path = model_path + \"/\"+ model_name\n",
        "model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=7).to(device)"
      ],
      "metadata": {
        "id": "AuIBKrXpvJob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [] \n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "for batch_id, (input_id,token_type_id,attention_mask) in enumerate(tqdm_notebook(test_dataloader4)):\n",
        "    input_id = input_id.long().to(device)\n",
        "    token_type_id = token_type_id.long().to(device)\n",
        "    attention_mask = attention_mask.long().to(device)\n",
        "    outputs = model(input_ids=input_id, token_type_ids=token_type_id, attention_mask=attention_mask)\n",
        "    out = outputs[0]\n",
        "    for inp in out:\n",
        "      preds.append(inp.detach().cpu().numpy())\n",
        "Preds = np.array(preds)"
      ],
      "metadata": {
        "id": "AbvQEyv_pM2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Koelectra_base = Preds \n",
        "Koelectra_base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deed768b-765d-42b3-d4ac-a4a69e9b27ca",
        "id": "JvX7lDJApM2J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.2799342 ,  1.0971454 ,  1.9229554 , ..., -3.1768875 ,\n",
              "        -4.2963166 , -3.937318  ],\n",
              "       [-2.0020711 , -2.1920724 ,  0.09604193, ..., -0.6008972 ,\n",
              "        -2.363793  , -1.9305559 ],\n",
              "       [ 0.23240103, -0.21703632,  2.977845  , ...,  0.36266443,\n",
              "        -5.23138   ,  2.2204292 ],\n",
              "       ...,\n",
              "       [-2.5612462 , -2.0795794 ,  3.453697  , ..., -1.545476  ,\n",
              "        -3.7329066 , -1.7561842 ],\n",
              "       [ 0.18274824,  5.3301067 ,  2.9568539 , ..., -1.7096467 ,\n",
              "        -3.6123543 , -2.6795487 ],\n",
              "       [-1.9395641 , -0.36861038,  3.4598277 , ..., -2.039366  ,\n",
              "        -3.251142  ,  5.1563487 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Voting"
      ],
      "metadata": {
        "id": "OpQL2Do3vTNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pred_values = Roberta_small*0.5 + Roberta_base * 0.1 + Roberta_large * 0.3 + Koelectra_base * 0.1"
      ],
      "metadata": {
        "id": "T3385l2wvUBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = np.argmax(Pred_values, axis=1)\n",
        "submission['topic_idx']= results"
      ],
      "metadata": {
        "id": "ocX2CSahvdpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vfKHxp1tqIPC",
        "outputId": "2de1a66e-5afd-4aa5-eef4-07797ce8741d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index  topic_idx\n",
              "0     45654          3\n",
              "1     45655          3\n",
              "2     45656          2\n",
              "3     45657          0\n",
              "4     45658          3\n",
              "...     ...        ...\n",
              "9126  54780          3\n",
              "9127  54781          2\n",
              "9128  54782          3\n",
              "9129  54783          2\n",
              "9130  54784          6\n",
              "\n",
              "[9131 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88a5a6f9-2888-4d13-8e68-ea6edb9dfbda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>topic_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45654</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45655</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45656</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45657</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45658</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9126</th>\n",
              "      <td>54780</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9127</th>\n",
              "      <td>54781</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9128</th>\n",
              "      <td>54782</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9129</th>\n",
              "      <td>54783</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9130</th>\n",
              "      <td>54784</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9131 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88a5a6f9-2888-4d13-8e68-ea6edb9dfbda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88a5a6f9-2888-4d13-8e68-ea6edb9dfbda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88a5a6f9-2888-4d13-8e68-ea6edb9dfbda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_path = \"/content/drive/Shareddrives/2022-1 KUBIG 딥러닝 콘테스트/Code/4주차_최종/민경\"\n",
        "submission.to_csv(result_path + \"/ensenble10.csv\", index = False)"
      ],
      "metadata": {
        "id": "ENXD6QZHqN_n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}