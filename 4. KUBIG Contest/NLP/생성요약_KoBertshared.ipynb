{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bertshared_데이터 일부만 학습.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"dd7f85d68f5b47f58df9849defa2c7e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77a70ac18dab462183c600ce3f230291","IPY_MODEL_6149fd1bf2094d3d9207e1d00bdcb2eb","IPY_MODEL_79c62472270a4fc388f0761e82766176"],"layout":"IPY_MODEL_c5f8d0c992504cc5827faadf63ab934b"}},"77a70ac18dab462183c600ce3f230291":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd87c55568a649838240389378fcc781","placeholder":"​","style":"IPY_MODEL_35c5b11a137d4d25bea76d6f34d030c3","value":"100%"}},"6149fd1bf2094d3d9207e1d00bdcb2eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c9f781e7c0a4b09aff8f0a9b4ea163b","max":675,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1eb1d1ca9724c5499e5b3999dba5c69","value":675}},"79c62472270a4fc388f0761e82766176":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b35007753cca4036be798bf2383bd663","placeholder":"​","style":"IPY_MODEL_b8a7f8e016f74f9fb7fbd0d151ee7ea2","value":" 675/675 [2:12:36&lt;00:00, 11.72s/ba]"}},"c5f8d0c992504cc5827faadf63ab934b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd87c55568a649838240389378fcc781":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35c5b11a137d4d25bea76d6f34d030c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c9f781e7c0a4b09aff8f0a9b4ea163b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1eb1d1ca9724c5499e5b3999dba5c69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b35007753cca4036be798bf2383bd663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8a7f8e016f74f9fb7fbd0d151ee7ea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2278a30483349bcac333baf0eaf5fcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc991dfca99d465589493ce6da0d3d7c","IPY_MODEL_a842dc1a26fc40a79a0c46673f12ef47","IPY_MODEL_28c1826c991e42f9a52fc3ed721a72da"],"layout":"IPY_MODEL_539f6ade42c442bcb5e108d8cb78098d"}},"dc991dfca99d465589493ce6da0d3d7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed2b508d802748c98b9b6cd9e199f61a","placeholder":"​","style":"IPY_MODEL_479e2b018852497cbcffc1c9a8948b02","value":"Downloading tokenizer_config.json: 100%"}},"a842dc1a26fc40a79a0c46673f12ef47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_228be43cf1c9486c9b6a0ae00949c9e4","max":80,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33046a37de8045cd9615aa27b808e581","value":80}},"28c1826c991e42f9a52fc3ed721a72da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_934e17335f394a05a538d042ea06948a","placeholder":"​","style":"IPY_MODEL_9ab7e8d37ad34de2b22857009f3bd034","value":" 80.0/80.0 [00:00&lt;00:00, 2.59kB/s]"}},"539f6ade42c442bcb5e108d8cb78098d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed2b508d802748c98b9b6cd9e199f61a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"479e2b018852497cbcffc1c9a8948b02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"228be43cf1c9486c9b6a0ae00949c9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33046a37de8045cd9615aa27b808e581":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"934e17335f394a05a538d042ea06948a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ab7e8d37ad34de2b22857009f3bd034":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"823239815fb74387b1ca1e98ebc3c3b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_288098870b8f4982aeef061126ea8ff3","IPY_MODEL_190fb11acd05406e8409f47a85e03fcd","IPY_MODEL_9404448fac4d4ca9a2dfd3500f2c8613"],"layout":"IPY_MODEL_f78cf5f9b3ff46958cee3e4d8f2bbbe6"}},"288098870b8f4982aeef061126ea8ff3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a26a1e7e9a424902bd9571aea541618c","placeholder":"​","style":"IPY_MODEL_d8d5c032f14244668f8388f9d9778fc8","value":"Downloading vocab.txt: 100%"}},"190fb11acd05406e8409f47a85e03fcd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_574c77f4f57146fb868abb88888279e0","max":344259,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf486b711508467aa6dc9edd6bdb2395","value":344259}},"9404448fac4d4ca9a2dfd3500f2c8613":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_173f8c7845d4404ab4978d736b67c43c","placeholder":"​","style":"IPY_MODEL_449eecbde40c4703a387d3ab5f86327a","value":" 336k/336k [00:00&lt;00:00, 1.13MB/s]"}},"f78cf5f9b3ff46958cee3e4d8f2bbbe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a26a1e7e9a424902bd9571aea541618c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8d5c032f14244668f8388f9d9778fc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"574c77f4f57146fb868abb88888279e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf486b711508467aa6dc9edd6bdb2395":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"173f8c7845d4404ab4978d736b67c43c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"449eecbde40c4703a387d3ab5f86327a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f916732827c14ac49baeac091b97f7ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_413d6a19bf4646bfa81003217dadbbe4","IPY_MODEL_ab506788725448e78a48bb80e47eb328","IPY_MODEL_0c05db31ea3a42d18dc1f66904737e7a"],"layout":"IPY_MODEL_022d1b3d515a4f2f87448252b1486d74"}},"413d6a19bf4646bfa81003217dadbbe4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60446eb0f4734ea7bc047172d70b90c9","placeholder":"​","style":"IPY_MODEL_0f1d4fa3842349018ed64e6729a97855","value":"Downloading config.json: 100%"}},"ab506788725448e78a48bb80e47eb328":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dac0aedcb8041049b3550958beb74b6","max":4241,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f37c6b5cfef64336b56f1f236c563599","value":4241}},"0c05db31ea3a42d18dc1f66904737e7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28bd4213eee6400ca7099e6f56d1cbd6","placeholder":"​","style":"IPY_MODEL_b26e514ffbba483eb34b0ffa77ff75e6","value":" 4.14k/4.14k [00:00&lt;00:00, 135kB/s]"}},"022d1b3d515a4f2f87448252b1486d74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60446eb0f4734ea7bc047172d70b90c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f1d4fa3842349018ed64e6729a97855":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dac0aedcb8041049b3550958beb74b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37c6b5cfef64336b56f1f236c563599":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28bd4213eee6400ca7099e6f56d1cbd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b26e514ffbba483eb34b0ffa77ff75e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"487e3f90ba6c469dab27e6e4391bea5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9af4940af0264942b6b7be9ca106da77","IPY_MODEL_da709de03f3f49c2923760a8e4c682c7","IPY_MODEL_98757950bc7443de898543929920756d"],"layout":"IPY_MODEL_91d5908976be4deba9bf63b92a68ffce"}},"9af4940af0264942b6b7be9ca106da77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d84c5e2d76642fdb666aeb97202d6ce","placeholder":"​","style":"IPY_MODEL_05852216d5e54db89d49af5fac4f69bd","value":"Downloading pytorch_model.bin: 100%"}},"da709de03f3f49c2923760a8e4c682c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_029c848d647643d9bb323f042d0fd510","max":589387271,"min":0,"orientation":"horizontal","style":"IPY_MODEL_300c8c7b9c0a4b99a3e33e091b021a23","value":589387271}},"98757950bc7443de898543929920756d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1933899d25a345f092dd5b1c0b1f73c9","placeholder":"​","style":"IPY_MODEL_b11b4e9e8ab448ea91a354af7767c356","value":" 562M/562M [00:10&lt;00:00, 53.1MB/s]"}},"91d5908976be4deba9bf63b92a68ffce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d84c5e2d76642fdb666aeb97202d6ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05852216d5e54db89d49af5fac4f69bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"029c848d647643d9bb323f042d0fd510":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"300c8c7b9c0a4b99a3e33e091b021a23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1933899d25a345f092dd5b1c0b1f73c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11b4e9e8ab448ea91a354af7767c356":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aee5f33c7cb74b1785f52cfdf5375c0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9dc0f84fde5e4ea4a51625aa9c3631e6","IPY_MODEL_223c006e48ba49d794a6f23d20ab44ec","IPY_MODEL_5fdecd0621fa457ca3915a563e79b6dc"],"layout":"IPY_MODEL_ab487d12f4a94d218fc9e6b781d27c5c"}},"9dc0f84fde5e4ea4a51625aa9c3631e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cd69452989940229aebfce8896f2f96","placeholder":"​","style":"IPY_MODEL_42285fdcaaa44e1a8f89d446a71a93df","value":"100%"}},"223c006e48ba49d794a6f23d20ab44ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6bf4e7ee55d4fec9ee0cab4a2b35b5b","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_319eb6b375f4413484f89ded69a6f354","value":1000}},"5fdecd0621fa457ca3915a563e79b6dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ace2256566340e5a888aa3f01d1aa70","placeholder":"​","style":"IPY_MODEL_b55dbba0d38c47bdad9c350723dae4dc","value":" 1000/1000 [00:13&lt;00:00, 137.74ba/s]"}},"ab487d12f4a94d218fc9e6b781d27c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cd69452989940229aebfce8896f2f96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42285fdcaaa44e1a8f89d446a71a93df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6bf4e7ee55d4fec9ee0cab4a2b35b5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"319eb6b375f4413484f89ded69a6f354":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ace2256566340e5a888aa3f01d1aa70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b55dbba0d38c47bdad9c350723dae4dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7be071980492458391097d76d2495961":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d008ba57d71140ada955e8eb3f2ca1ca","IPY_MODEL_cb9ed63a42c447a58b075806c4d3daad","IPY_MODEL_28b4d6e973d0407795a929256f3ef841"],"layout":"IPY_MODEL_59319c3a82ee4108a499526e628bed8a"}},"d008ba57d71140ada955e8eb3f2ca1ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4796d6d35b144fea7228a34d5d60c21","placeholder":"​","style":"IPY_MODEL_aae44e09093e446382da2436cbdcfbdc","value":"100%"}},"cb9ed63a42c447a58b075806c4d3daad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_593fca580d25488b92b786af48a17289","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b30ecbcbac240a0a76f4d2877602dfb","value":30}},"28b4d6e973d0407795a929256f3ef841":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d536e25a927f4d238f31e1910062e813","placeholder":"​","style":"IPY_MODEL_214e77e68f1848d586ab123c6681801a","value":" 30/30 [00:00&lt;00:00, 120.61ba/s]"}},"59319c3a82ee4108a499526e628bed8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4796d6d35b144fea7228a34d5d60c21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aae44e09093e446382da2436cbdcfbdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"593fca580d25488b92b786af48a17289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b30ecbcbac240a0a76f4d2877602dfb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d536e25a927f4d238f31e1910062e813":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"214e77e68f1848d586ab123c6681801a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8245fd7891474e5e8d72b3df50bf6c96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bba19331cb2436397909c22f79d65e7","IPY_MODEL_05f5b56ad9c54f71b27da5230b228817","IPY_MODEL_e525bbbb270240b795205572d5ce3f69"],"layout":"IPY_MODEL_945dbc295d73456b82c3b4180bbc1874"}},"1bba19331cb2436397909c22f79d65e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f802c54c9b9540a78439b82b67a5f4b5","placeholder":"​","style":"IPY_MODEL_835a5836e2af4b24bd0d2a57e4226c67","value":"Downloading builder script: "}},"05f5b56ad9c54f71b27da5230b228817":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee7d7cb665884c9a8f47faa0101fd09c","max":2160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0337f0e82cbd44848e0c4ead46c2baaf","value":2160}},"e525bbbb270240b795205572d5ce3f69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98432c9016064d4eb43d056fef47263a","placeholder":"​","style":"IPY_MODEL_082a7142a77947d69dd975a38a1778d0","value":" 5.60k/? [00:00&lt;00:00, 152kB/s]"}},"945dbc295d73456b82c3b4180bbc1874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f802c54c9b9540a78439b82b67a5f4b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"835a5836e2af4b24bd0d2a57e4226c67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee7d7cb665884c9a8f47faa0101fd09c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0337f0e82cbd44848e0c4ead46c2baaf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98432c9016064d4eb43d056fef47263a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"082a7142a77947d69dd975a38a1778d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"5i8yHzf6aZQJ","executionInfo":{"status":"ok","timestamp":1661692732235,"user_tz":-540,"elapsed":360,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## 0. Pretrain - "],"metadata":{"id":"SDXHVj-2hihv"}},{"cell_type":"code","source":["!git clone https://github.com/kiyoungkim1/LMkor\n","!pip3 install -q transformers\n","\n","from LMkor.examples.bertshared_summarization import Summarize\n","summarize = Summarize('kykim/bertshared-kor-base')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309,"referenced_widgets":["a2278a30483349bcac333baf0eaf5fcd","dc991dfca99d465589493ce6da0d3d7c","a842dc1a26fc40a79a0c46673f12ef47","28c1826c991e42f9a52fc3ed721a72da","539f6ade42c442bcb5e108d8cb78098d","ed2b508d802748c98b9b6cd9e199f61a","479e2b018852497cbcffc1c9a8948b02","228be43cf1c9486c9b6a0ae00949c9e4","33046a37de8045cd9615aa27b808e581","934e17335f394a05a538d042ea06948a","9ab7e8d37ad34de2b22857009f3bd034","823239815fb74387b1ca1e98ebc3c3b5","288098870b8f4982aeef061126ea8ff3","190fb11acd05406e8409f47a85e03fcd","9404448fac4d4ca9a2dfd3500f2c8613","f78cf5f9b3ff46958cee3e4d8f2bbbe6","a26a1e7e9a424902bd9571aea541618c","d8d5c032f14244668f8388f9d9778fc8","574c77f4f57146fb868abb88888279e0","bf486b711508467aa6dc9edd6bdb2395","173f8c7845d4404ab4978d736b67c43c","449eecbde40c4703a387d3ab5f86327a","f916732827c14ac49baeac091b97f7ac","413d6a19bf4646bfa81003217dadbbe4","ab506788725448e78a48bb80e47eb328","0c05db31ea3a42d18dc1f66904737e7a","022d1b3d515a4f2f87448252b1486d74","60446eb0f4734ea7bc047172d70b90c9","0f1d4fa3842349018ed64e6729a97855","0dac0aedcb8041049b3550958beb74b6","f37c6b5cfef64336b56f1f236c563599","28bd4213eee6400ca7099e6f56d1cbd6","b26e514ffbba483eb34b0ffa77ff75e6","487e3f90ba6c469dab27e6e4391bea5f","9af4940af0264942b6b7be9ca106da77","da709de03f3f49c2923760a8e4c682c7","98757950bc7443de898543929920756d","91d5908976be4deba9bf63b92a68ffce","6d84c5e2d76642fdb666aeb97202d6ce","05852216d5e54db89d49af5fac4f69bd","029c848d647643d9bb323f042d0fd510","300c8c7b9c0a4b99a3e33e091b021a23","1933899d25a345f092dd5b1c0b1f73c9","b11b4e9e8ab448ea91a354af7767c356"]},"id":"-saUqZnthoBb","executionInfo":{"status":"ok","timestamp":1661692793838,"user_tz":-540,"elapsed":35847,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"c811cbea-ec21-48b2-8045-117c9ce162e9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'LMkor'...\n","remote: Enumerating objects: 98, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 98 (delta 16), reused 11 (delta 11), pack-reused 80\u001b[K\n","Unpacking objects: 100% (98/98), done.\n","\u001b[K     |████████████████████████████████| 4.7 MB 6.9 MB/s \n","\u001b[K     |████████████████████████████████| 120 kB 74.7 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 56.1 MB/s \n","\u001b[?25h"]},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2278a30483349bcac333baf0eaf5fcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/336k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"823239815fb74387b1ca1e98ebc3c3b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/4.14k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f916732827c14ac49baeac091b97f7ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/562M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487e3f90ba6c469dab27e6e4391bea5f"}},"metadata":{}}]},{"cell_type":"code","source":["from transformers import BertTokenizerFast, EncoderDecoderModel\n","model_bertshared = EncoderDecoderModel.from_pretrained(\"kykim/bertshared-kor-base\")"],"metadata":{"id":"MmcoWD7Ajmwb","executionInfo":{"status":"ok","timestamp":1661692800937,"user_tz":-540,"elapsed":7106,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["text = '''\n","LG전자가 스마트폰을 담당하는 MC(모바일커뮤니케이션)사업부 분할 및 매각을 위한 법률 자문 업무를 김앤장법률사무소에 맡겼다. MC사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n","22일 인수합병(M&A)업계에 따르면 LG전자는 최근 MC사업부 분할 후 매각 방안 등을 포괄적으로 검토하기 위해 김앤장을 법률자문사로 선임한 것으로 알려졌다. 회계·실사 자문은 EY한영회계법인에 맡길 가능성이 큰 것으로 전해졌다. 김앤장 등 자문사들은 사업본부를 분할한 뒤 사업양수도나 분할사업부의 지분 매각, 지식재산권(IP) 매각 등을 놓고 검토에 들어간 것으로 알려졌다.\n","업계에서는 LG전자가 MC사업본부를 통매각하기보다는 ‘쪼개기 매각’에 나설 것으로 보고 있다. 스마트폰 선행기술 연구개발(R&D) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측하고 있다. 앞서 권봉석 LG전자 사장은 사내 메시지를 통해 임직원에게 “현재 모든 가능성을 열어 두고 사업 운영방향을 면밀히 검토하고 있다”고 밝히며 매각 추진을 암시했다. M&A업계 관계자는 “거래가 성사되기도 전에 사업 전면 재검토를 공식화한 것은 상당히 이례적”이라며 “향후 매각이 잘 이뤄지지 않더라도 모바일 사업을 철수하겠다는 배수진을 둔 것으로 보인다”고 설명했다.\n","다만 원매자를 찾기가 쉽지 않을 것이란 전망이 우세하다. LG전자 모바일 사업은 한때 글로벌시장에서 톱5 안에 드는 기술력을 인정받았지만 누적 적자만 5조원에 달하고 있다. 업계에서 평가하는 MC사업부의 가치도 5000억원대에서 수조원대까지 편차가 상당히 크다.\n","상대적으로 해외 원매자들의 인수의사가 더 확실한 것으로 알려지고 있다. 북미사업 등 글로벌 시장 확장을 원하는 후발기업들이 주요 대상이다. 베트남의 빈그룹과 중국 기업 등이 유력하게 거론된다. 증권업계를 중심으로는 스마트 기기를 연결하는 사물인터넷(IoT) 사업을 염두에 둔 구글, 페이스북 같은 미국 정보기술(IT) 기업들도 원매자 후보군으로 꼽고 있다.\n","'''\n","\n","summarize(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORhIcqt7huXq","executionInfo":{"status":"ok","timestamp":1661690273011,"user_tz":-540,"elapsed":11138,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"65ddece0-5494-4d6c-8e57-5ca67cf8563a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["22일 인수합병 ( m & a ) 업계에 따르면 스마트폰 선행기술 연구개발 ( r & d ) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측되고 있으며 업계에서는 mc사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n"]}]},{"cell_type":"code","source":["type(summarize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Bfe37EhdQ-u","executionInfo":{"status":"ok","timestamp":1661690283535,"user_tz":-540,"elapsed":10570,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"a35501eb-87d9-4c44-b7d4-19f5980c74d2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["22일 인수합병 ( m & a ) 업계에 따르면 스마트폰 선행기술 연구개발 ( r & d ) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측되고 있으며 업계에서는 mc사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n"]},{"output_type":"execute_result","data":{"text/plain":["NoneType"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["a = summarize(text)\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09moQeyBddJb","executionInfo":{"status":"ok","timestamp":1661690322199,"user_tz":-540,"elapsed":11658,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"9bba323e-e192-459a-d42b-9f3b4ca87481"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["22일 인수합병 ( m & a ) 업계에 따르면 스마트폰 선행기술 연구개발 ( r & d ) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측되고 있으며 업계에서는 mc사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n","None\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3OZRg1KaoTA","executionInfo":{"status":"ok","timestamp":1661692841162,"user_tz":-540,"elapsed":40235,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"3b313e14-aba5-450c-e520-ec942a957da7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["news23 = pd.read_csv(\"/content/drive/MyDrive/2022-08-23.csv\")"],"metadata":{"id":"RlOR3HC3j0Mp","executionInfo":{"status":"ok","timestamp":1661689766768,"user_tz":-540,"elapsed":740,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["news23.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"-dUoEVOXbc0i","executionInfo":{"status":"ok","timestamp":1661689782746,"user_tz":-540,"elapsed":19,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"5ac5467d-34a8-43e7-dcb0-7bf2f445e6f3"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 url  \\\n","0  https://finance.naver.com/news/news_read.naver...   \n","1  https://finance.naver.com/news/news_read.naver...   \n","2  https://finance.naver.com/news/news_read.naver...   \n","3  https://finance.naver.com/news/news_read.naver...   \n","4  https://finance.naver.com/news/news_read.naver...   \n","\n","                                           title  \\\n","0   잭슨 홀 리스크·유럽 침체우려에도 나스닥 소폭 상승 출발 [데일리 국제금융시장]   \n","1              [Asia마감] 긴축 공포에 짓눌린 시장…닛케이 1.19%↓   \n","2  [마켓뷰] 코스피·코스닥 1% 넘게 하락…치솟는 美 달러화 가치에 투자금 ‘썰물’   \n","3             [마감시황]코스피, 강달러 지속에 1%대 하락…2430선 마감   \n","4                        [유럽개장]장 초반 하락세…獨 0.35%↓   \n","\n","                                                text  \n","0  다우 0.065%·S&P 0.069% 상승10년 물 국채 3.06%로 올라유로존 8...  \n","1  23일 아시아 주요국 증시가 일제히 하락 마감했다. 통화긴축, 경기침체에 대한 우려...  \n","2  유럽, 500년 만에 최악의 가뭄…경기 우려 심화유로화 가치 20년 만에 최저치로,...  \n","3  [서울=뉴시스] 조성우 기자 =코스피가 전 거래일(2462.50)보다 27.16포인...  \n","4  23일 유럽 증시가 장 초반 하락세를 보이고 있다.이날 오후 4시20분(한국시간) ...  "],"text/html":["\n","  <div id=\"df-dfdf86f6-411f-47c5-9f9f-a0feba5a8e88\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>url</th>\n","      <th>title</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://finance.naver.com/news/news_read.naver...</td>\n","      <td>잭슨 홀 리스크·유럽 침체우려에도 나스닥 소폭 상승 출발 [데일리 국제금융시장]</td>\n","      <td>다우 0.065%·S&amp;P 0.069% 상승10년 물 국채 3.06%로 올라유로존 8...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://finance.naver.com/news/news_read.naver...</td>\n","      <td>[Asia마감] 긴축 공포에 짓눌린 시장…닛케이 1.19%↓</td>\n","      <td>23일 아시아 주요국 증시가 일제히 하락 마감했다. 통화긴축, 경기침체에 대한 우려...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://finance.naver.com/news/news_read.naver...</td>\n","      <td>[마켓뷰] 코스피·코스닥 1% 넘게 하락…치솟는 美 달러화 가치에 투자금 ‘썰물’</td>\n","      <td>유럽, 500년 만에 최악의 가뭄…경기 우려 심화유로화 가치 20년 만에 최저치로,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://finance.naver.com/news/news_read.naver...</td>\n","      <td>[마감시황]코스피, 강달러 지속에 1%대 하락…2430선 마감</td>\n","      <td>[서울=뉴시스] 조성우 기자 =코스피가 전 거래일(2462.50)보다 27.16포인...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://finance.naver.com/news/news_read.naver...</td>\n","      <td>[유럽개장]장 초반 하락세…獨 0.35%↓</td>\n","      <td>23일 유럽 증시가 장 초반 하락세를 보이고 있다.이날 오후 4시20분(한국시간) ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfdf86f6-411f-47c5-9f9f-a0feba5a8e88')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dfdf86f6-411f-47c5-9f9f-a0feba5a8e88 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dfdf86f6-411f-47c5-9f9f-a0feba5a8e88');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["for i in range(len(news23)):\n","  passage = news23['text'][i]\n","  print(len(passage))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUeZKDTgb67N","executionInfo":{"status":"ok","timestamp":1661689930225,"user_tz":-540,"elapsed":305,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"95e6f701-45ab-416d-d7e8-bfee5c1a9d42"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["978\n","630\n","2004\n","1592\n","173\n","1773\n","1675\n","1379\n","1119\n","1645\n","2231\n","437\n","1900\n","2624\n"]}]},{"cell_type":"code","source":["pretrain_sum = []\n","for i in range(len(news23)):\n","  passage = news23['text'][i]\n","  try:\n","    sum = str(summarize(passage))\n","    pretrain_sum.append(sum)\n","  except :\n","    pretrain_sum.append('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RgY9YWfobat3","executionInfo":{"status":"ok","timestamp":1661690201693,"user_tz":-540,"elapsed":27223,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"10f6e7e9-dc24-443e-8966-2a013c6a549d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["제롬 미 연방준비제도 ( fed 연준 ) 의 다우존스산업평균지수가 매파적인 모습을 보이임에 따라 미국 뉴욕증시의 주요 지수가 출발했으며, 23일 오전9시35분 현재 뉴욕증권거래소 ( nyse ) 에서 기준 10. 05포인트 ( 0. 065 % ) 오른 3만3085. 19에 거래를 마쳤다.\n","23일 일본 도쿄 주식시장에서 닛케이225지수가 전날 대비 341. 75포인트 ( 1. 19 % ) 하락한 2만8452. 25로 장을 마감했다.\n","23일 오후 4시20분 현재 독일 dax지수는 전 거래일보다 0. 35 % 하락한 1만3184.\n","22일 금융투자협회에 따르면 채권형 펀드 시장에서 911억원의 자금이 빠져나갔다.\n"]}]},{"cell_type":"code","source":["pretrain_sum[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"osltEaQhckH0","executionInfo":{"status":"ok","timestamp":1661690211436,"user_tz":-540,"elapsed":15,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"dbd42434-9bb6-4f83-acca-b75902e1fe21"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'None'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## 1. Dataset 만들기"],"metadata":{"id":"fFfYzemPhogq"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cpweiB5SqerV","executionInfo":{"status":"ok","timestamp":1661692846593,"user_tz":-540,"elapsed":5444,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"1e2b0558-012b-4c7c-c168-5c418a028cbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 7.5 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 65.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 69.9 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 73.2 MB/s \n","\u001b[?25hRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}],"source":["pip install datasets"]},{"cell_type":"code","source":["from datasets import list_datasets, load_dataset\n","from datasets import load_dataset"],"metadata":{"id":"uJTQ1XlDqnR6","executionInfo":{"status":"ok","timestamp":1661692847089,"user_tz":-540,"elapsed":520,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","import json\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"UfSVrkUDqr2F","executionInfo":{"status":"ok","timestamp":1661692847090,"user_tz":-540,"elapsed":12,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCXqljjGqtL1","executionInfo":{"status":"ok","timestamp":1661692850832,"user_tz":-540,"elapsed":3752,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"e2b2f036-2d97-43ef-f928-ffac727b8503"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/KUBIG_NLP분반/쿠빅컨테스트/train.csv')"],"metadata":{"id":"f2YhZAHTqvri","executionInfo":{"status":"ok","timestamp":1661692852180,"user_tz":-540,"elapsed":1365,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data = df['passage']\n","print(len(data))\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4n_aJZwq48X","executionInfo":{"status":"ok","timestamp":1661692852180,"user_tz":-540,"elapsed":8,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"69e32dc4-0c10-4c44-895d-3632fd14c568"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["10800\n"]},{"output_type":"execute_result","data":{"text/plain":["0    이건희 삼성그룹 회장 사망 이후 불거진 상속 세제 개편 논의가 급물살을 탈지 주목된...\n","1    17일 국무총리실 산하 김해 신공항 검증위원회가 내놓은 ‘사실상 백지화’결론에 대해...\n","2    12일 오전 11시 30분경 서울 소공동 롯데백화점 본점 샤넬 매장 앞에는 매장에 ...\n","3    이탈리아 롬바르디아주의 한 병원에 근무하는 간호사 모니카 마리오티는 밤마다 악몽에 ...\n","4     세 곡 모두 2000년대 들어 발표된 곡으로 전통 트로트라기보다는 댄스가 가미된 ...\n","Name: passage, dtype: object"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["summary = df['summary']"],"metadata":{"id":"0r5bAp_yq6WV","executionInfo":{"status":"ok","timestamp":1661692852181,"user_tz":-540,"elapsed":7,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import transformers\n","from transformers import BertTokenizerFast, EncoderDecoderModel\n","transformers.logging.set_verbosity_error()"],"metadata":{"id":"4eKum0dEq8TI","executionInfo":{"status":"ok","timestamp":1661692852182,"user_tz":-540,"elapsed":8,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["tokenizer =BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\")"],"metadata":{"id":"oZH_Zxxaq9o2","executionInfo":{"status":"ok","timestamp":1661692882443,"user_tz":-540,"elapsed":2577,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["tokenizer.bos_token = tokenizer.cls_token\n","tokenizer.eos_token = tokenizer.sep_token"],"metadata":{"id":"uu22Vp6Iq_ZW","executionInfo":{"status":"ok","timestamp":1661692854423,"user_tz":-540,"elapsed":43,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["tokenizer.bos_token = 2\n","tokenizer.eos_token = 3"],"metadata":{"id":"Wi7bVd5Tkjko","executionInfo":{"status":"ok","timestamp":1661692854424,"user_tz":-540,"elapsed":40,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["df.drop(['Unnamed: 0'],axis=1,inplace=True)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"cCT11WAerA_d","executionInfo":{"status":"ok","timestamp":1661692854428,"user_tz":-540,"elapsed":42,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"50e8bbec-2e2d-48f5-c9a6-f522009d5ce4"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             passage  \\\n","0  이건희 삼성그룹 회장 사망 이후 불거진 상속 세제 개편 논의가 급물살을 탈지 주목된...   \n","1  17일 국무총리실 산하 김해 신공항 검증위원회가 내놓은 ‘사실상 백지화’결론에 대해...   \n","2  12일 오전 11시 30분경 서울 소공동 롯데백화점 본점 샤넬 매장 앞에는 매장에 ...   \n","3  이탈리아 롬바르디아주의 한 병원에 근무하는 간호사 모니카 마리오티는 밤마다 악몽에 ...   \n","4   세 곡 모두 2000년대 들어 발표된 곡으로 전통 트로트라기보다는 댄스가 가미된 ...   \n","\n","                                             summary  \n","0  홍 경제부총리 겸 기획재정부 장관이 이건희 회장의 사망 이후 불거진 상속 세제 개편...  \n","1  사실상 백지화 결론에 대해 경제성 평가를 빼고 검증했다는 전문가의 지적에 김 위원장...  \n","2  다수의 명품 브랜드에 이어 샤넬이 7개월 만에 가격을 또 인상한다는 소식이 전해지자...  \n","3  세레나 박사에 따르면 이탈리아 코로나19 보건 종사자 약70%가 우울증을 앓고 있는...  \n","4  대중문화평론가 이 씨는 현미의 밤안개 등을 트로트로 분류하기는 어렵지만 수용층이 넓...  "],"text/html":["\n","  <div id=\"df-c09bae49-2dd1-4c69-8367-2242d85b7a7a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>passage</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>이건희 삼성그룹 회장 사망 이후 불거진 상속 세제 개편 논의가 급물살을 탈지 주목된...</td>\n","      <td>홍 경제부총리 겸 기획재정부 장관이 이건희 회장의 사망 이후 불거진 상속 세제 개편...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>17일 국무총리실 산하 김해 신공항 검증위원회가 내놓은 ‘사실상 백지화’결론에 대해...</td>\n","      <td>사실상 백지화 결론에 대해 경제성 평가를 빼고 검증했다는 전문가의 지적에 김 위원장...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12일 오전 11시 30분경 서울 소공동 롯데백화점 본점 샤넬 매장 앞에는 매장에 ...</td>\n","      <td>다수의 명품 브랜드에 이어 샤넬이 7개월 만에 가격을 또 인상한다는 소식이 전해지자...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>이탈리아 롬바르디아주의 한 병원에 근무하는 간호사 모니카 마리오티는 밤마다 악몽에 ...</td>\n","      <td>세레나 박사에 따르면 이탈리아 코로나19 보건 종사자 약70%가 우울증을 앓고 있는...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>세 곡 모두 2000년대 들어 발표된 곡으로 전통 트로트라기보다는 댄스가 가미된 ...</td>\n","      <td>대중문화평론가 이 씨는 현미의 밤안개 등을 트로트로 분류하기는 어렵지만 수용층이 넓...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c09bae49-2dd1-4c69-8367-2242d85b7a7a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c09bae49-2dd1-4c69-8367-2242d85b7a7a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c09bae49-2dd1-4c69-8367-2242d85b7a7a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"2Sl1cexTrFX7","executionInfo":{"status":"ok","timestamp":1661692892914,"user_tz":-540,"elapsed":13,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","torch.manual_seed(42)\n","import random\n","\n","from transformers import GPT2LMHeadModel, GPT2Config\n","from transformers import AdamW, get_linear_schedule_with_warmup"],"metadata":{"id":"1Gz_b79KrI1l","executionInfo":{"status":"ok","timestamp":1661692895083,"user_tz":-540,"elapsed":2178,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model = EncoderDecoderModel.from_pretrained(\"kykim/bertshared-kor-base\")"],"metadata":{"id":"_emUJJCFrHGx","executionInfo":{"status":"ok","timestamp":1661692902579,"user_tz":-540,"elapsed":7509,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import torch.utils.data as data_utils\n"],"metadata":{"id":"JpsRhxh2rPq8","executionInfo":{"status":"ok","timestamp":1661692902580,"user_tz":-540,"elapsed":42,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["import datasets"],"metadata":{"id":"4ZKfP6Dmrusd","executionInfo":{"status":"ok","timestamp":1661692902581,"user_tz":-540,"elapsed":36,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["데이터 일부만 학습\n","* train : 4000\n","* test : 120"],"metadata":{"id":"hJ4iNnldYeyR"}},{"cell_type":"code","source":["passage = []\n","summary = []\n","for i in range(4000):\n","  passage.append(df['passage'][i])\n","  summary.append(df['summary'][i])\n","\n","train_dict = {'passage':passage, 'summary':summary}\n","\n","train_set = datasets.Dataset.from_dict(train_dict)"],"metadata":{"id":"BQTrPQijrSCZ","executionInfo":{"status":"ok","timestamp":1661692934845,"user_tz":-540,"elapsed":966,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["passage = []\n","summary = []\n","for i in range(4000,4120):\n","  passage.append(df['passage'][i])\n","  summary.append(df['summary'][i])\n","\n","val_dict = {'passage':passage, 'summary':summary}\n","\n","val_set = datasets.Dataset.from_dict(val_dict)"],"metadata":{"id":"QZkn-TRDrUGP","executionInfo":{"status":"ok","timestamp":1661692943268,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["batch_size=4  # change to 16 for full training\n","encoder_max_length=512\n","decoder_max_length=128\n","\n","def process_data_to_model_inputs(batch):\n","  # tokenize the inputs and labels\n","  inputs = tokenizer(batch[\"passage\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n","  outputs = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n","\n","  batch[\"input_ids\"] = inputs.input_ids\n","  batch[\"attention_mask\"] = inputs.attention_mask\n","  batch[\"decoder_input_ids\"] = outputs.input_ids\n","  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n","  batch[\"labels\"] = outputs.input_ids.copy()\n","\n","  # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n","  # We have to make sure that the PAD token is ignored\n","  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n","\n","  return batch\n","\n","# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n","#train_data = train_data.select(range(32))\n","\n","train_data = train_set.map(\n","    process_data_to_model_inputs, \n","    batched=True, \n","    batch_size=batch_size, \n","    remove_columns=[\"passage\", \"summary\"]\n",")\n","train_data.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",")\n","\n","\n","# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n","#val_data = val_set.select(range(16))\n","\n","val_data = val_set.map(\n","    process_data_to_model_inputs, \n","    batched=True, \n","    batch_size=batch_size, \n","    remove_columns=[\"passage\", \"summary\"]\n",")\n","val_data.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["aee5f33c7cb74b1785f52cfdf5375c0a","9dc0f84fde5e4ea4a51625aa9c3631e6","223c006e48ba49d794a6f23d20ab44ec","5fdecd0621fa457ca3915a563e79b6dc","ab487d12f4a94d218fc9e6b781d27c5c","2cd69452989940229aebfce8896f2f96","42285fdcaaa44e1a8f89d446a71a93df","d6bf4e7ee55d4fec9ee0cab4a2b35b5b","319eb6b375f4413484f89ded69a6f354","0ace2256566340e5a888aa3f01d1aa70","b55dbba0d38c47bdad9c350723dae4dc","7be071980492458391097d76d2495961","d008ba57d71140ada955e8eb3f2ca1ca","cb9ed63a42c447a58b075806c4d3daad","28b4d6e973d0407795a929256f3ef841","59319c3a82ee4108a499526e628bed8a","c4796d6d35b144fea7228a34d5d60c21","aae44e09093e446382da2436cbdcfbdc","593fca580d25488b92b786af48a17289","8b30ecbcbac240a0a76f4d2877602dfb","d536e25a927f4d238f31e1910062e813","214e77e68f1848d586ab123c6681801a"]},"id":"tlBoMZrtsGa3","executionInfo":{"status":"ok","timestamp":1661692969764,"user_tz":-540,"elapsed":13828,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"45bd1c59-81b1-4cdc-ba84-e21c150cc8a0"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aee5f33c7cb74b1785f52cfdf5375c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/30 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be071980492458391097d76d2495961"}},"metadata":{}}]},{"cell_type":"code","source":["train_data[4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOiKW0Cg1MgV","executionInfo":{"status":"ok","timestamp":1661693007366,"user_tz":-540,"elapsed":351,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"ed1454b4-3597-47c9-ba31-a8a57a721a81"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([    2,  4983,  2261, 14135, 14197, 17111, 14007, 37414,  2261, 13969,\n","         15651, 25975, 17856, 25718, 28678,  8048, 34076,  8544, 22877, 25975,\n","         15506, 34744,  2016,     1, 19448,  8970,     1, 15163, 16920,  8112,\n","          5051,  8048, 14393,     1,  7653, 16012, 35603,  8228,     1,  2010,\n","         18714,  8062,  2011,     1,  3114, 14941, 36900,  8027, 36227,     1,\n","          2010, 18714,  8045,  2011,  3408, 18714, 17111, 30395, 15360, 28491,\n","         33907,  4882,  9559, 14044, 28073,  2016,  7382, 25989, 21410,  8112,\n","          5051,  8048, 15297, 15651, 25975, 16630, 21841, 14231, 15097, 17112,\n","         23533,  8008, 31010, 28809, 13993,  2016, 15410, 16849, 15866, 35747,\n","         19667, 29453, 37372,  8289, 23120, 14055, 22451, 15626,  8144, 16779,\n","          2016, 28306,  8272, 16849, 15866,  8599, 32080,  8034,     1,  5605,\n","         32563, 22367, 16855, 15979, 20730, 14310, 35025, 20738,  2817,  7109,\n","          6967,  8107,     1,  5940,  8391,  5590,  3832,  8942, 30111, 41772,\n","          2010, 17326,     1,  2059,  2041, 30512, 36655,  8364, 25351,  2055,\n","         23634, 17528,  8464,  8191,  2011,  5887,  4414,  8102,  8112, 23767,\n","          8107,     1,  4361,  8102,  8356,     1,  2010, 17598,  8065,  2011,\n","          2783, 14147,  8323, 14908, 14243,  7532, 36593, 35725, 20900, 14988,\n","             1, 21175,  8368,     1,  2010, 15827,  8062,  2011,  5887, 25975,\n","         14758, 18785, 17260, 20739,  2016,  4486,  8014, 14009,  5676, 20769,\n","          7235,  9086, 14167, 19128, 23595,  3175, 30474,  8250,  2190,     1,\n","         18236, 17660,  2016, 14391,     1, 39169, 14071,  4486, 16581, 35514,\n","         14181, 30196, 18994, 20209,     1, 19954,  8271,     1,     1,  2933,\n","          8043,  4242, 14354,  2033,     1,  5907, 17349,  8028, 14076, 22216,\n","          8322, 19128, 16521, 16433, 14215, 17278, 17641,  8150,  5099, 13979,\n","         14404, 38964,     1, 18236, 21043,  2016, 14448, 41660, 37241, 15461,\n","         37584, 25110, 17055, 15979, 15219, 16064,  5099, 13979, 20266, 33030,\n","         13990,  2016, 14157,  8152, 15019, 38041, 17416,  6165,  8430,  8293,\n","         19867,     1, 22703,     1,  2051,  9385, 14446,     1,  2783,  2053,\n","         36655,  8086,     1, 30954,  8029, 30658,     1, 14051, 14059, 18136,\n","         22930, 14977, 13987, 16590, 20599, 37118, 17278, 17540, 14489,  5554,\n","          8139, 14625, 25220, 19889,  2016, 14112,     1, 26399,  8147,  8970,\n","             1, 35852, 17991, 21664, 20769, 14057, 17534,  8271, 27950, 13973,\n","         19830, 13975, 25220, 14835, 14011, 25702,     1,  2260,  6291, 13993,\n","          2016, 14391,     1, 15009,  4215,  8350, 20122, 20771, 16590, 16926,\n","         38160,  8289, 32559,  8059, 17055, 20349,  8144, 14057, 16608, 17188,\n","         15262, 13979,  2190, 14714,     1,  2260, 21043,  2016, 36889, 16576,\n","         22447, 14086,  6101, 26645, 27293, 29007, 14167, 15097, 14376, 15029,\n","          8144, 18380, 14909,  2016, 17630, 22703, 13970, 15315, 24636, 13969,\n","         36300,  4956,  9032,  8250,  2353, 14330,     1, 34655,  4038,     1,\n","          2287,     1, 23894,  8107,  4038,     1,  5617, 14391,     1,  7328,\n","          8970,  8107,  4038,     1, 27303, 14021, 30301,  2016,     1, 19448,\n","          8970,     1, 40937, 16855, 14454, 27660, 16165, 15749,  4976, 14335,\n","          8393, 21909, 38024, 14407, 14543,     1, 26399,  8147,  8970,     1,\n","          5883, 30075, 14725, 15173, 14167,  5966, 15538,  4882, 24409, 23779,\n","          2016, 20140, 13970,     1,  2783, 14887, 30441,     1,     1, 14188,\n","         33384,  8018,     1, 14475, 15439,  8112, 36663,  8714, 22447,  8048,\n","         15293,  8064,  8051, 23762,  3201, 14391, 41435,     1, 16271, 20184,\n","             1, 14475, 15439,  8112, 33415,  8217, 22447,  8048, 15293,  8065,\n","          4345, 16893, 24311,  8622, 15139, 41660, 14009, 19749,  8144, 15300,\n","         14909,  2016,  4956,  2353, 14330,     1, 14376,  8250,  6182, 14891,\n","         22447,  8048, 16015,  2008,  3966, 34957,  8013,  2016, 19977, 16590,\n","         15849,     3]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]),\n"," 'decoder_input_ids': tensor([    2, 16849, 15866,  8599, 32080,  5921, 18367, 23767,  8107,  4361,\n","          8102,  8356, 14475, 25975, 14758, 18785, 20611, 35232, 19128, 23595,\n","         30474,  8250, 22780, 39169, 14071,  4486, 16581, 35514, 14181, 18994,\n","         20530, 14046, 17660,  2016,     3,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'decoder_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'labels': tensor([    2, 16849, 15866,  8599, 32080,  5921, 18367, 23767,  8107,  4361,\n","          8102,  8356, 14475, 25975, 14758, 18785, 20611, 35232, 19128, 23595,\n","         30474,  8250, 22780, 39169, 14071,  4486, 16581, 35514, 14181, 18994,\n","         20530, 14046, 17660,  2016,     3,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n","          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])}"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["## 2. Fine Tuning"],"metadata":{"id":"DPWwdAvSYkmT"}},{"cell_type":"code","source":["model.config.max_length = 512\n","model.config.min_length = 128"],"metadata":{"id":"-Z19SewoeWXg","executionInfo":{"status":"ok","timestamp":1661693032403,"user_tz":-540,"elapsed":314,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# set special tokens\n","model.config.decoder_start_token_id = tokenizer.bos_token_id\n","model.config.eos_token_id = tokenizer.eos_token_id\n","model.config.pad_token_id = 0 #tokenizer.pad_token_id\n","\n","# sensible parameters for beam search\n","model.config.vocab_size = 42000 #model.config.decoder.vocab_size\n","model.config.max_length = 40\n","model.config.min_length = 0\n","model.config.no_repeat_ngram_size = 0\n","model.config.early_stopping = False\n","model.config.length_penalty = 1.0\n","model.config.num_beams = 1"],"metadata":{"id":"I3I7_DLNsJCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.config.vocab_size = 42000 #model.config.decoder.vocab_size\n","model.config.max_length = 100\n","model.config.min_length = 10\n"],"metadata":{"id":"iHPPYC4mu0gn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"],"metadata":{"id":"itgYKCr1sMDz","executionInfo":{"status":"ok","timestamp":1661693051303,"user_tz":-540,"elapsed":423,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset, load_metric"],"metadata":{"id":"j_0CN2edsNPs","executionInfo":{"status":"ok","timestamp":1661693051842,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["pip install rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fjx1vwBYsO4b","executionInfo":{"status":"ok","timestamp":1661693056407,"user_tz":-540,"elapsed":4197,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"58c0a230-2908-4eee-e017-85a5cf7c2306"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.2.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=93bd82498811533993fd149ce9b92b9ff28d02929f50f3fc2bf28cc108545f65\n","  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}]},{"cell_type":"markdown","source":["* rouge 지표를 활용해 loss 평가"],"metadata":{"id":"Cd4jtWPbYoZd"}},{"cell_type":"code","source":["# load rouge for validation\n","rouge = datasets.load_metric(\"rouge\")\n","\n","def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    # all unnecessary tokens are removed\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","\n","    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n","\n","    return {\n","        \"rouge2_precision\": round(rouge_output.precision, 4),\n","        \"rouge2_recall\": round(rouge_output.recall, 4),\n","        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n","    }"],"metadata":{"id":"NZSCUDAdsRBx","executionInfo":{"status":"ok","timestamp":1661693057625,"user_tz":-540,"elapsed":1232,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8245fd7891474e5e8d72b3df50bf6c96","1bba19331cb2436397909c22f79d65e7","05f5b56ad9c54f71b27da5230b228817","e525bbbb270240b795205572d5ce3f69","945dbc295d73456b82c3b4180bbc1874","f802c54c9b9540a78439b82b67a5f4b5","835a5836e2af4b24bd0d2a57e4226c67","ee7d7cb665884c9a8f47faa0101fd09c","0337f0e82cbd44848e0c4ead46c2baaf","98432c9016064d4eb43d056fef47263a","082a7142a77947d69dd975a38a1778d0"]},"outputId":"fa565a4b-1ae7-419a-b986-b369cbb38ec6"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8245fd7891474e5e8d72b3df50bf6c96"}},"metadata":{}}]},{"cell_type":"code","source":["model.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q23dtY95rsgp","executionInfo":{"status":"ok","timestamp":1661693067407,"user_tz":-540,"elapsed":8606,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"7fb5edaf-1b9b-4a6c-8dc4-4e481c0e9b13"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoderModel(\n","  (encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (decoder): BertLMHeadModel(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(42000, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (cls): BertOnlyMLMHead(\n","      (predictions): BertLMPredictionHead(\n","        (transform): BertPredictionHeadTransform(\n","          (dense): Linear(in_features=768, out_features=768, bias=True)\n","          (transform_act_fn): GELUActivation()\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (decoder): Linear(in_features=768, out_features=42000, bias=True)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# set training arguments - these params are not really tuned, feel free to change\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./\",\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    predict_with_generate=True,\n","    logging_steps=2,  # set to 1000 for full training\n","    save_steps=8,  # set to 500 for full training\n","    eval_steps=4,  # set to 8000 for full training\n","    warmup_steps=1,  # set to 2000 for full training\n","    max_steps=16, # delete for full training\n","    overwrite_output_dir=True,\n","    save_total_limit=3,\n","    #fp16=True, \n",")\n","\n","# instantiate trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n",")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szXJXALNsSzP","executionInfo":{"status":"ok","timestamp":1661694986130,"user_tz":-540,"elapsed":1911507,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"3ff305ce-89b7-4857-bc28-762f2d393e22"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 4000\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 16\n","/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 11.8961, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.0}\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 120\n","  Batch size = 4\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 7.7399, 'learning_rate': 4e-05, 'epoch': 0.0}\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 3.0857131481170654, 'eval_rouge2_precision': 0.0147, 'eval_rouge2_recall': 0.0448, 'eval_rouge2_fmeasure': 0.0157, 'eval_runtime': 464.3764, 'eval_samples_per_second': 0.258, 'eval_steps_per_second': 0.065, 'epoch': 0.0}\n","{'loss': 2.6593, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.01}\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 120\n","  Batch size = 4\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 1.605, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.01}\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Saving model checkpoint to ./checkpoint-8\n","Configuration saved in ./checkpoint-8/config.json\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 0.5979111790657043, 'eval_rouge2_precision': 0.0017, 'eval_rouge2_recall': 0.0083, 'eval_rouge2_fmeasure': 0.0028, 'eval_runtime': 475.5046, 'eval_samples_per_second': 0.252, 'eval_steps_per_second': 0.063, 'epoch': 0.01}\n"]},{"output_type":"stream","name":"stderr","text":["Model weights saved in ./checkpoint-8/pytorch_model.bin\n","tokenizer config file saved in ./checkpoint-8/tokenizer_config.json\n","Special tokens file saved in ./checkpoint-8/special_tokens_map.json\n","/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.7243, 'learning_rate': 2e-05, 'epoch': 0.01}\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 120\n","  Batch size = 4\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.3794, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.01}\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 0.25478240847587585, 'eval_rouge2_precision': 0.0104, 'eval_rouge2_recall': 0.0125, 'eval_rouge2_fmeasure': 0.0104, 'eval_runtime': 478.299, 'eval_samples_per_second': 0.251, 'eval_steps_per_second': 0.063, 'epoch': 0.01}\n","{'loss': 0.2516, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}\n"]},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 120\n","  Batch size = 4\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["{'loss': 0.1857, 'learning_rate': 0.0, 'epoch': 0.02}\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n","Saving model checkpoint to ./checkpoint-16\n","Configuration saved in ./checkpoint-16/config.json\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_loss': 0.16687269508838654, 'eval_rouge2_precision': 0.0072, 'eval_rouge2_recall': 0.01, 'eval_rouge2_fmeasure': 0.0062, 'eval_runtime': 464.3942, 'eval_samples_per_second': 0.258, 'eval_steps_per_second': 0.065, 'epoch': 0.02}\n"]},{"output_type":"stream","name":"stderr","text":["Model weights saved in ./checkpoint-16/pytorch_model.bin\n","tokenizer config file saved in ./checkpoint-16/tokenizer_config.json\n","Special tokens file saved in ./checkpoint-16/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["{'train_runtime': 1910.8824, 'train_samples_per_second': 0.033, 'train_steps_per_second': 0.008, 'train_loss': 3.1801698729395866, 'epoch': 0.02}\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=16, training_loss=3.1801698729395866, metrics={'train_runtime': 1910.8824, 'train_samples_per_second': 0.033, 'train_steps_per_second': 0.008, 'train_loss': 3.1801698729395866, 'epoch': 0.02})"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["/content/checkpoint-16"],"metadata":{"id":"qLlnsOocfgVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, '/content/drive/MyDrive/KUBIG_NLP분반/쿠빅컨테스트/model3.pt')"],"metadata":{"id":"FLjGMgg5o0t_","executionInfo":{"status":"ok","timestamp":1661695879923,"user_tz":-540,"elapsed":3078,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["trained_model = torch.load('/content/drive/MyDrive/KUBIG_NLP분반/쿠빅컨테스트/model3.pt') "],"metadata":{"id":"_GLZ6b2Vp3YN","executionInfo":{"status":"ok","timestamp":1661695887277,"user_tz":-540,"elapsed":889,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["text = '''\n","LG전자가 스마트폰을 담당하는 MC(모바일커뮤니케이션)사업부 분할 및 매각을 위한 법률 자문 업무를 김앤장법률사무소에 맡겼다. MC사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n","22일 인수합병(M&A)업계에 따르면 LG전자는 최근 MC사업부 분할 후 매각 방안 등을 포괄적으로 검토하기 위해 김앤장을 법률자문사로 선임한 것으로 알려졌다. 회계·실사 자문은 EY한영회계법인에 맡길 가능성이 큰 것으로 전해졌다. 김앤장 등 자문사들은 사업본부를 분할한 뒤 사업양수도나 분할사업부의 지분 매각, 지식재산권(IP) 매각 등을 놓고 검토에 들어간 것으로 알려졌다.\n","업계에서는 LG전자가 MC사업본부를 통매각하기보다는 ‘쪼개기 매각’에 나설 것으로 보고 있다. 스마트폰 선행기술 연구개발(R&D) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측하고 있다. 앞서 권봉석 LG전자 사장은 사내 메시지를 통해 임직원에게 “현재 모든 가능성을 열어 두고 사업 운영방향을 면밀히 검토하고 있다”고 밝히며 매각 추진을 암시했다. M&A업계 관계자는 “거래가 성사되기도 전에 사업 전면 재검토를 공식화한 것은 상당히 이례적”이라며 “향후 매각이 잘 이뤄지지 않더라도 모바일 사업을 철수하겠다는 배수진을 둔 것으로 보인다”고 설명했다.\n","다만 원매자를 찾기가 쉽지 않을 것이란 전망이 우세하다. LG전자 모바일 사업은 한때 글로벌시장에서 톱5 안에 드는 기술력을 인정받았지만 누적 적자만 5조원에 달하고 있다. 업계에서 평가하는 MC사업부의 가치도 5000억원대에서 수조원대까지 편차가 상당히 크다.\n","상대적으로 해외 원매자들의 인수의사가 더 확실한 것으로 알려지고 있다. 북미사업 등 글로벌 시장 확장을 원하는 후발기업들이 주요 대상이다. 베트남의 빈그룹과 중국 기업 등이 유력하게 거론된다. 증권업계를 중심으로는 스마트 기기를 연결하는 사물인터넷(IoT) 사업을 염두에 둔 구글, 페이스북 같은 미국 정보기술(IT) 기업들도 원매자 후보군으로 꼽고 있다.\n","'''\n"],"metadata":{"id":"27wXo7mwi0ou","executionInfo":{"status":"ok","timestamp":1661695892113,"user_tz":-540,"elapsed":429,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["trained_model.to(\"cuda\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xEYA7fU9rEEg","executionInfo":{"status":"ok","timestamp":1661695890002,"user_tz":-540,"elapsed":515,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"2391ac83-1350-4ad6-9b9e-0c79c30560c4"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoderModel(\n","  (encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (decoder): BertLMHeadModel(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(42000, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (cls): BertOnlyMLMHead(\n","      (predictions): BertLMPredictionHead(\n","        (transform): BertPredictionHeadTransform(\n","          (dense): Linear(in_features=768, out_features=768, bias=True)\n","          (transform_act_fn): GELUActivation()\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (decoder): Linear(in_features=768, out_features=42000, bias=True)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["input_ids = tokenizer.encode(text, return_tensors= 'pt').to(\"cuda\")\n","\n","sentence_length = len(input_ids[0])\n","min_length = max(10, int(0.1*sentence_length))\n","max_length = min(128, int(0.3*sentence_length))\n","\n","outputs = trained_model.generate(\n","            input_ids,\n","            min_length=min_length,\n","            max_length=max_length\n","        ).to(\"cuda\")\n","\n","\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Xtzm-nGp8PF","executionInfo":{"status":"ok","timestamp":1661695907631,"user_tz":-540,"elapsed":2410,"user":{"displayName":"‍김제성[ 학부재학 / 산업경영공학부 ]","userId":"16977677194422573223"}},"outputId":"dab5110a-65d3-4ea9-9d84-7316359b2f35"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["lg전자 lg전자가가 스마트폰을 스마트폰을 담당하는 담당하는 담당 담당담당담당을을으로으로 앞으로 앞으로 향후 향후 스마트폰 스마트폰 사업을 사업을사업을사업을 전면 전면 재 재검검토를토를토 토 토토토론론론을론을 검토 검토하기하기 위해 위해위해위해부분부분 부분 부분 기능 기능만만 남겨 남겨둔둔 채 채 매각 매각 에 에 를 를 을 을 으로 으로으로판 판 판판판판을판을 판을 판을 벌 벌벌벌벌을벌을벌 벌 판 판을판을판판과판과판을판의판의판도판도도도등도등도등등 등 등 등을 등을 등에 등에등에등에등이등이\n"]}]},{"cell_type":"code","source":["df2 = pd.read_csv(\"/content/drive/MyDrive/nlp콘테/test.csv\")\n","\n","df2.drop(['Unnamed: 0'],axis=1,inplace=True)\n","passage = []\n","summary = []\n","for i in range(len(df2)):\n","  passage.append(df2['passage'][i])\n","  summary.append(df2['summary'][i])\n","\n","test_dict = {'passage':passage, 'summary':summary}\n","\n","test_set = datasets.Dataset.from_dict(test_dict)"],"metadata":{"id":"z3ETy4E6sggn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import torch\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"rOGgO6kggCOI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uGPXGMnc4bE_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FfiyJcfj4bSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xawaWgvI4btm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import datasets\n","from transformers import BertTokenizer, EncoderDecoderModel\n","\n","tokenizer =BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\")\n","model = EncoderDecoderModel.from_pretrained(\"./checkpoint-16\")\n","model.to(\"cuda\")\n","\n","\n","\n","batch_size = 2 \n","\n","\n","def generate_summary(batch):\n","    # cut off at BERT max length 512\n","    inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n","    input_ids = inputs.input_ids.to(\"cuda\")\n","    attention_mask = inputs.attention_mask.to(\"cuda\")\n","\n","    outputs = model.generate(input_ids, attention_mask=attention_mask)\n","\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","\n","    batch[\"pred_summary\"] = output_str\n","\n","    return batch"],"metadata":{"id":"Y84IgBZj8uzf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import datasets\n","from transformers import BertTokenizer, EncoderDecoderModel\n","\n","tokenizer =BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\")\n","model = EncoderDecoderModel.from_pretrained(\"./checkpoint-16\")\n","model.to(\"cuda\")\n","\n","\n","\n","batch_size = 2  # change to 64 for full evaluation\n","\n","# map data correctly\n","def generate_summary(batch):\n","    # Tokenizer will automatically set [BOS] <text> [EOS]\n","    # cut off at BERT max length 512\n","    inputs = tokenizer(batch[\"passage\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n","    input_ids = inputs.input_ids.to(\"cuda\")\n","    attention_mask = inputs.attention_mask.to(\"cuda\")\n","\n","    outputs = model.generate(input_ids, attention_mask=attention_mask)\n","\n","    # all special tokens including will be removed\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","\n","    batch[\"pred\"] = output_str\n","\n","    return batch\n","\n","results = test_set.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"passage\"])\n","\n","pred_str = results[\"pred\"]\n","label_str = results[\"summary\"]\n","\n","rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n","\n","print(rouge_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dd7f85d68f5b47f58df9849defa2c7e9","77a70ac18dab462183c600ce3f230291","6149fd1bf2094d3d9207e1d00bdcb2eb","79c62472270a4fc388f0761e82766176","c5f8d0c992504cc5827faadf63ab934b","fd87c55568a649838240389378fcc781","35c5b11a137d4d25bea76d6f34d030c3","3c9f781e7c0a4b09aff8f0a9b4ea163b","f1eb1d1ca9724c5499e5b3999dba5c69","b35007753cca4036be798bf2383bd663","b8a7f8e016f74f9fb7fbd0d151ee7ea2"]},"id":"-mukkugxssUx","executionInfo":{"status":"ok","timestamp":1661622643050,"user_tz":-540,"elapsed":7967844,"user":{"displayName":"김제성","userId":"03872953743054971674"}},"outputId":"7e44ebe0-5bb1-471b-fd7f-9d58cc335fca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/kykim/bertshared-kor-base/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/5dad19823e267356237de15b22ef0ee33581947e683485d09ea07aa09858ac7e.8106bc2733ea9041a1bd1c717c63feb58e8291205b0ab7149d33ef57acbf7967\n","loading file https://huggingface.co/kykim/bertshared-kor-base/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/kykim/bertshared-kor-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/kykim/bertshared-kor-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/kykim/bertshared-kor-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/96e77e7b4fe2ca6ced390b061ec914e1bbca249637824af6daf76c159733032b.cbeb6d614d6fa18f12b887150236fbacf7aa47161d1292c3779477e43b12812a\n","loading configuration file https://huggingface.co/kykim/bertshared-kor-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c4193135ed575eb49ab4d454c620d8307581b677884178b0f73edc86e1a1f109.382189617b374963f4df0cac57b160b4a55a90c49b5d2d757c7d266d518759b1\n","Model config EncoderDecoderConfig {\n","  \"_name_or_path\": \"kykim/bertshared-kor-base\",\n","  \"architectures\": [\n","    \"EncoderDecoderModel\"\n","  ],\n","  \"decoder\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": true,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"bos_token_id\": 2,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": 2,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"embedding_size\": 768,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 3,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"gradient_checkpointing\": false,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": true,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": 3,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"transformers_version\": \"4.21.2\",\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 42000\n","  },\n","  \"early_stopping\": true,\n","  \"encoder\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"bos_token_id\": 2,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"embedding_size\": 768,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 3,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"gradient_checkpointing\": false,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": 3,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"transformers_version\": \"4.21.2\",\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 42000\n","  },\n","  \"is_encoder_decoder\": true,\n","  \"length_penalty\": 1.5,\n","  \"min_length\": 30,\n","  \"model_type\": \"encoder-decoder\",\n","  \"no_repeat_ngram_size\": 2,\n","  \"num_beams\": 4,\n","  \"tie_encoder_decoder\": true,\n","  \"transformers_version\": null,\n","  \"vocab_size\": 42000\n","}\n","\n","loading configuration file https://huggingface.co/kykim/bertshared-kor-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c4193135ed575eb49ab4d454c620d8307581b677884178b0f73edc86e1a1f109.382189617b374963f4df0cac57b160b4a55a90c49b5d2d757c7d266d518759b1\n","Model config EncoderDecoderConfig {\n","  \"_name_or_path\": \"kykim/bertshared-kor-base\",\n","  \"architectures\": [\n","    \"EncoderDecoderModel\"\n","  ],\n","  \"decoder\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": true,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"bos_token_id\": 2,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": 2,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"embedding_size\": 768,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 3,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"gradient_checkpointing\": false,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": true,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": 3,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"transformers_version\": \"4.21.2\",\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 42000\n","  },\n","  \"early_stopping\": true,\n","  \"encoder\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"bos_token_id\": 2,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"embedding_size\": 768,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 3,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"gradient_checkpointing\": false,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": 3,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"transformers_version\": \"4.21.2\",\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 42000\n","  },\n","  \"is_encoder_decoder\": true,\n","  \"length_penalty\": 1.5,\n","  \"min_length\": 30,\n","  \"model_type\": \"encoder-decoder\",\n","  \"no_repeat_ngram_size\": 2,\n","  \"num_beams\": 4,\n","  \"tie_encoder_decoder\": true,\n","  \"transformers_version\": null,\n","  \"vocab_size\": 42000\n","}\n","\n","loading configuration file ./checkpoint-16/config.json\n","Model config EncoderDecoderConfig {\n","  \"_name_or_path\": \"kykim/bertshared-kor-base\",\n","  \"architectures\": [\n","    \"EncoderDecoderModel\"\n","  ],\n","  \"decoder\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": true,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"bos_token_id\": 2,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": 2,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"embedding_size\": 768,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 3,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"gradient_checkpointing\": false,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": true,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": 3,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"transformers_version\": \"4.21.2\",\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 42000\n","  },\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"encoder\": {\n","    \"_name_or_path\": \"\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"bos_token_id\": 2,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"embedding_size\": 768,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": 3,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"gradient_checkpointing\": false,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": 3,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"transformers_version\": \"4.21.2\",\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 42000\n","  },\n","  \"eos_token_id\": 3,\n","  \"is_encoder_decoder\": true,\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 512,\n","  \"min_length\": 128,\n","  \"model_type\": \"encoder-decoder\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"num_beams\": 4,\n","  \"pad_token_id\": 0,\n","  \"tie_encoder_decoder\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": null,\n","  \"vocab_size\": 42000\n","}\n","\n","loading weights file ./checkpoint-16/pytorch_model.bin\n","The following encoder weights were not tied to the decoder ['bert/pooler']\n","All model checkpoint weights were used when initializing EncoderDecoderModel.\n","\n","All the weights of EncoderDecoderModel were initialized from the model checkpoint at ./checkpoint-16.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n","The following encoder weights were not tied to the decoder ['bert/pooler']\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/675 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd7f85d68f5b47f58df9849defa2c7e9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1207: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Score(precision=0.002809070326232798, recall=0.009382716049382716, fmeasure=0.0036810585549715983)\n"]}]},{"cell_type":"code","source":["text = '''\n","현대자동차가 미국 '인플레이션 감축법' 대응 방안으로 미국 조지아주에 설립키로 한 전기차 전용공장의 착공 시점을 앞당기기로 했다. 또 전기차 보조금만큼의 가격 할인도 검토 중이다.\n","23일 완성차 업계에 따르면 현대차는 당초 내년 상반기 착공 예정이었던 조지아주 전기차 전용공장 설립을 올해 안에 시작하기로 했다.\n","현대차가 올해 공사를 시작하면 2024년 하반기엔 공장을 완성할 수 있다.\n","이 같은 결정은 인플레이션 감축법으로 인해 받지 못하는 전기차 보조금 때문에 시장점유율 이탈을 우려한 때문이다.\n","현대차그룹은 현재 미국 시장에서 아이오닉5, 코나EV, 제네시스 GV60, EV6, 니로EV 등 5개 모델를 판매 중이다.\n","현대차는 미국 내 전기차 조립 라인이 없어 5개 모델 모두를 국내에서 생산해 수출하고 있다.\n","현대차는 GV70 전기차와 EV9 등 일부 차종은 기존 미국 생산 라인을 전환해 현지 생산할 계획이지만, 주력 차종인 아이오닉5 등은 여전히 국내에서 만들어 미국으로 보내야 하는 상황이다.\n","정부의 전기차 보조금 지급 대상에서 제외된다. 현대차가 조금씩 넓히고 있는 전기차 시장에 빨간불이 켜진 셈이다.\n","현대차는 올해 상반기 미국 시장 전기차 점유율에서 테슬라(70%)에 이어 2위(9%)를 차지했다.\n","현대차는 비록 2위지만 올해 들어 지난달까지 약 4만대의 전기차를 미국에 수출하는 등 미국 포드와 독일 폭스바겐을 제치며 성장 중이었다.\n","하지만 보조금을 받지 못해 가격이 오르면 경쟁력에서 밀리고 결국 시장 선점에 어려움을 겪을 수 있다.\n","실제로 아이오닉 5의 가격은 보조금 7500달러(약 1000만원)을 제외하면 4만 달러(약 5250만원) 수준이다.\n","비슷한 성능인 포드의 머스탱 마하E는 4만4000달러(5800만원)로 아이오닉 5보다 500만원가량 비쌌다. 하지만 보조금을 받지 못하면 포드 머스탱 마하E가 아이오닉 5보다 450만원 정도 가격이 낮아진다.\n","이에 따라 현대차그룹은 이번 인플레이션 감축법 문제로 조지아주 공장 설립 시기를 앞당기고 또 한편으로는 일정기간 가격 할인 등의 프로모션(판촉활동)도 검토 중인 것으로 알려졌다.\n","현대차에서 소비자들에게 가격을 보전해준다면 수익성은 줄어들겠지만 시장점유율은 확보할 수 있다. 전기차 시장에선 점유율이 중요한 만큼 현대차의 고심이 깊어지는 것이다.\n","완성차업계 관계자는 \"연내 조지아주 공장 착공을 목표로 알고 있다\"며 \"그 외에도 여러가지 방법을 검토 중\"이라고 했다.\n","한편 조 바이든 미국 대통령이 서명해 시행된 인플레이션 감축법은 북미에서 최종 조립되는 전기차만 보조금을 받을 수 있도록 하고 있다. 이 법으로 인해 전기차 보조금 지급 대상이 기존 72개 모델에서 21개로 축소됐다.\n","지급 대상 차종은 아우디 Q5, BMW X5와 3시리즈 플러그인, 포드Mach-E, F 시리즈, 에스케이프 PHEV와 Transit 밴, 크라이슬러 Pacifica PHEV, 지프 그랜드 체로키 PHEV, 랭글러 PHEV, 링컨 에비에이터 PHEV, 코세어 플러그인, 루시드 에어, 닛산 리프, 볼보 S60, 리비안 R1S와 R1T 등이다. 테슬라와 GM 전기차도 받는다.\n","반면 현대차그룹, 포르쉐 등이 판매하는 전기차는 보조금을 받을 수 없게 된다.\n","'''\n","\n"],"metadata":{"id":"1PpIO76ZsvY3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_summary(test_set[10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P91klMCvyQJW","executionInfo":{"status":"ok","timestamp":1661447784892,"user_tz":-540,"elapsed":9440,"user":{"displayName":"김제성","userId":"03872953743054971674"}},"outputId":"116d9695-36dd-475d-a6d8-07d1e23a931d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'passage': ' 더불어민주당이 뉴딜 펀드 띄우기를 시작했다.\\n  이해찬 대표를 비롯한 민주당 지도부는 5일 서울 여의도 한국거래소에서 현장간담회를 열고 민간 참여를 당부했다.\\n  이 대표는 인사말에서 “(한국형 뉴딜 사업에) 2025년까지 약 160조원이 투자될 거라고 보는데 상당 부분은 정부 재정이지만, 민간 부분에서도 10% 가까이 투자를 하는 구상을 하고 있다”고 말했다.\\n  문재인 정부의 임기 말 중점 사업들에 뉴딜 펀드로 민간 자금 16조원 이상을 끌어오겠다는 것이다.\\n  민주당은 이날 간담회에 기획재정부, 금융위원회 등 정부 부처와 금융투자협회, 은행연합회, 경영자총연합회, 신용보증기금 등 금융권 주요 협회 관계자를 두루 불렀다.\\n  최영권 우리자산운용 대표, 김재익 KDB인프라자산운용 대표 등 펀드 운용사 대표들도 나와 뉴딜 펀드의 구체적 설계 방향을 제시하고 토론에 참여했다.\\n  “개인뿐 아니라 연기금, 기관투자자 모두에게 좋은 ‘1석 3조’ 펀드”(홍성국 민주당 의원)라는 메시지를 강조하려는 의도다.\\n  이호형 은행연합회 전무이사는 간담회 직후 통화에서 “부동산 대책 이후에 이런 (그린·디지털 뉴딜 등) 신산업 쪽으로 물꼬를 틀겠다는 상징적 의미의 행사였다”고 했다.\\n   하지만 이날 비공개 토론에서는 정부 주도 방식의 뉴딜 펀드에 대한 몇 가지 의문이 제기됐다고 한다.\\n  전례 없는 형태의 관제 인프라 펀드인데, 현재까지 알려진 ‘원금 보장, 연 3%대 수익률’을 어떻게 실현할 수 있을지가 논의의 핵심이었다.\\n  간담회에 참석한 김동욱 한국경영자총협회 본부장은 “인프라 사업이란 게 한두 해에 끝나는 게 아니다.\\n  5년, 10년씩 가고 그 기간에 계속 수익이 나야 하는데 지금처럼 시중 유동성이 큰 상황이 유지될지 등을 함께 고민해야 한다”고 말했다.\\n  “퇴직연금 같은 국민 다수의 저축성 재원이 (뉴딜 펀드에) 투자될 수 있도록 규정을 개정하겠다”(윤관석 민주당 정책위 수석부의장)는 당·정의 구상이 위험하다는 지적도 있었다.\\n  익명을 요구한 한 참석자는 “퇴직연금뿐 아니라 국민연금 같은 공적연금을 뉴딜 펀드에 많이 가져오고 싶다는 건데, 현 정권이야 법까지 개정해 근로자 목숨줄과도 같은 노후 자금을 지켜준다지만 훗날에라도 정권이 바뀌면 지속 가능할지 의문”이라고 말했다.\\n  당·정은 뉴딜 펀드를 ‘국민 참여형 인프라 펀드’라고 소개한다.\\n  미래에셋대우 대표이사를 지낸 홍성국 의원은 “한국에서 한 번도 안 해본 것”이라고 했다.\\n ',\n"," 'summary': '비공개 토론에서 뉴딜 펀드에 대한 몇 가지 의문이 제기됐는데 전례 없는 형태의 관제 인프라 펀드라 시중 유동성이 큰 지금 같은 상황이 유지될지가 논의의 핵심이었다.',\n"," 'pred': ['더불어민주당 더불어민주당 더불어민주당 지도 지도부는부는 5일 5일 5일 서울 서울 여의도 여의도 한국 한국거래소거래소에서에서에서 열린 열린 열린한한한 한 한 한석석석,, 등 등 등 등과 등과 등과등과등과등과 등과 등과 함께 함께 함께 같이 같이 같이 함께 함께 하는 하는 하는 구상 구상 구상을을을 하고 하고 하고 있다 있다 있다...,,, 1 1 1석석석이석이석이석석 석 석 석석석석을석을석을석석석으로석으로석으로석을을을 만들어 만들어 만들어 만들어져 만들어져 만들어져 만들어졌다 만들어졌다 만들어졌다가가가 가 가갔다갔다갔다가가 다시 다시 다시 재 재 재재재재 재 재제제제제로제로제로로로로를를를가가 시작했다 시작했다 시작했다 시작 시작 시작 시작하고 시작하고 시작하고 시작하면서 시작하면서 시작하면서 하면서 하면서하면서하면서하면서 하면서 하면서 하면서 하며 하며 하며 또한 또한 또한 이러한 이러한 이러한 이런 이런 이런 이러한 이러한 다양한 다양한 다양한 형태의 형태의 형태의 형태 형태 형태 형태로 형태로 형태로 형태를 형태를 형태를 형태의 형태의 형태로 형태로형태로형태로형태로형태형태형태 형태를 형태를 형태가 형태가 형태가 형태를 형태를 형태로 형태로 형태의 형태의 형태가 형태가 해가 해가해가해가해가 해가 해가 해가 해 해 해해의해의해의해해해 해 해해해 대통령 대통령 대통령 선거 선거 선거 선거에 선거에 선거에 선거 선거 보조 보조 보조보조보조보조 보조 보조 주 주 주 주가 주가 주가 주 주주주주 주주 주주 주주주주들이들이들이들도들도들도들이들이들들들 들 들 들 들을 들을 들을 들 들들들들을들을들을들들들에서들에서들에서에서에서적적적적인적인적인 요소 요소 요소요소요소요소 요소 요소 요소가 요소가 요소가 요소 요소 요소를 요소를 요소를요소요소가가들이들이들을들을 것들을 것들을 것들을들을들을들에들에들에들이들이 것들이 것들이 것들 것들 것들들을들을들이들이 들 들 들이 들이 들이 들 들 들어 들어 들어들들들이들이 들어 들어 들어서 들어서 들어서 들 들들이들이들에들에들들들에들에들도들도 것들도 것들도 것들도들도들도들에들에들에서들에서들이들이 들이 들이들이들이 일어나 일어나 일어나면 일어나면 일어나면 일어나고 일어나고 일어나고 일어날 일어날 일어날 일어나지 일어나지 일어나지 일어나 일어나 일어나 일어나고 일어나고 일어나 일어나 일어나서 일어나서 일어나고 일어나고 일어나서 일어나서 일어나서 일어나면 일어나면 일어나 일어나 일어날 일어날 일어나고 일어나고 일어나면 일어나면 일어나서 일어나서 일어난 일어난 일어난 일어나고 일어나고 일어났 일어났 일어났 일어났다 일어났다 일어났다 일어나고 일어나고 일어난 일어난 일어나서 일어나서 일어나 일어나 일어난 일어난 일어나면 일어나면 일어나지 일어나지 일어나고 일어나고 일어나는 일어나는 일어나는 일어나고 일어나고 일어나지 일어나지 일어날 일어날 일어나 일어나일어나 일어나고 일어나고일어나일어나 일어날 일어날 가능성이 가능성이 가능성 가능성 가능성 가능성이 가능성이 가능성이성이성이성이 판단이 판단이 판단이 판단 판단 판단하기하기하기 하기 하기하기하기']}"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["sentence_length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"29xFB_bcwmZ9","executionInfo":{"status":"error","timestamp":1661447784893,"user_tz":-540,"elapsed":115,"user":{"displayName":"김제성","userId":"03872953743054971674"}},"outputId":"1f210ea9-47d8-4012-b025-9458db1d7751"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-2ee734191f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'sentence_length' is not defined"]}]},{"cell_type":"code","source":["input_ids = tokenizer.encode(text, return_tensors= 'pt',padding=\"max_length\",truncation=True, max_length = encoder_max_length)\n","\n","sentence_length = len(input_ids[0])\n","min_length = max(10, int(0.1*sentence_length))\n","max_length = min(128, int(0.3*sentence_length))\n","\n","\n","outputs = model.generate(\n","            input_ids,\n","            min_length=min_length,\n","            max_length=max_length\n","        )\n","\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))"],"metadata":{"id":"Q9gako0Wsx6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, '/content/drive/MyDrive/nlp콘테/model2.pt')"],"metadata":{"id":"BJ1zilNls1CB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["/content/checkpoint-16\n","/content/runs"],"metadata":{"id":"wzvtxpMvhDFo"},"execution_count":null,"outputs":[]}]}